---
title: "语言学与大语言模型之争"
subtitle: "《自然》杂志2023<语言学与语言模型>一文读后感"
date: 2025-06-23
format: html
---

## 派系之争

现代语言学的争论来源于关于AI及其所代表的语言模型的派系之争。乔姆斯基等”守旧派"认为大语言模型及其代表的技术（自然语言处理）对科学是毫无贡献的（"not a contribution to science"）。而史蒂夫·皮安塔多西（Steven Piantadosi）等“革新派"认为语言模型是语言学习的准确和正式的方式（"precise and formal accounts of language learning"）。最后的平衡派则认可语言模型在特定语言学领域的贡献，比如用神经网络模型或大语言模型来构建语言习得和语言处理的现实模型。

他们三方争论的焦点在于大语言模型本身的局限性：

1. 大语言模型也许能够精通语言，但是不是思想模型(model of thoughts)。大语言模型的范式是一种机器学习模型不是人类语言学习的模型。它们擅长续写语言，生成具有符合语言学特征的语言以及重复人类复杂的行为习惯。但它们在世界知识和语用学等功能性胜任力(functional competence)上是失败的。
2. 大语言模型究其本质与人类认知和语言能力无关。大语言模型的语言生成机制不能映射/解释人类的语言生成机制。用大语言模型来理解人类语言本身是徒劳的。而将大语言模型用作语言的“生成器"和"模拟器"则不能帮助人类更好理解人类语言，就好像理解汽车玩具的构造不能帮助你准确且全面的理解真正汽车的构造。

## 语言能力与人类无关

语言是一种符号的规律性排列与意象的映射。在语言模型出现前，这种映射中代表的创造力（比如诗歌，文学作品）似乎是独一无二的。但是大语言模型的出现，部分的语言功能甚至是具有创造性的那部分被证明是可以用数学模型模拟出来的。基于此，我们是否可以持"人类怀疑论"，即认为人类语言中的创造力也是一种基于生物模型的模式识别，或者"模拟器论"，即机器的创造力只是人类创造力的模仿？我认为这个答案还需要更多的证据去确认。

## 大语言模型的边界

毫无疑问的是，大语言模型有两个边界。第一，大语言模型的信息库必须依托人类已知语言。没有人类的语言作为基准，也就没有人类的语言模拟器。比如，如果全世界都只说英语，很难想象人类如何构建能说中文的大语言模型。再比如，在获取外星人的语言信息（外星语对人类产生意义）前，我们人类没办法构建外星人的大语言模型。第二，大语言模型必须生成对人类有意义的语言。比如说，"狗"这个词和它代表的"地球上一种四足动物”仅对人类有意义。假如科学家心血来潮构建一个语言模型把"dwev42"代表狗，这也只是一种文字游戏，而不是有意义的语言。同样的，人类的语言无论是人类产生的还是模拟器产生的也仅对人类有意义。也许有一天大语言模型已经用完所有人类的语言做训练，它可以用自己生成的语言做训练（现实中已经发生了），但是它不会产生对人类无意义而对它有意义的语言。

关于AI的自学习机制能否突破人类知识的边界，我认为答案是否定的。AI也许可以突破人类的"信息边界"，但是不会突破人类的"知识边界"。比方，AI也许可以生成一个[大猩猩的VLOG](https://www.bilibili.com/video/BV1SzTQzAEDK/?spm_id_from=..search-card.all.click)，这也许从来没有在人类创造的信息池中。但是这种信息的"创新"只是信息的排列组合（大猩猩，举着gopro，英语，森林），而人类的知识赋予了这些“组合"以意义。

## 结语

秦朝人也许不知道汽车的构造，但是他们能够理解轮子。我们不知道100年后甚至20年后的AI会变成什么样子，但是我们肯定它的input和output是有边界。

## 相关文献

1. [Language models and linguistic theories beyond words (2023)](https://www.nature.com/articles/s42256-023-00703-8), Nature.
