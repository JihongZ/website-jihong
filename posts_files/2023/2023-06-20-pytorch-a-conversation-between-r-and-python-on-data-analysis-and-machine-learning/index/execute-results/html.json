{
  "hash": "3510d4521dd04e6c523be9898439a66e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: 'A Conversation between R and Python on Data Analysis and Machine Learning'\ndate: '2023-06-20'\nauthor: 'Jihong Zhang'\nslug: pytorch-a-conversation-between-r-and-python-on-data-analysis-and-machine-learning\ndraft: false\ncommentable: true\nexecute: \n  eval: false\ncategories:\n  - blog\n  - R\n  - PyTorch\n  - Deep Learning\nsubtitle: ''\nsummary: ''\nlastmod: '2023-06-20T14:49:56+08:00'\nfeatured: no\ntoc: true\ncode-fold: show\n---\n\n\n\n\n\n> When I play with machine learning using python and R, I keep wondering whether I can combine R and Python code in a better way, such as using R for data cleaning/visualization and Python for machine learning. Online resources for PyTorch are basically written using python code. However, I always struggle with pandas and numpy but prefer tidyverse for data cleaning, and data manipulation. That's why I write this blog. I will start with the Pytorch tensor manipulation and import Pytorch tensor into R, then talk about mixing R/python data analysis with R/python visualization.\n\n![reticulate package logo](reticulated_python.png){fig-align=\"center\"}\n\n## PyTorch Tensor\n\nLet's first get familiar with data manipulation using *PyTorch*. First, `torch.zeors(R, C)` function can create a zero tensor with the size of R by C.\n\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{python, echo = \"fenced\"}}\nimport torch\n\nz = torch.zeros(5, 3)\nprint(z)\n```\n````\n:::\n\n\n\nSimilarly, `torch.ones(R, C)` creates a tensor filled with ones with the size of R by C with `dtype=torch.int16` argument can coverting elements into integer.\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ni = torch.ones((5,3), dtype=torch.int16)\nprint(i)\n```\n:::\n\n\n\nWe can generate random numbers to tensor using `torch.rand(R, C)`. It's recommended to set up a random seed using `torch.manual_seed(seed_num)` to make sure we can replicate our random tensor.\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ntorch.manual_seed(1729)\nr1 = torch.rand(2, 2)\nprint(f'A random tensor:\\n {r1}')\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nb = torch.arange(4 * 5 * 6).view(4, 5, 6)\nprint(f\"A sequence of number arraged to 4 matrix of the size 5 X 6: \\n{b}\\n\" )\n```\n:::\n\n\n\n### Arithmetic operations\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nones = torch.ones(2, 3)\nprint(f\"First tensor: \\n{ones}\\n\")\n\ntwos = torch.ones(2, 3) * 2 # multiple each element by 2\nprint(f\"Second tensor: \\n{twos}\\n\")\n\nthrees = ones + twos # addition allowed when shapes of two tensors are similar\nprint(f\"Third tensor: \\n{threes}\\n\")\n```\n:::\n\n\n\n### More examples of the matrix operations:\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ntorch.manual_seed(1729)\na = (torch.rand(2, 2) - 0.5) * 2\nprint(f'A random matrix: \\n{a}\\n')\n\na_abs = torch.abs(a) # Absolute values for elements\nprint(f'A absolute matrix: \\n{a_abs}\\n')\n\na_asin = torch.asin(a) # trigonometric functions\nprint(f'Inverse sine of r: \\n{a_asin}\\n')\n\na_det = torch.det(a) # Determinant and singular value decomposition\nprint(f'Determinant of r: \\n{a_det}\\n')\na_svd = torch.svd(a) \nprint(f'Singlular value decomposition of r: \\n{a_svd}\\n')\n\na_std_mean = torch.std_mean(a) # Statistical and aggregate operations:\nprint(f'Average and standard deviation of r: \\n{a_std_mean}\\n')\na_max = torch.max(a)\nprint(f'Maximum value of r: \\n{a_max}\\n')\n```\n:::\n\n\n\n### listwise computation\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\na_totalSum = torch.sum(a)\nprint(f'global sum of r: \\n{a_totalSum}\\n')\n\na_rowSum = torch.sum(a, dim=1, keepdim=True)\nprint(f'row sums of r: \\n{a_rowSum}\\n')\n\na_colSum = torch.sum(a, dim=0, keepdim=True)\nprint(f'column sums of r: \\n{a_colSum}\\n')\n```\n:::\n\n\n\n## Import tensor to R\n\nIf you install `torch` package in R. You probably found that Pytorch's tensor object can be called directly in R as `torch.Tensor`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\na_inR = py$a\nclass(a_inR)\n```\n:::\n\n\n\nUnfortunately, it does not allow you to manipulate this tensor object directly using R function. For example, if you do matrix operation, it will pop up error message.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\na_inR * 2\n```\n:::\n\n\n\nHowever, you can use python method in R style (change `.` to `$`) as long as you load `reticulate` package. Like:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\na_inR$shape\na_inR$data\n```\n:::\n\n\n\nCan we import PyTorch tensor to R and employ R to do some dirty works, and then export it back to python? The answer is Yes (partially). We can try out this workflow: tensor -\\> np.ndarray -\\> R matrix -\\> ...(some manipulation) -\\> np.ndarray -\\> tensor (see diagram below). I'm not sure if it is worthy nor it is even plausible for more complicated tensor class. Note that it may make the memory stores at least three copies of the data. More experiments needed for such work. For more information about arrays in R and python, please refer to the [reticulate manual](https://rstudio.github.io/reticulate/articles/arrays.html).\n\n\n\n```{mermaid}\ngraph LR;\n    tensor-->|np$array|np.ndarray;\n    np.ndarray-->|py_to_r|R.matrix;\n    R.matrix -->|some data manipulation|R.matrix;\n    R.matrix-->|r_to_py|np.ndarray;\n    np.ndarray-->|torch$from_numpy|tensor;\n```\n\n::: {.cell}\n\n```{.r .cell-code}\nnp <- import(\"numpy\", convert=FALSE)\na_data_inR = py_to_r(np$array(a_inR$data))\na_data_inR_revised = a_data_inR * 2\na_inR # original python object in R\na_data_inR_revised # revised matrix in R\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntorch <- import(\"torch\", convert=FALSE)\na_inR$data = torch$from_numpy(a_data_inR_revised)\na_inR\n```\n:::\n\n\n\n## Mixture of R and Python: visualization\n\nAs mentioned above, the `reticulate` R package provides an R interface to Python modules, classes, and functions, which allows us to extend our graphical toolbox to all packages/modules of R and Python. Currently, we can use three methods of data visualization via mixing R code and Python code:\n\n-   R data + Python `matlibplot` module\n-   Python data + Python `Vega-Altair` module + R output\n-   Python data + R `ggplot2` package\n\nLet's try them out one by one. First, take `iris` data in R for example:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(kableExtra)\niris_dat = iris[1:3]\niris_mat = matrix(unlist(iris_dat), nrow = nrow(iris), ncol = ncol(iris_dat))\ndim(iris_mat)\n```\n:::\n\n\n\nThe column sums of iris are `c(876.5, 458.6, 564.7)` and the row sums of first 5 rows of iris are `c(10, 9.3, 9.2, 9.2, 10)`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglue::glue('Columns Sums: {colSums(iris_mat)}')\nglue::glue('Row Sums: {rowSums(iris_mat[1:5, ])}')\n```\n:::\n\n\n\nIn Python chunk code of Rmarkdown, we can call data in R using `r.{dataname}`, in which `{dataname}` is the object name in R. Note that do not define `r` in python, otherwise `r` not longer become the R environment. Now we can load the R data frame in python. Please check [reticulate package](https://rstudio.github.io/reticulate/) for more information about the rules of conversation between R and Python.\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport torch\nimport numpy as np\niris_ndarray = np.array(r.iris_mat)\niris_tensor = torch.from_numpy(iris_ndarray)\ntorch.sum(iris_tensor, dim=0, keepdim=True)\ntorch.sum(iris_tensor[:5,], dim=1, keepdim=True)\n```\n:::\n\n\n\nIn Edgar Anderson's `Iris` data, we can model a prediction model given the measurements in centimeters of sepal length/width, petal length/width and the three types of species: Iris <mark style=\"background-color:lightblue\">setosa</mark>, <mark style=\"background-color:lightblue\">versicolor</mark>, and <mark style=\"background-color:lightblue\">virginica</mark>. Each type contains 50 samples. The very first question is then \"can we train a machine learning algorithm to predict whether one belongs to Setosa/Versicolor/Virginica given four characteristics?\" We can fit a multinomial regression to test statistical hypotheses of the characteristics' differences among three species:\n\n\n\n::: {#tbl-coef .cell tbl-cap='Coefficients of multinominal logistic regression'}\n\n```{.r .cell-code}\nlibrary(nnet)\nlibrary(MASS)\nlibrary(broom)\nlibrary(kableExtra)\niris_new = iris |> \n  mutate(Species = relevel(Species, \"virginica\"))\n## A multinominal logistic regression with Species-setosa as reference group\ncapture.output(multinomial_fit <- nnet::multinom(Species ~ . + 0, data = iris_new, \n                                                 model = TRUE),file =\"/dev/null\")\n## Print the coefficient table\nkbl(tidy(multinomial_fit, exponentiate = FALSE), digits = 2, \n    booktabs = TRUE, align = \"c\",\n    col.names = c(\"DV\", \"IV\", \"b(logit)\", \"SE\", \"t.value\", \"p.value\")) |>\n  kable_styling(bootstrap_options = c(\"condensed\", \"hover\"), html_font = \"Maven Pro\")\n```\n:::\n\n\n\nAs shown in @tbl-coef , it seems that multinominal logistic regression suggests none of the four features can significantly differentiate species but this could be misleading. This is because there are underlying correlations between sepal width/length and petal width/length. Next step is we can use `matplotlib` module to explore the relationships among four characteristics.\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport random\nimport seaborn\n\nseaborn.set(style='whitegrid'); seaborn.set_context('talk')\n\nfrom sklearn.datasets import load_iris\niris_data = load_iris()\n\nn_samples, n_features = iris_data.data.shape\n\ndef Show_Diagram(x_label,y_label,title):\n    plt.figure(figsize=(10,8))\n    plt.scatter(iris_data.data[:,x_label], iris_data.data[:,y_label], c=iris_data.target, cmap=cm.viridis, alpha = 0.5, label = iris_data.target_names)\n    plt.xlabel(iris_data.feature_names[x_label]); plt.ylabel(iris_data.feature_names[y_label]); plt.title(title)\n    plt.legend(('setosa', 'versicolor', 'virginica'))\n    plt.show();x_label = 2;y_label=3;title='Petal'\n\nShow_Diagram(0,1,'Sepal')\nShow_Diagram(2,3,'Petal')\n```\n:::\n\n\n\nAlternatively, we can use python data and module `Vega-Altair` to compile a interactive graphical object to a json file (`.to_json()`). Then we can plot it in R using `as_vegaspec` function.\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# import altair with an abbreviated alias\nimport altair as alt\nimport pandas as pd\nlabel_dict = {0: 'setosa', 1: 'versicolor', 2: 'virginica'}\n        \niris = pd.DataFrame(\n    data= np.c_[iris_data['data'], iris_data['target']],\n    columns= iris_data['feature_names'] + ['target']\n    )\niris['target'] = iris['target'].replace(label_dict)\n\nchart1 = alt.Chart(iris).mark_point().encode(\n  alt.X('sepal length (cm):Q').scale(domain=(4,9)),\n  alt.Y('sepal width (cm):Q').scale(domain=(1.5,5)),\n  alt.Color('target:N').scale(scheme='dark2'),\n  alt.Shape('target:N')\n).interactive()\nvw = chart1.to_json()\n```\n:::\n\n::: {.cell .fig-cap-location-top}\n\n```{.r .cell-code}\nas_vegaspec(py$vw)\n```\n:::\n\n\n\nAlternatively, we can use `ggplot2` R package + python data to plot the scatter plots, which I prefer.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(RColorBrewer)\nlibrary(dplyr)\n## A function to convert python iris to R version of iris\ntidy_python_data <- function(iris_from_python) {\n  dat <- iris_from_python$data\n  dat <- apply(dat, 2, as.numeric)\n  colnames(dat) <- iris_from_python$feature_names\n  Species = as.character(factor(iris_from_python$target, labels = iris_from_python$target_names))\n  dat = as.data.frame(cbind(dat, Species = Species))\n  dat <- dat |> \n    mutate(across(-Species, \\(x) as.numeric(x)))\n  dat\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(emojifont)\niris_from_python = tidy_python_data(iris_from_python = py$iris_data)\nggplot(iris_from_python) +\n  geom_point(aes(x = `sepal length (cm)`, y = `sepal width (cm)`, color = Species, shape = Species), size = 2, alpha = 0.8) +\n  labs(title = 'Sepal', caption = 'Love you Melody  ♥ !') +\n  scale_color_brewer(palette = 'Dark2')\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(iris_from_python) +\n  geom_point(aes(x = `petal length (cm)`, y = `petal width (cm)`, color = Species, shape = Species), size = 2, alpha = 0.8) +\n  labs(title = 'Petal', caption = 'Love you Melody  ♥ !') +\n  scale_color_brewer(palette = 'Dark2')\n```\n:::\n\n\n\nIt appears that its hard to differentiate versicolor with verginica in terms of sepal and petal but setosa is more smaller in petal width/length and sepal length but relative long sepal width.\n\n## Pure R: torch for R\n\nAlternatively, there is a R package called [`torch`](https://torch.mlverse.org/start/guess_the_correlation/), which is built directly on top of libtorch, a C++ library that provides the tensor-computation and automatic-differentiation capabilities. However, to the date I wrote this post, the version of torch is 0.11.0, which suggests that the package is still far from well developed.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(torch)\nlibrary(luz)\nlibrary(torchvision)\n# torch_tensor(1, device = 'cpu')\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}