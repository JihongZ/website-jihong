{
  "hash": "a48583eb36075ceb108ef41558be4e31",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Data visualization for survey data\"\nauthor: \"Jihong Zhang\"\ndescription: \"Many tutorials online are about general data visualization. This post aims to showcase some tricks for survey data\"\ndate: \"2023-07-04\"\ndraft: false\ncategories: \n  - blog\n  - ggplot2\nexecute: \n  eval: false\nformat:\n  html:\n    toc: true\n    code-fold: show\n    code-line-numbers: false\n    number-sections: true\n    number-offset: 1\n---\n\n\n\n\n## Question\n\nI am looking for R package than can analyze big data of survey.\n\n## R package - survey\n\nThe `survey` package in R is designed specifically for analysis of data from complex surveys. It provides functions for descriptive statistics and general regression models for survey data that includes design features such as clustering, stratification, and weighting.\n\nHere are some of the core features of the `survey` package:\n\n1.  **Descriptive Statistics:** The package provides functions for computing descriptive statistics on survey data, including mean, total, and quantiles.\n\n2.  **Regression Models:** The package provides a variety of model fitting functions for binary and multi-category response, count data, survival data, and continuous response.\n\n3.  **Design Effects:** It allows calculation of design effects for complex survey designs.\n\n4.  **Post-stratification and Raking:** The package allows for adjusting the sampling weights to match known population margins.\n\n5.  **Subpopulation Analysis:** It includes functions for correctly handling analyses that are limited to a subset of the population (a subpopulation).\n\n6.  **Variance Estimation:** The `survey` package supports multiple methods of variance estimation, including Taylor series linearization, replication weights, and subbootstrap.\n\nRemember that before you can use these functions, you will need to define a survey design object that specifies the features of your survey's design (like the sampling method, strata, clustering, and weights).\n\nHere's an example of how you might use it to calculate the mean of a variable from a survey:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the necessary package\nlibrary(survey)\n\nmydata <- iris\n\n# Define the survey design\ndes <- svydesign(ids = ~1, data = mydata, weights = ~Sepal.Length)\n\n# Calculate the mean of a variable\nmean <- svymean(~Species, design = des)\n\nmean\n```\n:::\n\n\n\n\n::: callout-note\n## Note\n\n|             |                                                                                                                               |\n|-------------|-----------------------------------------------------------|\n| `variables` | Formula or data frame specifying the variables measured in the survey. If `NULL`, the `data` argument is used.                |\n| `ids`       | Formula or data frame specifying cluster ids from largest level to smallest level, `~0` or `~1` is a formula for no clusters. |\n| `probs`     | Formula or data frame specifying cluster sampling probabilities                                                               |\n:::\n\nPlease replace `mydata`, `weight`, and `variable` with your actual data frame, weight column, and the variable you're interested in, respectively.\n\nRemember, working with survey data can be complex due to the design features of surveys. The `survey` package in R provides a robust set of tools for dealing with this complexity.\n\n## An empirical example\n\nThe example I used here is a tody data exacted from a real data about eating disorders. The sample size is 500.\n\nThe measurement data contains 12 items, each ranging from 0 to 3. The demographic data contains 6 variables: age, gender, race, birthplace, height, weight. The very first thing is to visualize the characteristics of the samples to have a big picture of respondents.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nknitr::opts_chunk$set(echo = TRUE, message=FALSE, warnings=FALSE, include = TRUE)\nlibrary(here)\nlibrary(glue)\nlibrary(readr)\nlibrary(bruceR)\nlibrary(xtable)\nlibrary(survey)\nlibrary(formattable) # format styles of table \nlibrary(reshape2)\nlibrary(tidyverse)\nlibrary(ggtext) \nlibrary(kableExtra)\noptions(knitr.kable.NA = '')\nmycolors = c(\"#4682B4\", \"#B4464B\", \"#B4AF46\", \n             \"#1B9E77\", \"#D95F02\", \"#7570B3\",\n             \"#E7298A\", \"#66A61E\", \"#B4F60A\")\nsoftcolors = c(\"#B4464B\", \"#F3DCD4\", \"#ECC9C7\", \n               \"#D9E3DA\", \"#D1CFC0\", \"#C2C2B4\")\nmykbl <- function(x, ...){\n  kbl(x, digits = 2, ...) |> kable_styling(bootstrap_options = c(\"striped\", \"condensed\")) }\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndatList <- readRDS(here::here(\"posts/2023-07-04-data-visualization-for-survey-data/Example_Data.RDS\"))\nstr(datList)\n```\n:::\n\n\n\n\n### Descriptive statistics\n\nWe can use multiple R tools for descriptive statistics. `bruceR` is one of them.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndescription <- datList$description\nbruceR::Freq(dplyr::select(description, gender:birthplace), \n             varname = \"gender\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfreqTblVars = c(\"gender\", \"race\", \"birthplace\")\nfreqTable <- function(tbl, var) {\n  tbl |> as.data.frame() |> \n    tibble::rownames_to_column(\"Levels\") |> \n    dplyr::mutate(Variable = var)\n}\nfreqTableComb = NULL\nfor (var in freqTblVars) {\n  tbl = bruceR::Freq(dplyr::select(description, gender:birthplace), varname = var)\n  freqTableComb = rbind(freqTableComb, freqTable(tbl = tbl, var = var))\n  freqTableComb <- freqTableComb |> \n    relocate(\"Variable\")\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmykbl(freqTableComb)\n```\n:::\n\n\n\n\nOr we can use `survey` package for descriptive analysis\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(survey)\ndexample = svydesign(ids = ~1,\n                     data = datList$measurement)\nsummary(dexample)\n\n## summay statistics for all measurement indicators\nvars <- colnames(datList$measurement)\nsvymean(make.formula(vars), design = dexample, na.rm = TRUE)\nsvytotal(make.formula(vars), design = dexample, na.rm = TRUE)\n```\n:::\n\n\n\n\n### Stacked barplot for survey data responses\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurvey = datList$measurement\nsurvey <- survey |> \n  mutate(ID = 1:nrow(survey)) |> \n  mutate(across(starts_with(\"EDEQS\"), \\(x) factor(x, levels = 0:3))) |> \n  pivot_longer(starts_with(\"EDEQS\"), names_to = \"items\", values_to = \"values\") |> \n  group_by(items) |> \n  dplyr::count(values) |> \n  dplyr::mutate(perc = n/sum(n) * 100)\n\np = ggplot(survey) +\n  geom_col(aes(y = factor(items, levels = paste0(\"EDEQS\", 1:12)),\n               x = perc,\n               fill = values), \n           position = position_stack(reverse = TRUE)) +\n  labs(y = \"\", x = \"Proportion (%)\", title = \"N and proportion of responses for items\")\n\np = p + geom_text(aes(y = factor(items, levels = paste0(\"EDEQS\", 1:12)),\n                  x = perc, group = items,\n                  label = ifelse(n >= 50, paste0(n, \"(\", round(perc, 1), \"%)\"), \"\")), \n              size = 3, color = \"white\",\n              position = position_stack(reverse = TRUE, vjust = 0.5))\np = p + scale_fill_manual(values = mycolors)\np\n```\n:::\n\n\n\n\nWe can clearly identify item 7 has highest proportion of level 0, and needed to be theoretically justified.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}