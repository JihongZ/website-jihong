{
  "hash": "3b08b972b2b0653ecc1d45794e98be3c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Lasso Regression Example using glmnet package in R\nauthor: Jihong Zhang\ndate: '2019-02-19'\ncategories:\n  - R\n  - manual\ntags:\n  - Lasso\n  - glmnet\noutput: html_document\n---\n\n\n\n\nMore details please refer to the link below: (<https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html#lin>)\n\nThis post shows how to use `glmnet` package to fit lasso regression and how to visualize the output. The description of data is shown in [here](http://myweb.uiowa.edu/pbreheny/data/whoari.html).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndt <- readRDS(url(\"https://s3.amazonaws.com/pbreheny-data-sets/whoari.rds\"))\nattach(dt)\nfit <- glmnet(X, y)\n```\n:::\n\n\n## Visualize the coefficients\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(fit)\n```\n:::\n\n\n### Label the path\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(fit, label = TRUE)\n```\n:::\n\n\nThe summary table below shows from left to right the number of nonzero coefficients (DF), the percent (of null) deviance explained (%dev) and the value of $\\lambda$ (`Lambda`).\n\nWe can get the actual coefficients at a specific $\\lambda$ whin the range of sequence:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoeffs <- coef(fit, s = 0.1) \ncoeffs.dt <- data.frame(name = coeffs@Dimnames[[1]][coeffs@i + 1], coefficient = coeffs@x) \n\n# reorder the variables in term of coefficients\ncoeffs.dt[order(coeffs.dt$coefficient, decreasing = T),]\n```\n:::\n\n\nAlso, it can allow people to make predictions at specific $\\lambda$ with new input data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnx = matrix(rnorm(nrow(dt$X)*ncol(dt$X)), nrow = nrow(dt$X), ncol = ncol(dt$X))\npred <- predict(fit, newx = nx, s = c(0.1, 0.05)) \nhead(pred, 20)\n```\n:::\n\n\n`cv.glmnet` is the function to do cross-validation here.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nX <- dt$X\ny <- dt$y\ncv.fit <- cv.glmnet(X, y)\n```\n:::\n\n\nPlotting the object gives the selected $\\lambda$ and corresponding Mean-Square Error.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(cv.fit)\n```\n:::\n\n\nWe can view the selected $\\lambda$'s and the corresponding coefficients, For example,\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncv.fit$lambda.min\ncv.fit$lambda.1se\n```\n:::\n\n\n`lambda.min` returns the value of $\\lambda$ that gives minimum mean cross-validated error. The other $\\lambda$ saved is `lambda.lse`, which gives the most regularized model such that error is within one standard error of the minimum. To use that, we only need to replace `lambda.min` with `lambda.lse` above.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create a function to transform coefficient of glmnet and cvglmnet to data.frame\ncoeff2dt <- function(fitobject, s) {\n  coeffs <- coef(fitobject, s) \n  coeffs.dt <- data.frame(name = coeffs@Dimnames[[1]][coeffs@i + 1], coefficient = coeffs@x) \n\n  # reorder the variables in term of coefficients\n  return(coeffs.dt[order(coeffs.dt$coefficient, decreasing = T),])\n}\n\ncoeff2dt(fitobject = cv.fit, s = \"lambda.min\") %>% head(20)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncoeffs.table <- coeff2dt(fitobject = cv.fit, s = \"lambda.min\")\nggplot(data = coeffs.table) +\n  geom_col(aes(x = name, y = coefficient, fill = {coefficient > 0})) +\n  xlab(label = \"\") +\n  ggtitle(expression(paste(\"Lasso Coefficients with \", lambda, \" = 0.0275\"))) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        legend.position = \"none\") \n```\n:::\n\n\n## Elastic net\n\nAs an example, we can set $\\alpha=0.2$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2 <- glmnet(X, y, alpha = 0.2, weights = c(rep(1, 716), rep(2, 100)), nlambda = 20)\n\nprint(fit2, digits = 3)\n```\n:::\n\n\nAccording to the default internal settings, the computations stop if either the fractional change in deviance down the path is less than $10^{-5}$ or the fraction of explained deviance reaches 0.999.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(fit2, xvar = \"lambda\", label = TRUE)\n\n# plot against %deviance\nplot(fit2, xvar = \"dev\", label = TRUE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(fit2, newx = X[1:5, ], type = \"response\", s = 0.03)\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}