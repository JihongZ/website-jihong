---
title: "Lecture 10"
subtitle: "Generalized Measurement Models: Modeling Observed Polytomous Data"
author: "Jihong Zhang"
institute: "Educational Statistics and Research Methods"
title-slide-attributes:
  data-background-image: ../Images/title_image.png
  data-background-size: contain
execute: 
  echo: false
  eval: false
format: 
  revealjs:
    logo: ../Images/UA_Logo_Horizontal.png
    incremental: false  # choose "false "if want to show all together
    transition: slide
    background-transition: fade
    theme: [simple, ../pp.scss]
    footer:  <https://jihongzhang.org/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553>
    scrollable: true
    slide-number: true
    chalkboard: true
    number-sections: false
    code-line-numbers: true
    code-annotations: below
    code-copy: true
    code-summary: ''
    highlight-style: arrow
    view: 'scroll' # Activate the scroll view
    scrollProgress: true # Force the scrollbar to remain visible
    mermaid:
      theme: neutral
#bibliography: references.bib
---

## Previous Class

1.  Dive deep into factor scoring
2.  Show how different initial values affect Bayesian model estimation
3.  Show how parameterization differs for standardized latent variables vs. marker item scale identification

## Today's Lecture Objectives

1.  Show how to estimate unidimensional latent variable models with polytomous data
    -   Also know as [Polytomous]{.underline} I[tem response theory]{.underline} (IRT) or [Item factor analysis]{.underline} (IFA)
2.  Distributions appropriate for polytomous (discrete; data with lower/upper limits)

## Example Data: Conspiracy Theories

-   Today's example is from a bootstrap resample of 177 undergraduate students at a large state university in the Midwest.
-   The survey was a measure of 10 questions about their beliefs in various conspiracy theories that were being passed around the internet in the early 2010s
-   All item responses were on a 5-point Likert scale with:
    1.  Strong Disagree $\rightarrow$ 0
    2.  Disagree $\rightarrow$ 0
    3.  Neither Agree nor Disagree $\rightarrow$ 0
    4.  Agree $\rightarrow$ 1
    5.  Strongly Agree $\rightarrow$ 1
-   The purpose of this survey was to study individual beliefs regarding conspiracies.
-   Our purpose in using this instrument is to provide a context that we all may find relevant as many of these conspiracies are still prevalent.

## From Previous Lectures: CFA (Normal Outcomes)

For comparisons today, we will be using the model where we assumed each outcome was (conditionally) normally distributed:

For an item $i$ the model is:

$$
Y_{pi}=\mu_i+\lambda_i\theta_p+e_{pi}\\
e_{pi}\sim N(0,\psi_i^2)
$$

Recall that this assumption wasn't good one as the type of data (discrete, bounded, some multimodality) did not match the normal distribution assumption.

## Polytomous Data Characteristics

As we have done with each observed variable, we must decide which distribution to use

-   To do this, we need to map the characteristics of our data on to distributions that share those characteristics

Our observed data:

-   Discrete responses
-   Small set of known categories: 1,2,3,4,5
-   Some observed item responses may be multimodal

## Discrete Data Distributions

[Stan](https://mc-stan.org/docs/functions-reference/bounded_discrete_distributions.html) has a list of distributions for bounded discrete data

1.  Binomial distribution
    -   Pro: Easy to use / code
    -   Con: Unimodal distribution
2.  Beta-binomial distribution
    -   Not often used in psychometrics (but could be)
    -   Generalizes binomial distribution to have different probability for each trial
3.  Hypergeometric distribution
    -   Not often used in psychometrics
4.  Categorical distribution (sometimes called multinomial)
    -   Most frequently used
    -   Base distribution for graded response, partial credit, and nominal response models
5.  Discrete range distribution (sometimes called uniform)
    -   Not useful–doesn't have much information about latent variables

# Binomial Distribution Models

## Binomial Distribution Models

The binomial distribution is one of the easiest to use for polytomous items

-   However, it assumes the distribution of responses are unimodal

Binomial probability mass function (i.e., pdf):

$$
P(Y=y)=\begin{pmatrix}n\\y\end{pmatrix}p^y(1-p)^{(n-y)}
$$

Parameters:

-   n - "number of trials" (range: $n \in \{0, 1, \dots\}$)
-   y - "number of successes" out of $n$ "trials" (range: $y\in\{0,1,\dots,n\}$)
-   p - "probability of success" (range: \[0, 1\])
-   Mean: $np$
-   Variance: $np(1-p)$

## Adapting the Binomial for Item Response Models

Although it doesn't seem like our items fit with a binomial, we can actually use this distribution

-   Item response: number of successes $y_i$
    -   Needed: recode data so that lowest category is 0 (subtract one from each item)
-   Highest (recoded) item response: number of trials $n$
    -   For all out items, once recoded, $n_i = 4$
-   Then, use a link function to model each item's $p_i$ as a function of the latent trait:

$$
P(Y_i=y_i)=\begin{pmatrix}4\\y_i\end{pmatrix}p^{y_i}(1-p)^{(4-y_i)}
$$

where probability of success of item $i$ for individual $p$ is as:

$$
p_{pi}=\frac{\text{exp}(\mu_i+\lambda_i\theta_p)}{1+\text{exp}(\mu_i+\lambda_i\theta_p)}
$$

Note:

-   Shown with a logit link function (but could be any link)
-   Shown in slope/intercept form (but could be distrimination/difficulty for unidimensional items)
-   Could also include asymptote parameters ($c_i$ or $d_i$)

## Binomial Item Response Model

The item response model, put into the PDF of the binomial is then:

$$
P(Y_{pi}|\theta_p)=\begin{pmatrix}n_i\\Y_{pi}\end{pmatrix}(\frac{\text{exp}(\mu_i+\lambda_i\theta_p)}{1+\text{exp}(\mu_i+\lambda_i\theta_p)})^{y_{pi}}(1-\frac{\text{exp}(\mu_i+\lambda_i\theta_p)}{1+\text{exp}(\mu_i+\lambda_i\theta_p)})^{4-y_{pi}}
$$

Further, we can use the same priors as before on each of our item parameters

-   $\mu_i$: Normal Prior $N(0, 100)$

-   $\lambda_i$: Normal prior $N(0, 100)$

Likewise, we can identify the scale of the latent variable as before, too:

-   $\theta_p \sim N(0,1)$

## `model{}`  for the Binomial Model in Stan

```{stan, output.var='display'}
#| echo: true
model {
  lambda ~ multi_normal(meanLambda, covLambda); // Prior for item discrimination/factor loadings
  mu ~ multi_normal(meanMu, covMu);             // Prior for item intercepts
  theta ~ normal(0, 1);                         // Prior for latent variable (with mean/sd specified)
  for (item in 1:nItems){
    Y[item] ~ binomial(maxItem[item], inv_logit(mu[item] + lambda[item]*theta));
  }
}
```

Here, the binomial [item response function]{.underline} has two arguments:

-   The **first** part: (`maxItem[Item]`) is the number of "trials" $n_i$ (here, our maximum score minus one – 4)
-   The **second** part: (`inv_logit(mu[item] + lambda[item]*theta)`) is the probability from our model ($p_i$)

The data `Y[item]` must be:

-   Type: integer
-   Range: 0 through `maxItem[item]`

## `parameters{}` for the Binomial Model in Stan

```{stan, output.var='display'}
#| echo: true
parameters{
  vector[nObs] theta;                // the latent variables (one for each person)
  vector[nItems] mu;                 // the item intercepts (one for each item)
  vector[nItems] lambda;             // the factor loadings/item discriminations (one for each item)
}
```

No changes from any of our previous slope/intercept models

## `data{}` for the Binomial Model in Stan

```{stan, output.var='display'}
#| echo: true
data {
  int<lower=0> nObs;                     // number of observations
  int<lower=0> nItems;                   // number of items
  array[nItems] int<lower=0> maxItem;    // maximum value of Item (should be 4 for 5-point Likert)
  
  array[nItems, nObs] int<lower=0>  Y;   // item responses in an array

  vector[nItems] meanMu;                 // prior mean vector for intercept parameters
  matrix[nItems, nItems] covMu;          // prior covariance matrix for intercept parameters
  
  vector[nItems] meanLambda;             // prior mean vector for discrimination parameters
  matrix[nItems, nItems] covLambda;      // prior covariance matrix for discrimination parameters
}
```

Note:

-   Need to supply `maxItem` (maximum score minus one for each item)

-   The data are the same (integer) as in the binary/dichotomous item syntax

## Preparing Data for Stan

```{r}
#| fig-width: 18
#| eval: true
library(tidyverse)
library(kableExtra)
library(here)
library(blavaan)
self_color <- c("#DB7093", "#AFEEEE", "#3CB371", "#9370DB", "#FFD700")
root_dir <- "posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code"
dat <- read.csv(here(root_dir, 'conspiracies.csv'))
itemResp <- dat[,1:10]
colnames(itemResp) <- paste0('item', 1:10)
conspiracyItems = itemResp
```

```{r}
#| echo: true
#| eval: true
# note: data must start at zero
conspiracyItemsBinomial = conspiracyItems
for (item in 1:ncol(conspiracyItemsBinomial)){
  conspiracyItemsBinomial[, item] = conspiracyItemsBinomial[, item] - 1
}

# check first item
table(conspiracyItemsBinomial[,1])
```

```{r}
#| echo: true
#| eval: true
# determine maximum value for each item
maxItem = apply(X = conspiracyItemsBinomial,
                MARGIN = 2, 
                FUN = max)
maxItem
```

## Binomial Model Stan Call

```{r}
#| echo: true
modelBinomial_samples = modelBinomial_stan$sample(
  data = modelBinomial_data,
  seed = 12112022,
  chains = 4,
  parallel_chains = 4,
  iter_warmup = 5000,
  iter_sampling = 5000,
  init = function() list(lambda=rnorm(nItems, mean=5, sd=1))
)
```

## Discriminatin/Difficulty Parameterization

The slope/intercept form

## Resources

-   [Dr. Templin's slide](https://jonathantemplin.github.io/Bayesian-Psychometric-Modeling-Course-Fall2022/lectures/lecture04d/04d_Modeling_Observed_Polytomous_Data#/binomial-model-data-block)
