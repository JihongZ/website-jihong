---
title: "Lecture 08"
subtitle: "Generalized Measurement Models: Modeling Observed Data II"
author: "Jihong Zhang"
institute: "Educational Statistics and Research Methods"
title-slide-attributes:
  data-background-image: ../Images/title_image.png
  data-background-size: contain
execute: 
  echo: false
  eval: false
format: 
  revealjs:
    logo: ../Images/UA_Logo_Horizontal.png
    incremental: false  # choose "false "if want to show all together
    transition: slide
    background-transition: fade
    theme: [simple, ../pp.scss]
    footer:  <https://jihongzhang.org/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553>
    scrollable: true
    slide-number: true
    chalkboard: true
    number-sections: false
    code-line-numbers: true
    code-annotations: below
    code-copy: true
    code-summary: ''
    highlight-style: arrow
    view: 'scroll' # Activate the scroll view
    scrollProgress: true # Force the scrollbar to remain visible
    mermaid:
      theme: neutral

#bibliography: references.bib
---

# Review Previous Class

## In Previous Class...

1.  We introduced a self-reported survey data, called `Conspiracy Theories`

-   The scale has 10 items with 5-point Likert scale response
-   Items have varied item difficult and Positive skewed item response distribution

2.  We talked about using if factor analysis is a proper method when normality assumption is violated
3.  We checked the item characteristics curves

```{r}
#| fig-width: 18
#| eval: true
library(tidyverse)
library(here)
self_color <- c("#DB7093", "#AFEEEE", "#3CB371", "#9370DB", "#FFD700")
root_dir <- "posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code"
dat <- read.csv(here(root_dir, 'conspiracies.csv'))
itemResp <- dat[,1:10]
colnames(itemResp) <- paste0('item', 1:10)
conspiracyItems = itemResp
itemResp |> 
  rownames_to_column("ID") |> 
  pivot_longer(-ID, names_to = "Item", values_to = "Response") |> 
  mutate(Item = factor(Item, levels = paste0('item', 1:10)),
         Response = factor(Response, levels = 1:5)) |> 
  ggplot() +
  geom_bar(aes(x = Response, fill = Response, group = Response), 
           position = position_stack()) +
  facet_wrap(~ Item, nrow = 1, ncol = 10) +
  theme_bw() +
  scale_fill_manual(values = self_color)
```

## Today's Lecture Objectives

1.  Quickly go through our R code file so far
2.  Show different modeling specifications for different types of item response data
3.  Show how parameterization differs for standardized latent variables vs. marker item scale identification

## Posterior Distribution for Item Parameters

Before moving onto the latent variable, let's note the posterior distribution of item parameters (for a single item):

$$
f(\mu_i,\lambda_i,\psi_i\mid\boldsymbol{Y})\propto f(\boldsymbol{Y}\mid\mu_i,\lambda_i,\psi_i)f(\mu_i, \lambda_i,\psi_i)
$$

where $f(\boldsymbol{Y}\mid\mu_i,\lambda_i,\psi_i)$ is the (joint) posterior distribution of the parameters for item $i$ conditional on the adta

$f(\boldsymbol{Y}\mid\mu_i,\lambda_i,\psi_i)$ is the distribution we defined for our observed data:

$$
f(\boldsymbol{Y}\mid\mu_i,\lambda_i,\psi_i)\sim N(\mu_i+\lambda_i\theta_p, \psi_i)
$$

$f(\mu_i, \lambda_i, \psi_i)$ is the (joint) prior distribution for each of the parameters, which, are independent:

$$
f(\mu_i, \lambda_i, \psi_i) = f(\mu_i)f(\lambda_i)f(\psi_i)
$$

## Investigating the Latent Variables

The estimated latent variables are then:

```{r}
#| eval: true
save_dir <- "~/Library/CloudStorage/OneDrive-Personal/2024 Spring/ESRM6553 - Advanced Multivariate Modeling/Lecture07"
modelCFA_samples <- readRDS(here(save_dir, "model01.RDS"))
modelCFA_samplesFail <- readRDS(here(save_dir, "model01fail.RDS"))
modelCFA_samplesFix <- readRDS(here(save_dir, "model03fix.RDS"))
```

```{r}
#| eval: true
modelCFA_samples$summary('theta')
```

## EAP Estimates of Latent Variables

![](/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code/EAP_Estimates.png)

## Density of EAP Estimates

![](/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code/EAP_Estimates_density.png)

## Density of 500 Posterior draws of θ

![](/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code/Theta_Draws_density.png)

## Comparing Posterior Distribution for Individuals

![](/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code/Theta_density_ThreeIndividuals.png)

## Comparing EAP Estimate with Posterior SD

![](/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code/EAP_SD.png)

## Comparing EAP Estimate with Sum Score

![](/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code/EAP_SumScore.png)

## Comparing EAP Estimate with Factor Score by `lavaan`

![](/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code/EAP_FactorScore.png)

## Posterior Distribution for Person Parameter θ

The posterior distribution of the person parameters (the latent variable for a single person):

$$
f(\theta_p\mid\boldsymbol{Y}) \propto f(\boldsymbol{Y} \mid \theta_p)f(\theta_p)
$$

Here:

-   $f(\theta_p\mid\boldsymbol{Y})$ is the posterior distribution of the latent variable conditional on the observed data;

-   $f(\boldsymbol{Y} \mid \theta_p)$ is the model (data) likelihood:

    $$
    f(\boldsymbol{Y} \mid \theta_p) = \prod_{i=1}^{I} f(Y_i\mid\theta_p)
    $$

    -   $f(Y_i \mid \theta_p)$ is one individual item's data likelihood: $f(Y_i \mid \theta_p) \sim N(\mu_i+\lambda_i\theta_p, \psi_i)$;

-   $f(\theta_p) \sim N(0,1)$ is the prior distribution for the latent variable – $\theta_p$

# Measurement Model Estimation Fails

## Recall: Stan's `parameters {}` Block

```{stan, output.var='display'}
#| echo: true
parameters {
  vector[nObs] theta;                // the latent variables (one for each person)
  vector[nItems] mu;                 // the item intercepts (one for each item)
  vector[nItems] lambda;             // the factor loadings/item discriminations (one for each item)
  vector<lower=0>[nItems] psi;       // the unique standard deviations (one for each item)   
}
```

Here, the parameterization of $\lambda$ (factor loadings / discrimination parameters) can lead to problems in estimation

-   The issue is $\lambda_i\theta_p=(-\lambda_i)(-\theta_p)$

    -   Depending on the random starting values of each of these parameters (per Markov chain), a given chain may converge to different region with others

-   To demonstrate, we will start with different random number seend

    -   Currently use 09102022: works fine

    -   Change to 25102022: big problem

## New Samples Syntax

```{r}
#| echo: true
#| code-line-numbers: "|3"
modelCFA_samplesFail = modelCFA_stan$sample(
  data = modelCFA_data,
  seed = 25102022,
  chains = 4,
  parallel_chains = 4,
  iter_warmup = 1000,
  iter_sampling = 2000
)
```

Convergence fail with maximum of $\hat R$ as:

```{r}
#| eval: true
max(modelCFA_samplesFail$summary(.cores =4)$'rhat')
```

## Why Convergence Failed

-   The issue of exchangeable likelihood: $\lambda_i\theta_p=(-\lambda_i)(-\theta_p)$

```{r}
#| eval: true
#| echo: false
modelCFA_samplesFail$summary('lambda', .cores =4) |> mutate(across(-variable, \(x) round(x, 3)))
```

## Posterior Trace Plots of λ

Unfortunately, we are unable to extract initial values that were generated automatically by `cmdstanr`. See [here](https://mc-stan.org/cmdstanr/reference/fit-method-init.html) for more details.

![](/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code/Posterior_lambda.png){fig-align="center"}

## Posterior Density Plots of λ

![](/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code/Posterior_lambda_density.png){fig-align="center"}

## Examining Latent Variable

```{r}
#| eval: true
#| echo: false
print(modelCFA_samplesFail$summary('theta', .cores = 4) |> mutate(across(c(mean, median), \(x) round(x, 3))), 
      n = Inf)
```

## Posterior Trace Plots of θ

![](/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code/Posterior_theta_traceplot.png){fig-align="center"}

## Posterior Density Plots of θ

![](/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code/Posterior_theta_density.png)

## Fixing Convergence

`Stan` allows starting values to be set via `cmdstanr`

-   Documentation is very lacking, I can show you one method but it may change in the future.

Alternatively:

-   In `Stan` file, restrict $\lambda$ to be positive: `vector<lower=0>[nItems] lambda;`

-   Can also choose prior that has strictly positive range (like log-normal distribution)

-   Note: the restriction on the space of $\lambda$ will not permit truely negative values

    -   Not ideals as negative $\lambda$ values are informative as a problem with data

    ```{stan, output.var='display'}
    #| echo: true
    parameters {
      vector[nObs] theta;                // the latent variables (one for each person)
      vector[nItems] mu;                 // the item intercepts (one for each item)
      vector<lower=0>[nItems] lambda;    // the factor loadings/item discriminations (one for each item)
      vector<lower=0>[nItems] psi;       // the unique standard deviations (one for each item)   
    }
    ```

## Setting Starting (Inital) Values in `Stan`

Starting values (initial values) are the first values used when an MCMC chain starts

-   In `Stan`, by default, parameters are randomly started between -2 and 2

    -   Bounded parameters are transformed so they are unbounded in the algorithm

-   What we need:

    -   Randomly start all $\lambda$ parameters so that they converge to the $\lambda_i\theta_p$ mode

    -   As opposed to the (-$\lambda_i$)(-$\theta_p$) mode

## `cmdstanr` Syntax for Initial Values

Add the init option to the `$sample()` function of the `cmdstanr` object:

```{stan, output.var='display'}
#| echo: true
# set starting values for some of the parameters
modelCFA_samples2fixed = modelCFA_stan$sample(
  data = modelCFA_data,
  seed = 25102022,
  chains = 4,
  parallel_chains = 4,
  iter_warmup = 2000,
  iter_sampling = 2000, 
  init = function() list(lambda=rnorm(nItems, mean=10, sd=2))
)
```

The `init` option can be specified as a function, here, randomly starting each $\lambda$ following a normal distribution

## Initialization Process

See the lecture R syntax for information on how to confirm starting values are set.

You should find the initial values using `$init()` function

```{r}
#| eval: true
#| echo: true
modelCFA_samplesFix$init()
```

## Final Results: Parameters

```{r}
#| eval: true
#| echo: true
# Check convergence
max(modelCFA_samplesFix$summary()$'rhat')

print(modelCFA_samplesFix$summary(c("mu", "lambda", "psi"),.cores = 4) |> mutate(across(c(mean, median), \(x) round(x, 3))), n = Inf)
```

## Comparing Results with different inits

![](/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code/EAP_mu_lambda_psi_theta.png){fig-align="center"}

Correlation of all parameters across both algorithm runs:

```{r}
#| echo: true
#| eval: true
cor(modelCFA_samplesFix$summary(variables = c("mu", "lambda", "psi", "theta"), .cores = 4)$mean,
    modelCFA_samples$summary(variables = c("mu", "lambda", "psi", "theta"), .cores = 4)$mean)
```

## Wrapping up

Today, we showed how to model observed data using a normal distribution

-   Assumptions of Confirmatory Factor Analysis

    -   Not appropriate for our data

    -   May not be appropriate for many data sets

-   We will have to keep our loading/discrimination parameters positive to ensure converges to the same posterior mode

    -   This will continue through the next types of data

    -   

## Next Class

-   Next up, categorical distributions for observed data

    -   More appropriate for these data as they are discrete categorical responses

## Resources

-   [Dr. Templin's slide](https://jonathantemplin.github.io/Bayesian-Psychometric-Modeling-Course-Fall2022/lectures/lecture04b/04b_Modeling_Observed_Data#/title-slide)
