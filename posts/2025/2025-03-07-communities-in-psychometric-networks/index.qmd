---
title: "Communities in Psychometric Networks?"
institute: | 
  Educational Statistics and Research Methods (ESRM) Program*
  
  University of Arkansas
date: "2025-03-07"
draft: false
bibliography: references.bib
image: index_files/figure-html/plot-1.png
tbl-cap-location: top
categories:
  - R
  - Network
citation:
  type: webpage
  issued: 2025-03-07
execute: 
  warning: false
  message: false  
format: 
  html:
    code-tools: false
    code-line-numbers: false
    toc-depth: 2
    toc-expand: true
    code-fold: true
    code-summary: "Click this to see R code"
---

::: objectives
## Overview {.unnumbered}

A friend of mine recently asked me one question about network community: in her recent research, a network without community defined has different estimation with the one with community define. In this blog, I try to dive a little deeper into community issues in network analysis.

This [blog](https://psych-networks.com/r-tutorial-identify-communities-items-networks/) aims to talk about varied aspects of *community detection* in psychometric network analysis, including the following questions:

1.  What is "node community"?
2.  Why we need communities of nodes in network analysis?
3.  How to identify communities?
:::

```{r plot, cache=TRUE}
#| fig-height: 7
#| fig-width: 10
library("psychonetrics")
# Load bfi data from psych package:
library("psychTools")
data(bfi)

# Also load dplyr for the pipe operator:
library("dplyr")

# Let's take the agreeableness items, and gender:
ConsData <- bfi |> 
  select(A1:A5, gender) |> 
  na.omit() # Let's remove missingness (otherwise use Estimator = "FIML)

# Define variables:
vars <- names(ConsData)[1:5]

# Saturated estimation:
mod_saturated <- ggm(ConsData, vars = vars)

# Run the model:
mod_saturated <- mod_saturated |> runmodel()

# Labels:
labels <- c(
  "indifferent to the feelings of others",
  "inquire about others' well-being",
  "comfort others",
  "love children",
  "make people feel at ease")
# We can also fit an empty network:
mod0 <- ggm(ConsData, vars = vars, omega = "zero")

# Run the model:
mod0 <- mod0 |> runmodel()

# To automatically add along modification indices, we can use stepup:
mod1 <- mod0 |> stepup()

# Let's also prune all non-significant edges to finish:
mod1 <- mod1 |> prune()

qgraph::qgraph(getmatrix(mod1, "omega"),
               layout="spring",
               groups = labels,
               title = "Big 5 agreeableness",
               theme = "Borkulo")
```

## Big Problem in the network

[A]{.bigger}s said in Eiko's post [@friedTutorialHowIdentify2016] and I cited here â€“ authors sometimes *over-interpret* the network visualization of their data that some meaningful modules exist. This over-interpretation may have Type I error (mistakenly cluster nodes with actually weak connections in a community) or Type II error (fail to cluster nodes with strong connection into a community). In other words, researchers found that relying on visual inspection of network structure can not obtain reliable conclusion about which nodes should be clustered together and which ones should not be clustered, especially in a complicated network structure (say \> 20 nodes).

Identification of node clusters is not a new topic, which is typically called "*Community Detection*" in graph theory [@fortunatoCommunityDetectionGraphs2010]. This problem arises due to a phenomenon called "Community Structure"[@girvanCommunityStructureSocial2002] or "Clustering" was found in varied types of networks. This community structure has two characteristics:

1.  Heterogeneity of node degree: nodes with high degree (more neighbors/ high betweenness) coexist with nodes with low degree.
2.  Heterogeneity of edge strength: high concentrations of edges with certain "group" of nodes even though those "groups" are visual inspected.

Given this community structure, *Community* (or called clusters or modules) is defined as **groups of nodes which probably share common properties and / or play similar roles within the graph** [@fortunatoCommunityDetectionGraphs2010]. This is actually a very broad definition which does not answer what are "common properties" and "similar roles" in a network graph. The reason of this vagueness is because of variety of network in different areas.

For example, within a social network with each person as node and social relationship between two people as edge, social communities could be *family*, *company*, or any other social groups. In this case, "common properties" of social community may be emotional pattern due to the family education, behavioral pattern under company policy. In protein-protein interaction networks, communities are likely to group proteins having the same specific function within the cell. In the graph of the World Wide Web they may correspond to groups of web pages dealing with the same or related topics.

[B]{.bigger}ack to the community conceptualization in psychological research, especially psychiatry, the community is associated with *syndromes* or *comorbidity*. According to [Wikipedia](https://en.wikipedia.org/wiki/Syndrome), a syndrome is a set of medical signs and symptoms which are correlated with each other and often associated with a particular disease or disorder. Some psychological syndromes may present comorbidity of symptoms, which refers to simultaneous presence of two or more psychological symptoms in a same individual within a time frame (co-occurring, concurrent). In a earlier paper of @borsboomStructureDSM2002, Borsboom took the example of DSM-IV network and claimed that "commodity appears to be, at least partially and in particular for mood, anxiety, and substance abuse disorders, encoded in the structure of the diagnostic criteria themselves" [@borsboomStructureDSM2002], but he did not link the "commodity" of a cluster of highly-connected symptoms to the statistical concept "community" in network graph. It is until the paper of @cramerComorbidityNetworkPerspective2010, the symptom community as a local connectivity was considered as *syndromes*, while symptoms clusters are interconnected by individual symptoms ("bridge symptoms") that form the boundaries between the various basic syndromes of psychiatric disorders [@goekoopNetworkViewPsychiatric2014]. @goekoopNetworkViewPsychiatric2014 also emphasized that the presence of bridge symptoms that connects symptom clusters (communities / syndromes) plays a key role that can be identified as potential targets for treatment.

## Community Detection Algorithm

There are many previous studies comparing different community detection [@yangComparativeAnalysisCommunity2016; @gatesMonteCarloEvaluation2016]. @christensenComparingCommunityDetection2024 recently conducted a Monte-Carlo simulation study compared various node community detection algorithm in the framework of latent factor analysis. To interpret the results, @christensenComparingCommunityDetection2024 even created a [Shiny App](https://alex-christensen.shinyapps.io/community_detection_results/) to interactive present the results.

| Algorithm | Feature | Citation |
|------------------------|------------------------|------------------------|
| Walktrap | random walks | @ponsComputingCommunitiesLarge2006 |
| Infomap | random walks | @rosvallMapsRandomWalks2008 |
| Fast-greedy | hierarchical clustering; modularity-based | @clausetFindingCommunityStructure2004 |
| Louvian | hierarchical clustering; modularity-based | @blondelFastUnfoldingCommunities2008 |
| Leading Eigenvalue | eigenvalue | @newmanModularityCommunityStructure2006 |
| Label Propagation | non-parametric | @raghavanLinearTimeAlgorithm2007 |
| Spinglass | non-parametric | @reichardtStatisticalMechanicsCommunity2006 |
| Edge Betweenness | non-parametric | @girvanCommunityStructureSocial2002 |
| Triangulated Maximally Filtered Graph (TMFG) | score based | @massaraNetworkFilteringBig2017 |
| Parallel Analysis | EFA |  |

: Different types of community detection algorithm {#tbl-algorithm tbl-colwidths="\[35,40,25\]"}

@tbl-algorithm shows the list of community detection algorithms and their features. In the framework of psychometric assessment (\< 50 nodes, balanced item number per factor), the best-performing algorithms are GLASSO with unidimentional adjustment, Louvian, Fast-greedy, Walktrap, and parallel analysis. The evaluation criteria include:

1.  The percentage of correct number of factors (PC)
2.  Mean absolute error (MAE; the average absolute deviation away from the correct number of factors)
3.  Mean bias error (MBE; the average deviation away from the correct number of factors)

Assume $N$ is the total number of simulated sample date sets (Replication), $K$ is the population number of factors/communities, and $\hat{K}$ is the estimated number of factors/communities. $\mathbb{I}(\cdot)$ is the indicator function so that $\mathbb{I}(\hat{K}, K) = 1$ if $\hat{K} = K$ and $\mathbb{I}(\hat{K}, K) = 0$ otherwise. The three evaluation criteria are defined as:

$$
\mathrm{PC} = \frac{1}{N} \sum_{i=1}^{N} \mathbb{I}(\hat{K}_i, K_i)
$$

$$
\mathrm{MAE} = \frac{1}{N} \sum_{i=1}^{N} |\hat{K}_i - K_i|
$$

$$
\mathrm{MBE} = \frac{1}{N} \sum_{i=1}^{N} (\hat{K}_i - K_i)
$$

```{r}
## K is a vector of population number of factors with the length of number replications
## K_hat is a vector of estimate number of factors with the length of number replications
cal_pc <- function(K, K_hat) {
  N <- length(K)
  pc <- sum(K_hat == K) / N
  return(pc)
}
cal_mae <- function(K, K_hat) {
  N <- length(K)
  mae <- sum(abs(K_hat - K)) / N
  return(mae)
}
cal_mbe <- function(K, K_hat) {
  N <- length(K)
  mbe <- sum(K_hat - K) / N
  return(mbe)
}
```

## Example: Accuracy and Stability for Fast Greedy and Walktrap

For illustration, we can examine the differences in accuracy and stability between the fast-greedy method and the walktrap method due to the sampling error. The sample data is the Big-five questionnaire dataset (N=2800). The bootstrapping resampling method with 100 replications and 10% total sample size is used for the analysis.

For evaluation criteria, the standardized deviation (SD) for two methods was used to examine the stability; PC, MAE, MBE for two methods were used to examine the accuracy.

```{r exp1, cache=TRUE}
#| warning: false
#| message: false
#| code-fold: false
#| code-summary: "Community Detection for Bootstrapping Resampled Samples"
library(igraph) # For community detection
library(foreach) # For parallel computing
library(doParallel) # For core registration

# Load bfi data from psych package:
Data <- bfi |> 
  select(A1:A5, C1:C5, E1:E5, N1:N5, O1:O5) |> 
  na.omit()

ten_perc_N = floor(nrow(Data) / 10) # Number of cases for 10% sample size
N_replications <- 100 # Number of bootstrapping resampling

# Function to get the number of communities by fast-greedy and walktrap
get_resampling_community_n <- \(dat, i, size) {
  set.seed(1234 + i)
  sampled_cases <- dat[sample(x = 1:nrow(dat), size = size), ]
  # Define variables:
  vars <- names(dat)
  
  # Saturated estimation:
  mod_sparsed <- ggm(sampled_cases, vars = vars) |> runmodel()  |>  stepup() |>  prune()
  
  ## Get edge weights
  omega_mat <- getmatrix(mod_sparsed, "omega")
  
  ## Convert to igraph object from adjcent matrix
  ggm_igraph <- graph_from_adjacency_matrix(adjmatrix = abs(omega_mat), 
                                            weighted = TRUE, 
                                            mode = "undirected")
  
  ## Apply Walktrap / Fast Greedy Community Detection Algoritm 
  ggm_wt <- cluster_walktrap(ggm_igraph)
  ggm_fg <- cluster_fast_greedy(ggm_igraph)
  
  ## Get number of detected communities 
  return(
    c(K_wt = length(ggm_wt), 
      K_fg = length(ggm_fg),
      size = size, 
      seed = (1234 + i))
  )
}

cl <- makePSOCKcluster(detectCores() - 1)
registerDoParallel(cl)
res <- foreach(i = 1:N_replications, 
               .packages = c("psychonetrics", "igraph"),
               .combine = "rbind") %dopar% 
  get_resampling_community_n(dat = Data, i = i, size = ten_perc_N)
stopCluster(cl)
```

```{r}
K_wt <- res[,1]
K_fg <- res[,2]
report <- data.frame(
  Algorithm = c("Walktrap", "Fast-Greedy"),
  PC = sapply(list(K_wt, K_fg), \(x) cal_pc(x, rep(5, length(x))) ),
  MAE = sapply(list(K_wt, K_fg), \(x) cal_mae(x, rep(5, length(x))) ),
  MBE = sapply(list(K_wt, K_fg), \(x) cal_mbe(x, rep(5, length(x))) )
)
kableExtra::kable(report)
```

```{r}
summary_tbl <- data.frame(
  Algorithm = c("Walktrap", "Fast-Greedy"),
  Min = sapply(list(K_wt, K_fg), min),
  Max = sapply(list(K_wt, K_fg), max),
  Mean = sapply(list(K_wt, K_fg), mean),
  SD = sapply(list(K_wt, K_fg), sd)
)
kableExtra::kable(summary_tbl)
```

::: callout-note
## Interpretation

Overall, the fast-greedy method performs better than the walktrap method given its higher value of PC and lower absolute values of MAE and MBE across 100 bootstrapping re-sampling iterations with the $\frac{1}{10}$ sample size. The fast-greedy is also more stable than the walktrap given smaller variability ($\mathrm{SD_{FG}}=.65$; $\mathrm{SD_{WT}}=1.13$).
:::

### Sample Size Effect on Community Detection

We can further examine the effect of sample size on the community detection. The sample sizes are 100, 200, 500, 1000, and 2000. The bootstrapping resampling method with 100 replications is used for variability in each condition.

```{r exp1_n, cache=TRUE}
#| warning: false
#| code-fold: show
cl <- makePSOCKcluster(detectCores() - 1)
registerDoParallel(cl)
res_byN <- foreach(N = c(100, 200, 500, 1000, 2000), 
        .packages = c("psychonetrics", "igraph"),
        .combine = "rbind") %:%
  foreach(i = 1:N_replications, .combine = "rbind") %dopar%
  get_resampling_community_n(dat = Data, i = i, size = N)
stopCluster(cl)
```

```{r}
#| label: fig-comm-detect-n
#| fig-cap: "Community Detection by Sample Size"

library(tidyverse)
res_byN_tbl <- as.data.frame(res_byN) 

res_byN_smy <- res_byN_tbl |> 
  group_by(size) |> 
  summarise(
    wt_mean = mean(K_wt),
    fg_mean = mean(K_fg),
    wt_sd = sd(K_wt),
    fg_sd = sd(K_fg)
  )

library(ggplot2)
library(tidyr)
res_byN_smy |> 
  tidyr::pivot_longer(cols = -size, names_to = "Algorithm", values_to = "K") |>
  tidyr::separate(Algorithm, into = c("Algorithm", "Stat"), sep = "_") |> 
  tidyr::pivot_wider(names_from = Stat, values_from = K) |> 
  ggplot(aes(x = size, color = Algorithm, group = Algorithm)) +
  geom_path(aes(y = mean), linewidth = 1.5) +
  geom_point(aes(y = mean), size = 3) +
  geom_errorbar(aes(ymin = mean - 1.96*sd, ymax = mean + 1.96*sd), 
                width = 70, linewidth = 1.1, alpha = .7) +
  labs(title = "Community Detection by Sample Size",
       x = "Sample Size",
       y = "Number of Communities") +
  scale_color_manual(values = c("royalblue", "tomato"), labels = c("Fast-Greedy", "Walktrap")) +
  scale_x_continuous(breaks = c(100, 200, 500, 1000, 2000)) +
  theme_minimal()
```

As shown in @fig-comm-detect-n, for both methods, as sample size gets larger, the number of communities detected by both methods tends to align with the theoretical number of communities, $K = 5$. From N = 100 to N = 200 has strong increase in the accuracy of the number of communities detected, while from N = 200 to N = 500 has moderate improvement in the number of communities detected. After N = 500, the number of communities detected is stable.