---
title: "Lecture 05: Data Transformation and Summary"
subtitle: "Using `dplyr` package"
date: "2025-02-05"
execute: 
  eval: true
  echo: true
  warning: false
output-location: default
code-annotations: below
format: 
  html:
    code-tools: true
    code-line-numbers: false
    code-fold: false
    number-offset: 0
  uark-revealjs:
    scrollable: true
    chalkboard: true
    embed-resources: false
    code-fold: false
    number-sections: false
    footer: "ESRM 64503 - Lecture 05: Text Data Analysis"
    slide-number: c/t
    tbl-colwidths: auto
    output-file: slides-index.html
---

::: objectives
## Overview

1.  String and Text Data
2.  Basic Data Summary Using `dplyr`
3.  Case Study of Trump Tweets
4.  AI + Text Analysis?
:::

# String and Text Data

## Special Characters

-   Strings (character-type variable) can be enclosed in either single or double quotes.

    ```{r}
    class("some text")
    ```

-   If using both within a string, escape necessary quotes using `\`.

    ```{r}
    cat("I'm a student")
    cat('He says "it is ok!"')
    cat("I'm a student. He says \"it is ok\"!")
    ```

::: callout-tip
`cat()`: Prints the string output directly and escape special symbols.
:::

-   Use `\` to escape special characters such as `\n` (new line) and `\t` (tab).

```{r}
cat("To show \\ , we need to use two of them.")
cat("You are my student\nI am your teacher/")
```

------------------------------------------------------------------------

## Unicode and Other Special Characters

-   `\n` and `\t`: Represent new line and tab space.
-   `\u` followed by Unicode code points allows special character insertion.
-   This [Unicode Website](https://c.r74n.com/unicode/bullets) can copy and paste freely

```{r}
test <- "This is the first line. \nThis the \t second line with a tab."
cat(test)
cat("\u03BC \u03A3 \u03B1 \u03B2")
cat("❤ ♫ ⦿")
```

------------------------------------------------------------------------

## Basic String Operations

```{r}
library(tidyverse)  # Or use stringr: install.packages("stringr")
```

### Creating and Manipulating Strings

```{r}
tweet1 <- "MAKE AMERICA GREAT AGAIN!"
tweet2 <- "Congratulations @ClemsonFB! https://t.co/w8viax0OWY"

(tweet <- c(tweet1, tweet2))
```

#### Change Case

```{r}
tolower(tweet)
toupper(tweet)
```

#### Calculate String Length

```{r}
nchar(tweet1)
str_length(tweet)  # `stringr` alternative
```

------------------------------------------------------------------------

### Splitting and Combining Strings

#### Splitting Strings by Pattern

```{r}
str_split(tweet, pattern = " ")
str_split_1(tweet2, pattern = " https://")  # Returns a vector instead of a list
```

#### Combining Strings

```{r}
tweet.words <- unlist(str_split(tweet, pattern = " "))
str_c(tweet.words, collapse=" ")
```

# Data Transformation

## Overview

-   Data often needs transformation to fit the desired analysis or visualization.
-   Learn to use the `dplyr` package for data transformation.
-   Explore the `nycflights13` dataset.

[Required Libraries]{.redcolor}

```{r}
library(nycflights13) # `nycflights13` for the dataset flights.
library(tidyverse)
glimpse(flights)
```

-   `glimpse()` for the quick screening of the data.

## `dplyr` Core Functions

-   `filter()`: Subset rows based on conditions.
-   `arrange()`: Reorder rows.
-   `select()`: Choose columns by name.
-   `mutate()`: Create new columns.
-   `summarize()`: Aggregate data.
-   `group_by()`: group data for summarization.

------------------------------------------------------------------------

::: callout-important
## Operators
-   All following operators will return `TRUE` or `FALSE`:
    -   Comparison operators: `==`, `!=`, `<`, `<=`, `>`, `>=`.
    -   Logical operators: `&`, `|`, `!`.
    -   Inclusion operator: `%in%`, i.e., `3 %in% c(1,2,3)` will return `TRUE`

    ```{r}
    #| eval: false
    flights |> filter(month != 1) # Months other than January
    flights |> filter(month %in% 1:10) # Months other than Nov. and Dec.
    ```
:::

### `filter()`: select cases based on condtions

-   Use `|>` (Preferred, a vertical line symbol `|` plus a greater symbol `>`) or `%>%` to chain multiple functions/operations (shortcut: {{< kbd mac=Command+Shift+M win=Ctrl+Shift+M >}}).
-   **Aim**: Select flights on January 1st:
    -   Compare whether month,day equal to "1" (Januarary) and "1" (1<sup>st</sup> day), respectively

    ```{r}
    jan1 <- flights |> filter(month == 1, day == 1)
    jan1
    ```


------------------------------------------------------------------------

### `arrange()`: Arranging Rows

-   Sort flights by departure delay:

```{r}
flights[, c("year", "month", "day", "dep_delay")] |> arrange(dep_delay)
```

-   Descending order:

```{r}
flights[, c("year", "month", "day", "dep_delay")] |> arrange(desc(dep_delay))
```

------------------------------------------------------------------------

### `select()`: Selecting Columns

-   Choose specific columns:

```{r}
flights |> select(year, month, day)

## is equivalent to 
# flights[, c("year", "month", "day")]
```

-   Helper functions for selecting the variables: `starts_with()`, `ends_with()`, `contains()`, `matches()`, `num_range()`.

------------------------------------------------------------------------

### `mutate()`: Adding New Variables

-   Create new columns:

```{r}
flights_sml <- flights |> select(
  year:day,
  ends_with("delay"),
  distance,
  air_time
)

flights_sml |> mutate(
  gain = dep_delay - arr_delay,
  speed = distance / air_time * 60
) |> 
  select(year:day, gain, speed)
```

-   Use `transmute()` to keep only the new variables.

```{r}
flights_sml |> transmute(
  gain = dep_delay - arr_delay,
  speed = distance / air_time * 60
) 
```

------------------------------------------------------------------------

#### `mutate()` and `case_when`: Create new categories

-   `case_when`: The left hand side (LHS) determines which values match this case. The right hand side (RHS) provides the replacement value.
    -   The LHS inputs must evaluate to logical vectors.
    -   The RHS inputs will be coerced to their common type. In following case, it is character type

```{r}
x <- c(1:10, NA)
categorized_x <- case_when(
  x %in% 1:3 ~ "low",
  x %in% 4:7 ~ "med",
  x %in% 7:10 ~ "high",
  is.na(x) ~ "Missing"
)
categorized_x
```

-   Combine `mutate()` and `case_when()` to create a new categorical variable
    -   `na.rm = TRUE` to ignore the NA values when calculating the mean

```{r}
flights |> 
  mutate(
    Half_year = case_when(
      month %in% 1:6 ~ 1,
      month %in% 6:12 ~ 2,
      is.na(month) ~ 999
    )
  ) |> 
  group_by(year, Half_year) |> 
  summarise(
    Mean_dep_delay = mean(dep_delay, na.rm = TRUE)
  )
```

------------------------------------------------------------------------

### `summarize()` with `group_by()`: Summarizing Data

-   Calculate average delay by destination:

```{r}
by_dest <- flights |> group_by(dest)
delay <- summarize(by_dest,
  count = n(),
  dist = mean(distance, na.rm = TRUE),
  delay = mean(arr_delay, na.rm = TRUE)
)
```

-   Visualize the results:

```{r}
ggplot(data = delay, mapping = aes(x = dist, y = delay)) +
  geom_point(aes(size = count), alpha = 1/3) +
  geom_smooth(se = FALSE)
```

------------------------------------------------------------------------

### `group_by()` and `ungroup()`: Grouping and Ungrouping

-   Group data by multiple variables:

```{r}
by_day <- flights |> group_by(year, month, day)
by_day |> 
  summarize(avg_dep_delay = mean(dep_delay, na.rm = TRUE))
```

-   Ungroup data:

```{r}
by_day <- ungroup(by_day)
```

## More dplyr Functions

-   `rename()`: Renaming Columns.
-   `relocate()`: Reorder column position.
-   `distinct()`: Choose distinct/unique cases.
-   `count()`: Create group size.
-   `slice()`: Select cases or random sampling.
-   `rowwise()`: Perform calculations for each row.

------------------------------------------------------------------------

### `rename()`: Renaming Columns

```{r}
# Rename columns
df <- flights |> rename(
  departure_time = dep_time,
  arrival_time = arr_time,
  departure_delay = dep_delay,
  arrival_delay = arr_delay
)
glimpse(df)
```

------------------------------------------------------------------------

### `relocate()`: Changing Column Order

```{r}
# Move the "year" column after "carrier" column
df |> 
  select(carrier, departure_time, arrival_time, year) |> 
  relocate(year, .after = carrier)
```

------------------------------------------------------------------------

### `distinct()`: Remove Duplicates

-   `unique()` function outputs unique [values]{.redcolor} from a vector.
-   `distinct()` function outputs unique [cases]{.redcolor} from a dataset

```{r}
unique(c(1, 2, 3, 4, 4, 5, 5))
# flights with unique carrier-destination pairs
df |> 
  distinct(carrier, dest)
```

------------------------------------------------------------------------

### `count()`: Quick Grouping & Summarization

```{r}
# Count number of flights per carrier
df |> count(carrier, sort = TRUE)

# equivalent to
if (0) {
df |> 
  group_by(carrier) |> 
  summarise(
    n = n()
  )
}
```

------------------------------------------------------------------------

### `slice()`: Selecting Specific Rows

`slice_*()` family allows you to choose rows based on their positions

```{r}
# Select the first 10 flights
df |> slice(1:10)
```

```{r}
# Select the top 5 flights with the highest departure delay
df |> slice_max(departure_delay, n = 5)
```

```{r}
# Select the 5 flights with the lowest arrival delay
df |> slice_min(arrival_delay, n = 5)
```

------------------------------------------------------------------------

### `slice_sample()`: Random Sampling

```{r}
# Randomly select 5 flights
df |> slice_sample(n = 5)
```

```{r}
# Select 1% random sample
df |> slice_sample(prop = 0.01)
```

------------------------------------------------------------------------

### `rowwise()`: Row-Wise Grouping Operations

-   Similar to `group_by`, but each row/case will be considered as one group

-   When you're working with a rowwise tibble, then dplyr will use `[[` instead of `[` to make your life a little easier.

-   [Assume you want to calculate the mean of variables x, y and c: $\frac{x + y + z}{3}$]{.redcolor}

```{r}
set.seed(1234)
xyz <- tibble(x = runif(6), y = runif(6), z = runif(6))
rowMeans(xyz[, c("x", "y", "z")])
# Compute the mean of x, y, z in each row
xyz |> 
  rowwise() |> 
  mutate(m = mean(c(x, y, z)))
```

```{r}
# Compute the total delay per flight
df |> 
  rowwise() |> 
  mutate(avg_delay_time_perMile = sum(departure_delay, arrival_delay, na.rm = TRUE) / distance,
         .keep = "used")
```

::: callout-tip
`.keep = "used"` retains only the columns used in `...` to create new columns. This is useful for checking your work, as it displays inputs and outputs side-by-side.
:::

## Summary & Takeaways

-   `dplyr` provides powerful tools for data transformation.
-   Combining functions allows for efficient data manipulation.
-   `group_by()` and `summarize()` are key for data aggregation.
-   Functions like `rename()`, `slice()`, `relocate()`, and `case_when()` enhance usability.

# Motivating Example: AI + Text Analysis

## Extract Structural Information from Text

-   Make use of language models to extract key information from a unstructral text file

-   This is not a step-by-step guide of using LLMs, but a motivating example so that you may want to explore more usage of LLMs in data analysis.

    -   The details of techniques can be found in this [link](https://ellmer.tidyverse.org/articles/structured-data.html).

-   Note that the following code cannot be successfully executed in your local device without ChatGPT account and access to API keys.

    -   Here is a video [tutorial](https://www.youtube.com/watch?v=B_Fbd_vxZyE) for using ChatGPT in R.

## Programming LLMs in R

-   Rather than using ChatBot on the OpenAI website, to programming LLMs for text analysis, I suggested using `ellmer` package (the [manual](https://ellmer.tidyverse.org/)) which was developed by the same person who developed `tidyverse` package.

```{r}
#| cache: true
library(ellmer)
chat <- chat_openai(echo = FALSE, model = "gpt-4o-mini")

chat$extract_data(
  tweet2,
  type = type_object(
    URL = type_string("URL address starting with 'http'")
  )  
)

```

```{r}
#| cache: true
chat$extract_data(
  "My name is Susan and I'm 13 years old. I like traveling and hiking.",
  type = type_object(
    age = type_number("Age, in years."), # extract the numeric information as "age" from the provided text
    name = type_string("Name, Uppercase"), # extract the character information as "name" from the provided text
    hobbies = type_array(
      description = "List of hobbies. Uppercase",
      items = type_string()
    )
  )
)
```

-   Here, `type_*()` specify object types in a way that LLMs can understand and are used for structured data extraction.

## Article Summarisation

```{r}
#| cache: true
library(pdftools)
paper_text <- paste0(pdf_text("example_paper.pdf"), collapse = "\n")

type_summary <- type_object(
  "Summary of the article.",
  author = type_string("Name of the article author"),
  topics = type_array(
    'Array of topics, e.g. ["tech", "politics"]. Should be as specific as possible, and can overlap.',
    type_string(),
  ),
  design = type_string("Summary of research design of the article. One or two paragraphs max"),
  measures = type_string("Key indices in results"),
  finding = type_string("Summary of key findings. One paragraph max")
)

chat <- chat_openai(model = "gpt-4o-mini")
data <- chat$extract_data(paper_text, type = type_summary)
str(data)
cat(data$author)
print(data$topics)
print(data$design)
print(data$measures)
print(data$finding)
```

## Open Sourced Local Distilled Models

-   You can freely download the open source LLM - Llama developed by Meta on this [link](https://ollama.com/).

-   Teaching how to set up the LLMs is out of scope of this class. There are a lot of tutorials that you can use. For example, this [medium post](https://medium.com/@arunpatidar26/run-llm-locally-ollama-8ea296747505).

-   Just showcase how you can extract key information. Llama needs more guide information to extract certain key words than ChatGPT.

```{r}
#| cache: true
chat <- chat_ollama(model = "llama3.2")

chat$extract_data(
  "My name is Jihong and I'm an assistant professor. I like reading and hiking.",
  type = type_object(
    job = type_string("Job"), # extract the numeric information as "age" from the provided text
    name = type_string("Name of the person, uppercase"), # extract the character information as "name" from the provided text
    hobbies = type_array(
      description = "List of hobbies. transform to Uppercase",
      items = type_string()
    )
  )
)  
```

------------------------------------------------------------------------

### Deepseek distilled model

```{r}
#| cache: true
chat <- chat_ollama(model = "deepseek-r1:8b")

Text_to_summarize <- "Results of Paper: Researchers have devised an ecological momentary assessment study following 80 students (mean age = 20.38 years, standard deviation = 3.68, range = 18–48 years; n = 60 female, n = 19 male, n = 1 other) from Leiden University for 2 weeks in their daily lives."

type_summarize_results = type_object(
    N = type_number("Total sample size the study used"),
    Age = type_number("Average age in years"),
    Method = type_string("Assessment for data collection"),
    Participants = type_string("source of data collection"),
    Days = type_string("Duration of data collection")
)
chat$extract_data(
  Text_to_summarize,
  type = type_summarize_results
)
```

# Case Study: Analysis of Trump Tweets

## Download of Trump Tweets

-   For demonstration, we will analyze the tweets from President Donald Trump from 2009 to 2017.

```{r}
library(dslabs) # install.packages("dslabs")
library(tidyverse) 
glimpse(dslabs::trump_tweets)
```

::: callout-note
-   `source`. Device or service used to compose tweet.
-   `id_str`. Tweet ID.
-   `text`. Tweet.
-   `created_at`. Data and time tweet was tweeted.
-   `retweet_count`. How many times tweet had been retweeted at time dataset was created.
-   `in_reply_to_user_id_str`. If a reply, the user id of person being replied to.
-   `favorite_count`. Number of times tweet had been favored at time dataset was created.
-   `is_retweet`. A logical telling us if it is a retweet or not.
:::

## Basic summary of Trump tweets

-   Where the tweets were sent from

```{r}
#| code-fold: false

trump_tweets |> 
  group_by(
    source
  ) |> 
  summarise(N = n()) |> 
  arrange(desc(N))
```

------------------------------------------------------------------------

### Histogram of tweet sources

```{r}
#| code-fold: true
n_source_tbl <- trump_tweets |> 
  group_by(source) |> 
  summarise(
    N = n()
  )
ggplot(data = n_source_tbl) +
  geom_col(aes(x = fct_reorder(source, N), y = N)) +
  geom_label(aes(x = fct_reorder(source, N), y = N, label = N), nudge_y = 500) +
  labs(x = "", y = "") +
  coord_flip()
```

------------------------------------------------------------------------

### The length of each tweet

```{r}
summary(str_length(trump_tweets$text))
```

-   Most tweets have the length from 100 to 150 characters.

-   Filter the tweet less than 20 characters

```{r}
trump_short_tweets <- trump_tweets |> 
  mutate(
    N_characters = str_length(text)
  ) |> 
  filter(N_characters <= 20)
```

## Extract Frequent Words from the Short Tweets

```{r}
trump_short_clean_tweets <- trump_short_tweets |> 
  mutate(
    clean_text = str_remove(text, "@\\S+ ")
  ) |> 
  mutate(
    clean_text2 = str_remove_all(clean_text, "[[:punct:]]") # Remove punctuation
  ) |> 
  select(text, clean_text, clean_text2)
slice_sample(trump_short_clean_tweets, n = 5)
```

Explanation of the Regular Expression:

-   `@` matches the \@ symbol.
-   `\\S+` matches one or more non-whitespace characters (i.e., the username).
-   `str_remove()` removes the matched pattern.

------------------------------------------------------------------------

-   Top 20 most frequently used words

```{r}
#| code-fold: true

trump.split <- unlist(str_split(trump_short_clean_tweets$clean_text2, 
                                pattern = " "))

word.freq <- as.data.frame(sort(table(word = tolower(trump.split)), decreasing = T))

word_freq_tbl <- word.freq |> 
  mutate(word = trimws(word)) |> 
  filter(
    word != "",
    !(word %in% stopwords::stopwords("en")),
    !(word %in% c("I", "&amp;", "The", "-", "just"))
  )
```

```{r}
ggplot(data = word_freq_tbl[1:20, ]) +
  geom_col(aes(x = fct_reorder(word, Freq), y = Freq)) +
  geom_label(aes(x = fct_reorder(word, Freq), y = Freq, label = Freq)) +
  labs(x = "", y = "") +
  coord_flip()
```

## Reference

1.  [Tidyverse Skills for Data Science](https://jhudatascience.org/tidyversecourse/get-data.html#images)
2.  [Practical Data Processing for Social and Behavioral Research Using R](https://books.psychstat.org/rdata/image-data.html)
