---
title: "Lecture 08: Block Design (2)"
subtitle: "Experimental Design in Education"
date: "2025-03-07"
date-modified: "`{r} Sys.Date()`"
execute: 
  eval: true
  echo: true
  warning: false
  message: false
format: 
  html:
    code-tools: true
    code-line-numbers: false
    code-fold: false
    code-summary: "Click to see R code"
    number-offset: 1
    fig.width: 10
    fig-align: center
    message: false
    grid:
      sidebar-width: 350px
  uark-revealjs:
    chalkboard: true
    embed-resources: false
    code-fold: false
    number-sections: true
    number-depth: 1
    footer: "ESRM 64503"
    slide-number: c/t
    tbl-colwidths: auto
    scrollable: true
    output-file: slides-index.html
    mermaid:
      theme: forest    
---

::: objectives
## Overview {.unnumbered}

1.  Review Block Design
2.  Randomized Block Design with R Programming[^1]
3.  Completely Randomized Block Design with R Programming[^2]
:::

[^1]: Please check [here](https://www.geeksforgeeks.org/randomized-block-design-with-r-programming/) for the original post

[^2]: Please check [here](https://www.geeksforgeeks.org/completely-randomized-design-with-r-programming/?ref=ml_lbp) for the original post

```{r setup, include=FALSE}
library(tidyverse)
library(gt)
```

## Features of RCBD

::: discussion
Think about our example of the effects of teaching methods (M1, M2, M3, M4) and measurement forms (F1, F2, F3, F4) to math performance.
:::

1.  In a **randomized complete block design (RCBD)**, each block size is the same and is equal to the number of treatments (i.e. factor levels or factor level combinations).
    -   For those who using saming form (same block), they will be randomly assigned to 4 teaching methods.
2.  Each treatment will be randomly assigned to exactly one experimental unit (students) within every block.
3.  The assignments of treatment levels (teaching methods) to the experimental units (students) have to be done within each block separately.

## Random Effects of RCBD

1.  It is important to mention that blocks are usually (but not always) treated as random effects as they typically represent the population of all possible blocks.
2.  In other words, the mean comparison among specific blocks is not of interest.
3.  However, the variation between blocks must be incorporated into the model.

## Exercises

:::: discussion
-   A poultry experiment was run to investigate the effect of **diet** and **antibiotics** on egg production. They evaluated 2 diets of interest and 2 specific antibiotics that are on the market. The feed and antibiotic were combined and used to fill the feeding trays in barns. They chose 3 poultry farms at random and randomly assigned the combinations of diet and antibiotic to 4 barns within each farm. Total egg production by the chickens was recorded after 4 weeks.
    1.  What is the experimental design (hint: think about the randomization process)?
    2.  Identify which factors are treatment and block.

::: {.callout-note .mohu}
## Answer

a.  RCBD.
b.  treatment: combination of Diet and Antibiotic; block: Farms.
:::
::::

## Other Aspects of the RCBD 

-   The RCBD utilizes an *additive model* â€“ one in which there is *no interaction* between treatments and blocks. The error term in a randomized complete block model reflects how the treatment effect varies from one block to another.

-   Both the treatments and blocks can be considered as *random effects* rather than fixed effects, if the levels were selected at random from a population of possible treatments or blocks. We consider this case later, but it does not change the test for a treatment effect.

-   What are the consequences of not blocking if we should have? Generally the **unexplained error** in the model will be larger, and therefore the test of the treatment effect less powerful.

-   How to determine the sample size in the RCBD? 

    -   The [Operating Characteristic (OC) curve](https://online.stat.psu.edu/stat503/lesson/3/3.2#paragraph--298) approach can be used to determine the number of blocks to run. The number of blocks, *b*, represents the number of replications (they are exchangable from the point of researchers' view). The power calculations that we looked at before would be the same, except that we use b rather than n, and we use the estimate of error, $\sigma^2$, that reflects the improved precision based on having used blocks in our experiment. So, the major benefit or power comes not from the number of replications but from the error variance which is much smaller because you removed the effects due to block.

## Example 1: Tutoring session

:::::: columns
::: {.column width="60%"}
-   Letâ€™s look at a simple example:
-   Research question: **What is the effect of time of day of** **tutoring session on midterm grades?**
-   The Primary Investigator (PI) of the study wants to control for tutor, believing some tutors may be better in the subject matter than others. Thus, they design a completely randomized block design.
-   Each tutor works with students in the morning and afternoon.
    -   In this example, student select their favorite tutor, but are then randomly assigned to either a morning (AM) or afternoon (PM) session.
    -   200 total students: 91 in the morning, 109 in the afternoon
:::

:::: {.column width="40%"}
![](images/clipboard-3708810514.png)

::: callout-note
DV: Midterm Score (in cells)
:::
::::
::::::

------------------------------------------------------------------------

### Example 1: Variables and Null Hypothesis

:::::: columns
::: {.column width="60%"}
-   IV: Time (ğ‘= 2 )
    -   [2 levels]{style="color: orange"}: AM and PM
-   Nuisance factor: Tutor (ğ‘= 4 )
    -   [4 levels]{style="color: purple"}: Booby, Julia, Monique, and Ned
-   DV: Midterm Score
-   Null hypothesis pertaining to the IV of interest:
    -   $H_0:\mu_{ğ´ğ‘€} = \mu_{ğ‘ƒğ‘€} â†’ a= 2$
-   We will also have a null hypothesis pertaining to the blocking factor:
    -   $H_0:\mu_{Bobby} = \mu_{Julia} = \mu_{Monique} =\mu_{Ned} â†’ b=4$
    
-   Two Nulls = two values of $F_{obs}$, two values of $F_{crit}$, two decisions
:::

:::: {.column width="40%"}
![](images/clipboard-3708810514.png)

::: callout-note
DV: Midterm Score (in cells)
:::
::::
::::::

------------------------------------------------------------------------

### Example 1: Sum of Squares 

::::: columns
::: {.column width="70%"}
-   IV: Time (ğ‘= 2 )

-   Nuisance factor: Tutor (ğ‘= 4 )

-   DV: Midterm Score

-   Now:

    -   $ğ‘†ğ‘†_{Total} =\color{red}{ğ‘†ğ‘†_{ğ‘€ğ‘œğ‘‘ğ‘’ğ‘™}}+\color{purple}{ğ‘†ğ‘†_{ğµğ‘™ğ‘œğ‘ğ‘˜}}+\color{blue}{ğ‘†ğ‘†_{ğ¸ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿ}}$

-   Thus, we can partition the effects into three parts:

    -   Sum of squares due to [treatments (IV = Time)]{style="color: red"},

    -   Sum of squares due to the [blocking factor]{style="color: purple"},

    -   and Sum of squares due to [error]{style="color: blue"}.

-   We **do not** model an **interaction** with blocked designs. (we will talk about it later.)
:::

::: {.column width="30%"}
![](images/clipboard-624916915.png)
:::
:::::

------------------------------------------------------------------------

### Example 1: Mean of Squares and F-statistics

-   IV: Time (ğ‘= 2 )
-   Nuisance factor: Tutor (ğ‘= 4 )
-   DV: Midterm Score
-   Model: $ğ‘†ğ‘†_{Total} =\color{red}{ğ‘†ğ‘†_{ğ‘€ğ‘œğ‘‘ğ‘’ğ‘™}}+\color{purple}{ğ‘†ğ‘†_{ğµğ‘™ğ‘œğ‘ğ‘˜}}+\color{blue}{ğ‘†ğ‘†_{ğ¸ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿ}}$
-   ANOVA table:

![](images/clipboard-505786804.png)

------------------------------------------------------------------------

### Example 1: Sum of Square Formula

$$
SS_{Total}=\sum_{i=1}^{n}(y_{ij}-\bar{y}_{..})^2
$$

-   This is the same as before: take each individual score ($y_{ij}$), subtract the grand mean ($\bar{y}$), and square it $(y_{ij}-\bar{y}_{..})^2$

-   Do this for everyone and then sum over all people $\sum_{i=1}^{n}(y_{ij}-\bar{y}_{..})^2$

-   However, when calculating IV: $SS_{Model}$, $SS_{Block}$, $SS_{error}$, we need to compute "**marginal means**"

    -   A **marginal mean** is the mean for one level of the variable, ignoring the other variable

------------------------------------------------------------------------

### Example 1: Marginal Means

-   A **marginal mean** is the mean for one level of the variable, ignoring the other variable

::::: columns
::: {.column width="50%"}
For example:

-   The AM marginal mean is the average of all studentsâ€™ midterm scores in the morning, ignoring who they have as a tutor $$
    \bar{y}_{AM.} = 22.95
    $$
-   The Bobby marginal mean is the average of all studentsâ€™ midterm scores who had Bobby as a tutor, ignoring time of day $$
    \bar{y}_{.Bobby} = 11.91
    $$
:::

::: {.column width="50%"}
![](images/clipboard-560146152.png)
:::
:::::

------------------------------------------------------------------------

### Example 1: SS for Total and Model

$$
SS_{Total} = \sum_{i=1}^{n}(y_{ij}-\bar{y}_{..})^2=15060.48
$$

$$
SS_{Model(time)} = \sum_{a=1}^{a}n_a(\bar{y}_{a.}-\bar{y}_{..})^2=4489.02
$$

-   where $n_a$ is the group size for AM/PM and $\bar{y}_{a.}$ are the marginal means for AM and PM {22.95, 13.43}

-   This is similar to how we computed $ğ‘†ğ‘†_{ğ‘€ğ‘œğ‘‘ğ‘’ğ‘™}$ before: marginal group mean subtract off the grand mean and square it. Sum over all groups.

$$
SS_{Block} = \sum_{b=1}^{b}n_{b}(\bar{y}_{.b}-\bar{y}_{..})^2=3239.43
$$

-   Technically, the blocking factor is just another IV (but we are not interested in or is not within the scope of research question).

    -   $ğ‘†ğ‘†_{ğ¸ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿ} = ğ‘†ğ‘†_{ğ‘‡ğ‘œğ‘¡ğ‘ğ‘™}âˆ’ ğ‘†ğ‘†_{ğ‘€ğ‘œğ‘‘ğ‘’ğ‘™} +ğ‘†ğ‘†_{ğµğ‘™ğ‘œğ‘ğ‘˜}$ = 7332. 03

------------------------------------------------------------------------

### Example 1: Details of ANOVA Table

-   Then, we can fill out the ANOVA table:

![](images/clipboard-122981133.png)

::: callout-note
Under $\alpha=.05$, for "Model" factor â€“ Time, we have $df_{Model}$ = 1, $df_{error} = 195$: $F_{crit}=3.89$ so sig.

Similarly, for "Blocking" - Tutor, we have $df_{block}$ = 3, $df_{error} = 195$: $F_{crit}=2.65$ so sig.
:::

------------------------------------------------------------------------

### Interpretation

-   A randomized block design was used to test the effect of tutoring time on midterm scores. For each tutor, participants were randomly assigned to either morning (ğ‘› = 91 ) or afternoon (ğ‘›= 109 ) tutoring sessions.
-   The effect of tutoring time was significant $(ğ¹(1,195) = 119. 39, ğ‘<. 001 ,\eta^2_{ğ‘‡ğ‘–ğ‘šğ‘’} =. 298$) with a large effect. Using a Tukeyâ€™s test, morning is significantly higher than afternoon sessions (ğ‘ \<. 05 ).
-   The effect of the blocking factor, tutor, was significant ($ğ¹(3 , 195) = 28. 72 ,ğ‘< . 001 ,\eta^2_{ğ‘‡ğ‘¢ğ‘¡ğ‘œğ‘Ÿ} =. 215$) with a large effect. Using a Tukeyâ€™s test, Moniqueâ€™s students were significantly higher than other students, and Bobbyâ€™s students were significantly lower than other students in the midterm scores (ğ‘\<. 05 ).

## Example 2: Hardness Reading[^exp2]

[^exp2]: Please check the original post here: [STAT 503](https://online.stat.psu.edu/stat503/lesson/4/4.1)

- In this example we wish to determine whether 4 different tips (the treatment factor) produce different (mean) hardness readings on a Rockwell hardness tester. 
    -   The **treatment factor** is the design of the tip for the machine that determines the hardness of metal. The tip is one component of the testing machine.

::: callout-note
## The Rockwell hardness test
**The Rockwell hardness test** is a hardness test based on indentation hardness of a material. The Rockwell test measures the depth of penetration of an indenter under a large load (major load) compared to the penetration made by a preload (minor load).
:::

- To conduct this experiment we assign the tips to an experimental unit; that is, to a **test specimen** (called a coupon), which is a piece of metal on which the tip is tested.
    -   The **blocking factor** is the block of test specimens. The test specimens are blocks of metal that are similar in hardness. The test specimens are used to block the variation in hardness of the metal from the variation in the tips.

------------------------------------------------------------------------

### Example 2: Block Design - CRD

- If the structure were a completely randomized experiment (CRD) that we discussed in lecture 7, we would assign the tips to a random piece of metal for each test. In this case, the test specimens would be considered a source of nuisance variability. 

```{r}
#| code-fold: true
set.seed(1234)
data.frame(
  Metal = paste0("Metal", 1:8),
  Tip = rep(c("Tip1", "Tip2", "Tip3", "Tip4"), each = 2),
  Hardness = sample(seq(9, 10, by =.1), 8)
) |> 
  kableExtra::kable()
```

------------------------------------------------------------------------

### Example 2: Block Design - RCBD

- If we conduct this as a blocked experiment, we would assign all four tips to the same test specimen, randomly assigned to be tested on a different location on the specimen. Since each treatment occurs once in each block, the number of test specimens is the number of replicates.

- Back to the hardness testing example, the experimenter may very well want to *test the tips* (treatment) across *specimens* (block) of various hardness levels. This shows the importance of blocking. To conduct this experiment as a RCBD, we assign all 4 tips to each specimen.

    -  In this experiment, each specimen is called a â€œblockâ€; thus, we have designed a more homogenous set of experimental units on which to test the tips.
    

------------------------------------------------------------------------

### Example 2: Block Design Table - RCBD

:::: columns
::: column
-   Suppose that we use b = 4 blocks as shown in the table below:

-   We are primarily interested in testing the equality of treatment means, but now we have the ability to remove the variability associated with the nuisance factor (the blocks) through the grouping of the experimental units prior to having assigned the treatments.
:::

::: column
```{r}
#| code-fold: true
tribble(
  ~`1`, 	~`2`, 	~`3`, 	~`4`,
  "Tip 3", 	"Tip 3", 	"Tip 2",	"Tip 1",
  "Tip 1", 	"Tip 4", 	"Tip 1",	"Tip 4",
  "Tip 4", 	"Tip 2", 	"Tip 3",	"Tip 3",
  "Tip 2", 	"Tip 1", 	"Tip 4",	"Tip 3"
) |> 
  gt() |> 
  tab_header(
    title = "The Hardness Testing Experiment",
    subtitle = "Randomized Complete Block Design"
  ) |> 
  tab_spanner(
    label = "Test Coupon (Block)",
    columns = everything()
  ) |> 
  tab_options(
    table.width = px(500),
    table.font.size = px(20)
  )
```
:::
::::





::: callout-important
Notice the two-way structure of the experiment. Here we have four blocks and within each of these blocks is a random assignment of the tips within each block.
:::

------------------------------------------------------------------------

### Example 2: ANOVA Results (1)

-   Remember, the hardness of specimens (coupons) is tested with 4 different tips.

```{r}
#| code-fold: true
library(here)
dat <- read.csv(here::here("posts/Lectures/2025-01-13-Experiment-Design/Lecture08", "tip_hardness.csv"))
kableExtra::kable(dat)
```

------------------------------------------------------------------------

### Example 2: ANOVA Results (2)

-   Here is the output from R `aov()`. We can see four levels of the Tip and four levels for Coupon:

```{r}
#| code-fold: true
dat$Tip <- factor(dat$Tip)
dat$Coupon <- factor(dat$Coupon)
fit_exp2 <- aov(Hardness ~ Tip + Coupon, data = dat)
```

::: callout-note
-   The Analysis of Variance table shows three degrees of freedom for Tip three for Coupon, and the residual (error) degrees of freedom is nine. 

-   The ratio of mean squares of treatment over error gives us an F ratio that is equal to 14.44 which is highly significant since it is greater than the .001 percentile of the F distribution with three and nine degrees of freedom.

-   Our 2-way analysis also provides a test for the block factor, Coupon. The ANOVA shows that this factor is also significant with an F-test = 30.94. So, there is a large amount of variation in hardness between the pieces of metal. 

-   This is why we used specimen (or coupon) as our blocking factor. We expected in advance that it would account for a large amount of variation. By including block in the model and in the analysis, we removed this large portion of the variation, such that the residual error is quite small. By including a block factor in the model, the error variance is reduced, and the test on treatments is more powerful.
:::

### Example 2: ANOVA Results (3)

-   The test on the block factor is typically not of interest except to confirm that you used a good blocking factor. The results are summarized by the table of means given below.

```{r}
#| code-fold: true
cbind(
dat |> 
  group_by(Tip) |>
  summarize(
    N_Tip = n(),
    Hardness_Tip = mean(Hardness))
,
dat |> 
  group_by(Coupon) |>
  summarize(
    N_Coupon = n(),
    Hardness_Coupon = mean(Hardness)) 
) |> 
  kableExtra::kable()
```





## Experiment 3: Plan Fertilizer[^3]

[^3]: Please check the original post here: [STAT 502 Analysis of Variance and Design of Experiments](https://online.stat.psu.edu/stat502/lesson/7/7.3)

::::: columns
::: column
1.  In a greenhouse experiment, there was a single factor (fertilizer) with 4 levels (i.e. 4 treatments), six replications, and a total of 24 experimental units (potted plants). Suppose the image below is the greenhouse bench (viewed from above) that was used for the experiment.

2.  To use CBD, we need to randomly assign each of the treatment levels to 6 potted plants. To do this, we first assign numbers to the physical position of the pots on the bench. Each column of plants will be use one Fertilizer.

3.  To further expand it to RCBD, we need to put them into different farms (say we have six farms). Each farms will have 4 plans with each will use one type of fertilizer.
:::

::: column
![](images/clipboard-1929254708.png){width="100%"}
:::
:::::

------------------------------------------------------------------------

### Read in R Data

-   After saving the **exp1_data.csv** into the same directory of your R file. You should be able to import dataset from Files Panel in Rstudio:

![](images/clipboard-1848460327.png)

![](images/clipboard-1116098669.png)

------------------------------------------------------------------------

### Block Design

```{r}
#| include: false
library(tidyverse)
dat <- tribble(
  ~Block, ~Fertilizer, ~Height,
"Block1", "Control", 19.5,
"Block2", "Control", 20.5,
"Block3", "Control", 21,
"Block4", "Control", 21,
"Block5", "Control", 21.5,
"Block6", "Control", 22.5,
"Block1", "F1", 25,
"Block2", "F1", 27.5,
"Block3", "F1", 28,
"Block4", "F1", 28.6,
"Block5", "F1", 30.5,
"Block6", "F1", 32,
"Block1", "F2", 22.5,
"Block2", "F2", 25.2,
"Block3", "F2", 26,
"Block4", "F2", 26.5,
"Block5", "F2", 27,
"Block6", "F2", 28,
"Block1", "F3", 27.5,
"Block2", "F3", 28,
"Block3", "F3", 29.2,
"Block4", "F3", 29.5,
"Block5", "F3", 30,
"Block6", "F3", 31
)
dat$Plant <- 1:nrow(dat)
# write.csv(dat, "exp1_data.csv")
```

```{r}
#| echo: true
gt(dat, 
   rownames_to_stub = TRUE, 
   groupname_col = "Block", 
   row_group_as_column = TRUE) |> 
   tab_options(table.width = px(300))
```

------------------------------------------------------------------------

### ANOVA Results

:::::: columns
::: column
-   Let us obtain the ANOVA table for the **RCBD**. To run the model with Block Design in R we can use the `aov()` function with the formula:

`<Outcome>~<Treatment>+<Block>`.

```{r}
fit_rcbd <- aov(Height ~ Fertilizer + Block, data = dat)				 
summary(fit_rcbd)
```
:::

::: column
-   For comparison, let us obtain the ANOVA table for the **CRD** for the same data. We use the following R code with the formula:

`<Outcome>~<Treatment>`

```{r}
fit_cbd <- aov(Height ~ Fertilizer, data = dat)				 
summary(fit_cbd)
```
:::

::: discussion
## Interpretation {.unnumbered}

Comparing the two ANOVA tables, we see that the MSE in RCBD has decreased considerably in comparison to the CRD. This reduction in MSE can be viewed as the partition in SSE for the CRD (61.033) into SSBlock (53.32) + SSE (7.715). The potential reduction in SSE by blocking is offset to some degree by losing degrees of freedom for the blocks. But more often than not, is worth it in terms of the improvement in the calculated *F*-statistic. In our example, we observe that the *F*-statistic for the treatment has increased considerably for RCBD in comparison to CRD. It is reasonable to assume that the result from the RCBD is more valid than that from the CRD as the MSE value obtained after accounting for the block to block variability is a more accurate representation of the random error variance.
:::
::::::

## Experiment 3: Planet Fertilizer

-   **Background**: Testing new fertilizers in different types of crops.
-   **Design**: Crops are divided into 3 different types (blocks). These blocks are again divided into 3 fertilizers (F1, F2, and NF) that are used on those crops. The figure of study design can be visualized as follows:

![](https://media.geeksforgeeks.org/wp-content/uploads/20201014082316/RCBDexample.PNG)

```{r}
corn <- factor(rep(c("corn", "rice", "wheat"), each = 3)) 
fert <- factor(rep(c("f1", "f2", "nf"), times = 3)) 
corn
fert
```

------------------------------------------------------------------------

### Experiment 3: Data

```{r}
y <- c(6, 5, 6, 
       4, 4.2, 5, 
       5, 4.4, 5.5) 

# y is the months the crops were healthy 
results <- data.frame(y, corn, fert) 
kableExtra::kable(results)
```

------------------------------------------------------------------------

### Experiment 3: ANOVA Results

```{r}
fit <- aov(y ~ fert+corn, data = results)				 
summary(fit)
```

::: discussion
## Interpretation {.unnumbered}

The value of *Mean Sq* shows is blocking really necessary for the experiment. Here *Mean Sq for residuals* `0.1078 << 0.7011`, thus blocking is necessary will give precise values for the experiment. Though this method is a little debatable yet useful. The significance value of every experiment is given by the person taking the experiment. Here lets consider significance has 5% i.e 0.05. The Pr(\>F) value is `0.0553>0.05`. Thus the hypothesis is accepted for the crops experiment. Letâ€™s consider one more experiment.
:::


## Experiment 4: Performance of Students

-   **Background:** Comparing the performances of students (male and female) blocks in different environments (at home and at college). To represent this experiment in the figure will be as follows:

![](https://media.geeksforgeeks.org/wp-content/uploads/20201015122147/RCBDexample2.PNG)

-   Where *AC*: At College, *AH*: At Home

```{r}
stud <- factor(rep(c("male", "female"), each = 2)) 
perf <- factor(rep(c("ah", "ac" ), times = 2)) 
perf
```

```{r}
y <- c(5.5, 5, 
	4, 6.2) 

# y is the hours students 
# studied in specific places 
results <- data.frame(y, stud, perf) 

fit <- aov(y ~ perf+stud, data = results)				 
summary(fit)
```

-   **Explanation**: The value of Mean Sq is `0.7225<<1.8225`,i.e, here blocking wasnâ€™t necessary. And as Pr value is 0.642 \> 0.05 (5% significance) and the hypothesis is accepted - there is no sufficient evidence suggesting females and males have significant differences in performance.

## Effectiveness of Health Promotion Programs

::: discussion
## Background {.unnumbered}
-   Researchers are interested in comparing the effectiveness of three health promotion programs with nursing students.
-   The researcher has the following research question: *Which of the three health promotion programs are most effective at reducing unhealthy coping behaviors?*
    1.   Unhealthy coping behavior is measured as a composite score from the â€œPoor Coping Behaviorâ€ survey (PCB). High scores on the PCB indicate higher levels of unhealthy coping behaviors. Low scores indicate low levels of unhealthy coping behaviors. PCB scores can range from 0 (no unhealthy behaviors) to 100 (multiple unhealthy behaviors at high frequency and high intensity).
    2.   The researcher thinks that the health promotion programs for nursing students may have an effect on academic and well-being outcomes.
    3.   However, gender and status (traditional vs. non-traditional student) differences may influence the effectiveness of health promotion programs.
:::

------------------------------------------------------------------------

### Blocking Factors?

-   The researcher has a sample of 200 nursing students from the state of Arkansas. 50 students are assigned to each program: Program A, Program B, and Program C. In addition, 50 students are assigned to a control group that receives the status quo educational model.

```{r}
data.frame(
  Health_Program = c("Program A", "Program B", "Program C", "Control"),
  N = c(50, 50, 50, 50)
) |> kableExtra::kable()
```


### Blocking Factors?

::: panel-tabset
## Visualization

![](images/clipboard-1200507560.png)

## Table

![](images/clipboard-2055304403.png)
:::
    

------------------------------------------------------------------------

### Factors

1.   What is the dependent variable? â†’ [PCB SCORES]{.mohu}
2.   What is the independent variable of interest? â†’ [HEALTH PROGRAM (4 LEVELS)]{.mohu}
3.   What is (are) the confounding variables, that the researcher might statistically control for? â†’ [`GENDER`, `STATUS`]{.mohu}
4.   What is (are) the blocking factors? â†’  [`Schools`, `Classes`]{.mohu}

