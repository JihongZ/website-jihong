---
title: "Lecture 02: General Linear Model"
subtitle: "Descriptive Statistics and Basic Statistics"
author: "Jihong Zhang*, Ph.D"
institute: | 
  Educational Statistics and Research Methods (ESRM) Program*
  
  University of Arkansas
date: "2024-08-18"
sidebar: false
execute: 
  echo: true
format: 
  html: 
    page-layout: full
    toc: true
    toc-depth: 2
    lightbox: true
    code-fold: true
  uark-revealjs:
    chalkboard: true
    embed-resources: false
    code-fold: true
    number-sections: true
    number-depth: 1
    footer: "ESRM 64503: Lecture 02 - Descriptive Statistics"
    slide-number: c/t
    tbl-colwidths: auto
    output-file: slides-index.html

#jupyter: python3
---

## Learning Objectives

1.  Install Class Project **ESRM64503**
2.  Univariate Descriptive Statistics
    -   Central tendency: Mean, Median, Mode
    -   Variation/Spread: Standard deviation (SD), Variance, Range
3.  Bivariate descriptive statistics
    -   Correlation
    -   Covariance
4.  Types of variable distributions
    -   Marginal
    -   Joint
    -   Conditional
5.  Bias in estimators

## Installation of *ESRM64504* R package

```{r}
#| code-fold: show
#| eval: false
pak::pak("JihongZ/ESRM64503") # Install the Github package
pak::pak("JihongZ/ESRM64503", upgrade = TRUE) # If you already install the package, try to upgrade
```

## Test *ESTM64503* Package

```{r}
#| message: true
#| output-location: column
#| code-fold: show
#| code-summary: 'package version'
library(ESRM64503)
devtools::package_info("ESRM64503") # Make sure the version number is 2024.08.20
```

```{r}
#| message: true
#| output-location: column
#| code-fold: show
#| code-summary: 'homework information'
homework() # You can call "homework()" function to access homework info
```

## Data Files of *ESRM64503*

```{r}
#| output-location: column
#| code-fold: show
#| code-summary: 'Data dataSexHeightWeight automate loaded'
dataSexHeightWeight # You should find data named "dataSexHeightWeight" already loaded 
```

```{r}
#| code-fold: show
#| code-summary: 'Type ? to check variable information of data'
?dataSexHeightWeight
```

## Data for Today's Lecture

-   To help demonstrate the concepts of today's lecture, we will be using a toy data set with three variables

    -   **Female (Gender)**: Coded as Male (= 0) or Female (= 1)

    -   **Height**: in inches

    -   **Weight**: in pounds

-   The goal of lecture 02 will be to build a general **linear model** that predicts a person's weight

    -   **Linear (regression) model**: a statistical model for an outcome that uses a linear combination (a weighted sum) of one or more predictor variables to produce an estimate of an observation's predicted value

    -   $$
        \mathbb{y} = \beta_0+\beta_1 \mathbf{X}
        $$

-   All models we learnt today will follow this framework.

## Recoding Variables

```{r}
<<<<<<< HEAD
library(ESRM64504) # INSTALL: pak::pak("JihongZ/ESRM64504")
library(kableExtra) # INSTALL: pak::pak("JihongZ/ESRM64504")
=======
library(ESRM64503) # INSTALL: pak::pak("JihongZ/ESRM64503")
library(kableExtra)
>>>>>>> b33a03c (edit name)
dataSexHeightWeight$female = dataSexHeightWeight$sex == "F"
kable(dataSexHeightWeight,
      caption = 'toy data set') |> 
  kable_styling(font_size = 30)
```

# Descriptive Statistics

## Quick inspection I

-   Check (1) if any case has **missing** value (2) **distributions** for continuous and categorical variables

```{r}
#| code-fold: show
#| output-location: column
table(complete.cases(dataSexHeightWeight))

```

```{r}
#| code-fold: show
#| output-location: column
dataWithMissing <- dataSexHeightWeight
dataWithMissing[11, 2] <- NA
table(complete.cases(dataWithMissing))
```

```{r}
#| code-summary: "Distribution of continous variables"
psych::describe(dataSexHeightWeight[,-1], omit = TRUE, trim = 0) |> kable(digits = 3)
```

## Quick Inspect II

```{r}
#| code-summary: "Distribution of categorical variables"
table(dataSexHeightWeight$female)
```

## Visualization: Pairwise Scatterplot

```{r}
pairs(dataSexHeightWeight[, c('female', 'heightIN', 'weightLB')])
```

## Histograms of Height and Weight

::: columns
::: {.column width="50%"}
```{r}
#| fig-cap: "Pairwise Scatter Points"
hist(dataSexHeightWeight$weightLB, main = 'Weight', xlab = 'Pounds')
```
:::

::: {.column width="50%"}
```{r}
hist(dataSexHeightWeight$heightIN, main = 'Height', xlab = 'Inches')
```
:::
:::

## Descriptive Statistics

-   First, we can inspect each variable individually (**marginal distribution**) through a set of descriptive statistics

    -   Visual way: histogram plot or density plot

    -   Statistical way: Central tendency and Variability

        -   Mean, Median, Mode

        -   SD, Range

-   Second, we can also summarize the **joint (bivariate) distribution** of two variables through a set of descriptive statistics:

    -   **Joint vs. Marginal**: joint distribution describes more than one variable simultaneously

    -   Common bivariate descriptive statistics:

        -   Correlation and covariance

## Descriptive Statistics for Toy Data: Marginal

```{r}
library(dplyr)
## wide-format marginal description
wide_marginal_desp <- dataSexHeightWeight |> 
  summarise(across(c(heightIN, weightLB, female), list(mean = mean, sd = sd, var = var)))
```

```{r}
library(tidyr)
wide_marginal_desp |> 
  pivot_longer(everything(), names_to = "Variable", values_to = "Value") |> 
  separate(Variable, sep = "_", into = c("Variable", "Stats")) |> 
  pivot_wider(names_from = Stats, values_from = Value) |> 
  kable(digits = 3)
```

## Descriptive Statistics for Toy Data: Joint

```{r}
cor_cov_mat <- matrix(nrow = 3, ncol = 3)
colnames(cor_cov_mat) <- rownames(cor_cov_mat) <- c("heightIN", "weightLB", "female")
cov_mat <- cov(dataSexHeightWeight[, c("heightIN", "weightLB", "female")])
cor_mat <- cor(dataSexHeightWeight[, c("heightIN", "weightLB", "female")])
## Assign values
cor_cov_mat[lower.tri(cor_cov_mat)] <- cor_mat[lower.tri(cor_mat)]
cor_cov_mat[upper.tri(cor_cov_mat)] <- cov_mat[upper.tri(cov_mat)]
diag(cor_cov_mat) <- diag(cov_mat)
kable(cor_cov_mat, digits = 3)
```

-   Note:

    -   Diagonal: Variance

    -   Above Diagonal (upper triangle): Covaraince

    -   Below Diagonal (lower triangle): Correlation

-   **Question:** What we can tell regarding the relationships among three variables?

# Variance

## Re-examining the Concept of Variance

-   Variability is a central concept in advanced statistics

    -   In multivariate statistic, covariance is also central

-   Two formulas for the variance (about the same when $N$ is larget):

    ::: columns
    ::: {.column width="50%"}
    $$
    S^2_Y= \frac{\Sigma_{p=1}^{N}(Y_p-\bar Y)}{N-1}
    $$ {#eq-unbiased-var}
    :::

    ::: {.column width="50%"}
    $$
    S^2_Y= \frac{\Sigma_{p=1}^{N}(Y_p-\bar Y)}{N}$$ {#eq-biased-var}
    :::
    :::

-   @eq-unbiased-var: **Unbiased** or "sample"

-   @eq-biased-var: **Biased/ML** or "population"

Here: $p$ = person;

## Biased vs. Unbiased Variability

```{r}
set.seed(1234)
population_points <- rnorm(10000, 0, 1)
sample_points <- sample(population_points, size = 200, replace = FALSE)

population_mean <- mean(population_points)
population_sd <- sd(population_points)
sample_mean <- mean(sample_points)
sample_sd_biased <- sqrt(var(sample_points) * 9 / 10)
sample_sd_unbiased <- sd(sample_points)

```

<<<<<<< HEAD
**Take home note**: Unbiased variance estimators can get the estimate of variance closer to the population variance than the biased one.
=======
## Biased VS. Unbiased Estimator of Variance (Cont.)

```{r}
#| message: false
#| output-location: column
#| code-fold: show
library(ggplot2)
variance_mat |> 
  as.data.frame() |> 
  pivot_longer(-sample_size) |> 
  ggplot() +
  geom_line(aes(x = sample_size, y = value, color = name), linewidth = 1.1) +
  labs(x = "Sample Size", y = "Estimates of Variance") +
  scale_color_manual(values = 1:3, labels = c("Population Variance", "Sample Biased Variance (ML)", "Sample Unbiased Variance"), name = "Estimator") +
  theme_classic() +
  theme(text = element_text(size = 25)) 
```

**Take home note**: When sample size is small, unbiased variance estimators can get the estimate of variance closer to the population variance than the biased one.

## Interpretation of Variance

-   The variance describes the spread of a variable in squared units (which come from $(Y_p - \bar Y)^2$ term in the equation)

-   Variance: **the average squared distance of an observation from the mean**

    -   For the toy sample, the **variance of height** is 55.358 inches squared

    -   For the toy sample, the **variance of weight** is 3179.095 pounds squared

    -   The **variance of female** — not applicable in the sample way!

        -   How is the sample equally distributed across different groups: 50/50 -\> largest variance

-   Because squared units are difficult to work with, we typically use the standard deviation – which is reported in units

-   Standard deviation: the average distance of an observation from the mean

    -   SD of Height: 7.44 inches

    -   SD of Weight: 56.383 pounds

## Variance/SD as a More General Statistical Concept

-   Variance (and the standard deviation) is a concept that is applied across statistics – not just for data
>>>>>>> b33a03c (edit name)
