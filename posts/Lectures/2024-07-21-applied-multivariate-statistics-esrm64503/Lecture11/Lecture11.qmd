---
title: "Lecture 11: Introduction to Bayesian Statistics and Markov Chain Monte Carlo Estimation"
subtitle: ""
author: "Jihong Zhang*, Ph.D"
institute: | 
  Educational Statistics and Research Methods (ESRM) Program*
  
  University of Arkansas
date: "2024-10-09"
date-modified: "2024-10-11"
draft: true
sidebar: false
execute: 
  echo: true
  warning: false
output-location: default
code-annotations: below
highlight-style: "nord"
format: 
  uark-revealjs:
    scrollable: true
    chalkboard: true
    embed-resources: false
    code-fold: false
    number-sections: false
    footer: "ESRM 64503 - Lecture 11: Absolute Model fit and Path Analysis"
    slide-number: c/t
    tbl-colwidths: auto
    output-file: slides-index.html
  html: 
    page-layout: full
    toc: true
    toc-depth: 2
    toc-expand: true
    lightbox: true
    code-fold: false
    fig-align: center
filters:
  - quarto
  - line-highlight
---

## 

{=html}
<div class="card shadow">
    <div class="ml-3 mt-2">
        <svg xmlns="http://www.w3.org/2000/svg" width="54" height="14" viewBox="0 0 54 14">
            <g fill="none" fill-rule="evenodd" transform="translate(1 1)">
                <circle cx="6" cy="6" r="6" fill=$\beta_0$FF5F56" stroke=$\beta_0$E0443E" stroke-width=".5"></circle>
                <circle cx="26" cy="6" r="6" fill=$\beta_0$FFBD2E" stroke=$\beta_0$DEA123" stroke-width=".5"></circle>
                <circle cx="46" cy="6" r="6" fill=$\beta_0$27C93F" stroke=$\beta_0$1AAB29" stroke-width=".5"></circle>
            </g>
        </svg>
    </div>
    <div class="card-body">
        <h4 class="card-title"><b>Today's Class</b></h4>
        <ul>
          <li>An introduction to Bayesian statistics:</li>
          <ul>
            <li>What it is</li>
            <li>What it does</li>
            <li>Why people use it</li>
          </ul>
          <li>An introduction to Markov Chain Monte Carlo:</li>
          <ul>
            <li>How it works</li>
            <li>Features to look for when using MCMC</li>
            <li>Why people use it</li>
          </ul>
        </ul>
    </div>
</div>




# AN INTRODUCTION TO BAYESIAN STATISTICS


## Bayesian Statistics: The Basics

- Bayesian statistical analysis refers to the use of models where some or all of the parameters are treated as **random components**
      - Each parameter comes from some type of distribution
       
- The likelihood function of the data is then augmented with an additional term that represents the likelihood of the **prior** **distribution** for each parameter 
      - Think of this as saying each parameter has a certain likelihood - the height of the prior distribution
       
- The final estimates are then considered summaries of the **posterior distribution** of the parameter, conditional on the data 
      - In practice, we use these estimates to make inferences, just as we have when using the non-Bayesian approaches we have used throughout this class (e.g., maximum likelihood/least squares)


## Bayesian Statistics: Why It Is Used

- Bayesian methods get used because the **_relative_** accessibility of one method of estimation (MCMC – to be discussed shortly)

- There are four main reasons why people use MCMC:
1. Missing data
    - Multiple imputation: MCMC is used to estimate model parameters then “impute” data
    - More complicated models for certain types of missing data
    
2. Lack of software capable of handling large sized analyses
    - Have a zero-inflated negative binomial with 21 multivariate outcomes per 18 time points?

3. New models/generalizations of models not available in software
       - Have a new model?
       - Need a certain link function not in software?
       
4. Membership in the cult of Bayesians
    - They believe philosophical differences exist between numbers from Bayesian analysis and other types of estimators


## Bayesian Statistics: Perceptions and Issues

- The use of Bayesian statistics has been controversial
    - The use of certain prior distributions can produce results that are biased or reflect
       subjective judgment rather than objective science
       
- Most MCMC estimation methods are **computationally intensive**
    - Until recently, very few methods available for those who aren’t into programming in Fortran, C, or C++
       
- Understanding of what Bayesian methods are and how they work is limited outside the field of mathematical statistics
    - Especially the case in the educational and social sciences
    
- Over the past 20 years, Bayesian methods have become
    widespread – making new models estimable and becoming
    standard in some social science fields (quantitative psychology
    and educational measurement)


# HOW BAYESIAN METHODS WORK


## How Bayesian Statistics Work

- The term Bayesian refers to Thomas Bayes (1701-1761)
    - Formulated Bayes’ Theorem

- Bayesian methods rely on Bayes’ Theorem:

$$
P(A|B) = \frac{P(B|A)P(A)}{P(B)}
$$

- $P(A)$ is the prior distribution (pdf) of A $\rightarrow$ WHY THINGS ARE BAYESIAN
- $P(B)$ is the marginal distribution (pdf) of B
- $P(B|A)$ is the conditional distribution (pdf) of B, given A
- $P(A|B)$ is the posterior distribution (pdf) of A, given B


- Bayes’ Theorem Example...

Imagine a patient takes a test for a rare disease (present 1% of the population) that has a 95% accuracy rate...what is the
probability the patient actually has the disease?




## Bayes’ Theorem Example

Imagine a patient takes a test for a rare disease (present 1% of the population) that has a 95% accuracy rate...what is the probability the patient actually has the disease?

- D = the case where the person actually has the disease
- ND = the case where the person does not have the disease
- + = the test for the disease is positive

Thus,
$$
P(D) = .01
$$
$$
P(+|D) = .95
$$

- The question is asking for: P(D|+)

- From Bayes’ Theorem, the probability of the person actually having the disease given the test is positive:

$$
P(D|+)=\frac{P(+|D)P(D)}{P(+)}
$$

## Back to Distributions

- We don’t know $P(+)$ directly from the problem, but we can figure it out if we recall how distributions work:
    - $P(+)$ is a marginal distribution
    - $P(+|D)$ is a conditional distribution

- We can get to the marginal by summing across the conditional:

$$
\begin{align}
P(+) &= P(+|D)P(D) + P(+|ND)P(ND) \\
     &= .95 \times .01 + .05 \times .99 \\
     &= .059
\end{align}
$$

- So, to figure out the answer, if a person tests positive for the disease, the **posterior probability** they actually have the disease is:

$$
P(D|+)=\frac{P(+|D)P(D)}{P(+)} =  \frac{.95\times.01}{.059} = 0.161
$$
which is very surprising, if the test is positive, there is less than 20% probability of actually having the disease

## A (Perhaps) More Relevant Example

- The old-fashioned Bayes’ Theorem example I’ve found to be difficult to generalize to your actual data, so...

- Imagine you administer an IQ test to a sample of 50 people
    - $y_p$: person p’s IQ test score

- To put this into a linear-models context, the empty model for Y:

$$
y_p = \beta_0 + e_p
$$

Where $e_p \sim N(0, \sigma^2_e)$

- From this empty model, we know that:
    - $\beta_0$ is the mean of the Y (the mean IQ)
    - $\sigma^2_e$ is the sample variance of Y
    - The conditional distribution of Y is then: $f(y_p|\beta_0, \sigma^2_e)\sim N(\beta_0, \sigma^2_e)$


## Non-Bayesian Analysis

- Up to this point in the class, we have analyzed these data using ML and REML

- For ML, we maximized the joint likelihood of the sample with respect to the two unknown parameters $\beta_0$ and $\sigma^2_e$:

$$
\begin{align}
L(\beta_0, \sigma^2_e) &=\prod_{p=1}^{N} f(y_p|\beta_0, \sigma^2_e) \\
&= \prod_{p=1}^{N}\frac{1}{\sqrt{2\pi\sigma^2_e}}\exp(-\frac{(y_p-\beta_0)^2}{2\sigma^2_e})
\end{align}
$$
-   Here, using `gls()`, we found:


$$
\beta_0 = 102.769 \\
\sigma^2_e = 239.490 \\
\text{LogL} = −207.91
$$

## Setting up a Bayesian Approach

- The (fully) Bayesian approach would treat each parameter as a random instance from some **prior distribution**
- Let’s say you know that this version of the IQ test is supposed to have a mean of 100 and a standard deviation of 15
       - So $\beta_0$ should be 100 and $\sigma^2_e$ should be 225
       
- Going a step further, let’s say you have seen results for administrations of this test that led you to believe that the mean came from a normal distribution with a SD of 2. 
      - This indicates the prior distribution for the **mean** ...or
          $f(\beta_0) ∼ (100 , 2.13^2)$
          
- Let’s also say that you don’t really have an idea as for the distribution of
    the variance, but you have seen it range from 200 to 400, so we can come
    up with a prior distribution for the **variance** of:
       $\sigma^2_e \sim U(200, 400)$
       
- Here the prior is a uniform distribution meaning all values from 200 to 400 are equally likely


## More on the Bayesian Approach

- The Bayesian approach is now to seek to find the **posterior** **distribution** of the parameters given the data: 

$$
f(\beta_0,\sigma^2_e|\mathbf{y}_p)
$$

- We can again use Bayes’ Theorem (but for continuous parameters):

$$
\begin{align}
f(\beta_0,\sigma^2_e|\mathbf{y}_p) &= \frac{f(\mathbf{y}_p|\beta_0, \sigma^2_e)f(\beta_0, \sigma^2_e)}{f(\mathbf{y}_p)} \\
&= \frac{f(\mathbf{y}_p|\beta_0, \sigma^2_e)f(\beta_0)f(\sigma^2_e)}{f(\mathbf{y}_p)}
\end{align}
$$


- Because $f(\mathbf{y}_p)$ essentially is a constant (which involves integrating across $\beta_0$ and $\sigma^2_e$ to find its value), this term is often referred to as:

$$
f(\beta_0,\sigma^2_e|\mathbf{y}_p) \propto f(\mathbf{y}_p|\beta_0, \sigma^2_e)f(\beta_0, \sigma^2_e)
$$

- The symbol $\propto$ is read as “is proportional to” 
    - meaning it is the same as when multiplied by a constant
    - So it is the same for all values of $\beta_0$ and $\sigma^2_e$


## Unpacking the Posterior Distribution I

-$f(\mathbf{y}_p|\beta_0, \sigma^2_e)$ is the **conditional distribution** of the data given the parameters 
    
    – we know this already from our linear model (slide 12)

$$
f\left(\boldsymbol{y}_{p} \mid \beta_{0}, \sigma_{e}^{2}\right)=\prod_{p=1}^{N} f\left(y_{p} \mid \beta_{0}, \sigma_{e}^{2}\right)=\prod_{p=1}^{N} \frac{1}{\sqrt{2 \pi \sigma_{e}^{2}}} \exp \left(-\frac{\left(y_{p}-\beta_{0}\right)^{2}}{2 \sigma_{e}^{2}}\right)
$$

- $f(\beta_0)$ is the **prior distribution** of $\beta_0$, which we decided would be
    $N(100, 2.13^2)$ , giving the height of any $\beta_0$:

$$
\begin{array}{l}
f\left(\beta_{0}\right)=\frac{1}{\sqrt{2 \pi \sigma_{\beta_{0}}^{2}}} \exp \left(-\frac{\left(\beta_{0}-\mu_{\beta_{0}}\right)^{2}}{2 \sigma_{\beta_{0}}^{2}}\right) \\
=\frac{1}{\sqrt{2 \pi * 2.13^{2}}} \exp \left(-\frac{\left(\beta_{0}-100\right)^{2}}{2 * 2.13^{2}}\right)
\end{array}
$$

## Unpacking the Posterior Distribution II

-$f(\sigma^2_e)$ is the **prior distribution** of $\sigma^2_e$, which we decided would be $U(200, 400)$, giving the height of any value of $\sigma^2_e$
as:

$$
f\left(\sigma_{e}^{2}\right)=\frac{1}{b_{\sigma_{e}^{2}}-a_{\sigma_{e}^{2}}}=\frac{1}{400-200}=\frac{1}{200}=.005
$$

- Some useful terminology:
    - The parameters of the model (for the data) get prior distributions
    - The prior distributions each have parameters –these parameters are called
       **hyper-parameters**
    - The hyper-parameters are not estimated in our example, but could be –giving us a case where we would call our priors **empirical priors**
          - **AKA random intercept variance**


## Up Next: Estimation (first using non-MCMC)

- Although MCMC is commonly thought of as the only method for
    Bayesian estimation, there are several other forms
- The form analogous to ML (where the value of the parameters that
    maximize the likelihood or log-likelihood) is called **Maximum (or Modal) a Posteriori estimation(MAP)**
       - The term modal comes from the maximum point coming at the peak (the mode) of the
          posterior distribution
- In practice, this functions similar to ML, only instead of maximizing
    the joint likelihood of the data, we now have to worry about the
    prior:

$$
f\left(\beta_{0}, \sigma_{e}^{2} \mid \boldsymbol{y}_{p}\right)=\frac{f\left(\boldsymbol{y}_{p} \mid \beta_{0}, \sigma_{e}^{2}\right) f\left(\beta_{0}\right) f\left(\sigma_{e}^{2}\right)}{f\left(\boldsymbol{y}_{p}\right)} \propto f\left(\boldsymbol{y}_{p} \mid \beta_{0}, \sigma_{e}^{2}\right) f\left(\beta_{0}\right) f\left(\sigma_{e}^{2}\right)
$$

- Because it is often more easy to work with, the log of this is often used:
    
$$
\log \left(f\left(\beta_{0}, \sigma_{e}^{2} \mid \boldsymbol{y}_{p}\right)\right) \propto \log f\left(\boldsymbol{y}_{p} \mid \beta_{0}, \sigma_{e}^{2}\right)+\log f\left(\beta_{0}\right)+\log f\left(\sigma_{e}^{2}\right)
$$

## Grid Searching for the MAP Estimate of $\beta_0$

- To demonstrate, let’s imagine we know $\sigma^2_e$ = 239. 490
    - Later we won’t know this...when we use MCMC
    
- We can use Excel or R to search over a grid of possible values for $\beta_0$

- In each, we will use $\log f\left(\boldsymbol{y}_{p} \mid \beta_{0}\right)+\log f\left(\beta_{0}\right)$

- As a comparison, we will also search over the ML log likelihood function $\log (\mathbf{y}_p|\beta_0)$


## ML v. Prior for** !" **of N(100, 2.13**^2 **)

- Maximum for ML: 102.
- Maximum for Bayes: 101.
    (estimate is closer to mean of prior)

-213EPSY 905: Intro to Bayesian and MCMC 19

-
-
-
-
-
-
-
-


99.8100.1100.4100.7^101 101.3101.6101.9102.2102.5102.8103.1103.4103.7^104 104.


ML Version (no prior)
N(100,2.13) Prior


## ML vs. Prior for !" of N(100, 10002 )

ML Version (no prior)

- • Maximum for ML: 102.
- • Maximum for Bayes: 102.
   - -
   - -
   - -
   - -
   - -
   - -
   - -
   - -
   - -
      - 99.8100.1100.4100.7^101 101.3101.6101.9102.2102.5102.8103.1103.4103.7^104 104.


## ML vs. Prior for** !" **of N(100, 0.15**^2 **)

- Maximum for ML: 102.8
- Maximum for Bayes: 100


-300


-290


-280


-270


-260


-250


-240


-230


-220


-210


-200
99.8100.1100.4100.7^101 101.3101.6101.9102.2102.5102.8103.1103.4103.7^104 104.3


ML Version (no prior)
N(100,.15) Prior


## ML vs. Prior for** !" **of U(-1000,1000)

- Maximum for ML: 102.8
- Maximum for Bayes: 102.8


-218


-216


-214


-212


-210


-208


-206


-204


-202
99.8100.1100.4100.7^101 101.3101.6101.9102.2102.5102.8103.1103.4103.7^104 104.3


ML Version (no prior)
U(-1000,1000) Prior


## Summarizing Bayesian So Far

- Bayesian à parameters have prior distributions
- Estimation in Bayesian à MAP estimation is much like


estimation in ML, only instead of likelihood of data, now have
to add in likelihood for prior of all parameters
- But...MAP estimation may be difficult as figuring out derivatives for gradient
function (for Newton-Raphson) are not always easy
- Where they are easy: Conjugate priors àprior distributions that are the same as
the posterior distribution (think multilevel with normal outcomes)

- Priors can be **informative** (highly peaked) or **uninformative**


(not peaked)
- Some uninformative priors will give MAP estimates that are equal to ML

- Up next: estimation by brute force: Markov Chain Monte Carlo


## MARKOV CHAIN MONTE CARLO ESTIMATION:

## THE BASICS


## How Estimation Works (More or Less)

- Most estimation routines do one of three things:
**1. Minimize Something:** Typically found with names that have “least”
    in the title. Forms of least squares include “Generalized”,
    “Ordinary”, “Weighted”, “Diagonally Weighted”, “WLSMV”, and
    “Iteratively Reweighted.” Typically the estimator of last resort...
**2. Maximize Something:** Typically found with names that have
    “maximum” in the title. Forms include “Maximum likelihood”,
    “ML”, “Residual Maximum Likelihood” (REML), “Robust ML”.
    Typically the gold standard of estimators (and we now know why).
**3. Use Simulation to Sample from Something:** more recent advances
    in simulation use resampling techniques. Names include “Bayesian
    Markov Chain Monte Carlo”, “Gibbs Sampling”, “Metropolis
    Hastings”, “Metropolis Algorithm”, and “Monte Carlo”. Used for
    complex models where ML is not available or for methods where
    prior values are needed.


## How MCMC Estimation Works

- MCMC estimation works by taking samples from the posterior distribution of the
    data given the parameters:
      f$\beta_0$,$\sigma^2_e$ () =


f() $\beta_0$,$\sigma^2_e$f$\beta_0$f$\sigma^2_e$
f()
- How is that possible? We don’t know !(())...but...we’ll see...

- After enough values are drawn, a rough shape of the distribution
    can be formed
       - From that shape we can take summaries and make them our parameters (i.e., mean)
- How the sampling mechanism happens comes from several different algorithms
    that you will hear about, the most popular being:
       - **Gibbs Sampling** : used whenf$\beta_0$,$\sigma^2_e$() is known
          w Parameter values are drawn and kept throughout the chain
       - **Metropolis-Hastings (within Gibbs):** used whenf$\beta_0$,$\sigma^2_e$() is unknown
          w Parameter values are proposed, then either kept or rejected
          w SAS PROC MCMC uses the latter
          w TRIVIA NOTE: The Metropolis algorithm comes from Chemistry (in 1950)
       - **Hybrid MC:** Newer versions (1980s; implemented in Stan)
- In some fields (Physics in particular), MCMC estimation is referred to as
    Monte Carlo estimation


## MCMC Estimation with MHG

- The Metropolis-Hastings algorithm works a bit differently than


Gibbs sampling:

1. Each parameter (here !" and $\sigma^2_e$) is given an initial value
2. In order, a new value is proposed for each model parameter


from some distribution:
!"∗ ∼ ( !"∗ !" ;$\sigma^2_e$


∗
∼ ( $\sigma^2_e$


∗
$\sigma^2_e$

3. The proposed value is then accepted as the current value with


probability max(./01, 1 ):

### ./01 =

### 6 78 !"∗,$\sigma^2_e$


∗
6 !"∗ 6 $\sigma^2_e$


∗
( !" !"∗ ( $\sigma^2_e$ $\sigma^2_e$


∗

### 6 78 !",$\sigma^2_e$ 6 !") 6 ($\sigma^2_e$ ( !"∗ !" ( $\sigma^2_e$


∗
$\sigma^2_e$

4. The process continues for a pre-specified number of iterations

EPSY 905: Intro to Bayesian and MCMC(more is better) 27


## Notes About MHG

- The constant in the denominator of the posterior distribution:


f$\beta_0$,$\sigma^2_e$ () =

### f() $\beta_0$,$\sigma^2_e$f$\beta_0$)!($\sigma^2_e$

### f()

_...cancels when the ratio is formed_

- The proposal distributions - $\beta_0$∗ $\beta_0$ and - $\sigma^2_e$


∗
$\sigma^2_e$ can
literally be any statistical distribution
- The trick is picking ones that make the chain “converge” quickly
- Want to find values that lead to moderate number of accepted parameters
- SAS PROC MCMC/WINBUGS don’t make you pick these

- Given a long enough chain, the final values of the chain will


come from the posterior distribution
- From that you can get your parameter estimates


# Introducing Jags...


## Iteration History from JAGS


## Examining the Chain and Posteriors


## Practical Specifics in MCMC Estimation

- A **burn-in** period is used where a chain is run for a set number
    of iterations before the sampled parameter values are used in
    the posterior distribution
- Because of the rejection/acceptance process, any two
    iterations are likely to have a high correlation (called
    **autocorrelation** ) à posterior chains use a **thinning interval** to
    take every Xth sample to reduce the autocorrelation
       - A high autocorrelation may indicate the standard error of the posterior
          distribution will be smaller than it should be
- The **chain length** (and sometimes number of chains) must also
    be long enough so the rejection/acceptance process can
    reasonably approximate the posterior distribution
- How does one what values to pick for these? Output
    diagnostics

EPSY 905: Intro to Bayesian and MCMC- Trial. And. Error. 32


## Best Output Diagnostics: the Eye Ball Test


Perfect:


Not
Perfect:


Not
Perfect:


Not
Perfect:


## Output Statistics and Diagnostics


## Changing Up the Prior

- To demonstrate how changing the prior affects the


analysis, we will now try a few prior distributions for our
parameters

- Prior: !" ∼ $ − 10000 , 10000 ;*+, ∼ $( 0 , 5000 )


## Chain Plots


## Changing Up the Prior

- Prior: !" ∼ $ 0 , 100 , 000 ;
- )*+, ∼ -.//.( 1 =. 01 , 4 =. 01 )


## Chain Plots


## What About an Informative Prior?

- Prior: !" ∼ $ 102 , 103 ;+,- ∼ $ 238 , 242


## Chain Plots


# MCMC in R

## • R itself does not have an MCMC engine native to the

## language – but there are many free versions available

## outside of R

## • For instance, if you wanted to estimate a path model with

## MCMC you can:


- Install the blavaanpackage (Bayesian lavaan)
- Run the path analysis with MCMC

## • I am not showing you these because I they all end up being

## really frustrating


- Very buggy
- Took me about an hour to just install all code


## WRAPPING UP


## Wrapping Up

- Today was an introduction to Bayesian statistics
    - Bayes = use of prior distributions on parameters
- We used two methods for estimation:
    - MAP estimation –far less common
    - MCMC estimation
       w Commonly, people will say Bayesian and mean MCMC –but Bayesian is just the
          addition of priors. MCMC is one way of estimating Bayesian models!
- MCMC is effective for most Bayesian models:
    - Model likelihood and prior likelihood are all that are needed
- MCMC is estimation by brute force:
    - Can be very slow, computationally intensive, and disk-space intensive


