---
title: "Lecture 03: Simple, Marginal, and Interaction Effects"
subtitle: "More about general linear model"
author: "Jihong Zhang*, Ph.D"
institute: | 
  Educational Statistics and Research Methods (ESRM) Program*
  
  University of Arkansas
date: "2024-09-03"
sidebar: false
execute: 
  echo: true
  warning: false
output-location: column
format: 
  html: 
    page-layout: full
    toc: true
    toc-depth: 2
    toc-expand: true
    lightbox: true
    code-fold: false
  uark-revealjs:
    scrollable: true
    chalkboard: true
    embed-resources: false
    code-fold: false
    number-sections: false
    footer: "ESRM 64503: Lecture 02 - Descriptive Statistics"
    slide-number: c/t
    tbl-colwidths: auto
    output-file: slides-index.html
---

## Presentation Outline

1.  Centering and Coding Predictors

2.  Interpreting Parameters in the Model for the Means

3.  Main Effects Within Interactions

4.  GLM Example 1: "Regression" vs. "ANOVA"

## Today's Example:

-   Study examining effect of new instruction method (**New**: 0=Old, 1=New) on test performance (**Test**: % correct) in college freshmen vs. senior (**Senior**: 0=Freshman, 1=Senior), n = 25 per group.

$$
\text{Test}_p =\beta_0+\beta_1\text{Senior}_p+\beta_2\text{New}_p+ \beta_3 \text{Senior}_p\text{New}_p+ e_p
$$

```{r}
#| code-fold: true
#| output-location: default
library(ESRM64503)
library(tidyverse)
library(kableExtra)
library(gt)
data("dataTestExperiment")
dataTestExperiment |> 
  group_by(Senior, New) |> 
  summarise(
    Mean = mean(Test),
    SD = sd(Test),
    SE = sd(Test) / 25
  ) |> 
  mutate(
    Statistics = paste0(signif(Mean, 4), "(", round(SD, 2), ")", "[", round(SE, 2), "]")
  ) |> 
  dplyr::select(-c(Mean, SD, SE)) |> 
  mutate(
    Senior = factor(Senior, levels = 0:1, labels = c("Freshmen", "Senior")),
    New = factor(New, levels = 0:1, labels = c("Old", "New")),
         ) |> 
  pivot_wider(names_from = Senior, values_from = Statistics) |> 
  kable()
```

## The Two Sides of a Model

$$
\text{Test}_p =\color{red}{\beta_0+\beta_1\text{Senior}_p+\beta_2\text{New}_p+ \beta_3 \text{Senior}_p\text{New}_p}+ \color{blue}{e_p}
$$

-   [[Model for the Means (Predicted Values)]{.underline}]{style="color: red"}

    -   Each person's expected (predicted) outcome is a function of his/her values on x and z (and their interaction), each measured once person

    -   **Estimated parameters are called fixed effects** (here, $\beta_0$, $\beta_1$, $\beta_2$, and $\beta_3$); although they have a sampling distribution, they are not random variables

    -   The number of fixed effects will show up in formulas as ***k*** (so ***k = 4***here)

-   [[Model for the Variance]{.underline}]{style="color: blue"}:

    -   $e_p \sim N(0, \sigma^2_e) \rightarrow$ ONE residual (unexplained) deviation
    -   $e_p$ has a mean of 0 with some estimated constant variance $\sigma^2_e$, is normally distributed, is unrelated across people
    -   Estimated parameter is the residual variance only (in the model above)

## Representing the Effects of Predictor Variables

-   From now on, we will think carefully about how the predictor variables enter into the [model for the means]{style="color: red;"} rather than the scales of predictors

-   Why don't people always care about **the scale of predictors**:

    1.  Does NOT affect the amount of outcome variance account for ($R^2$)

    2.  Does NOT affect the outcomes values predicted by the model for the means (so long as the same predictor fixed effects are included)

-   Why should this matter to us?

    1.  Because the **Intercept = expected outcome value when X = 0**

    2.  Can end up with nonsense values for intercept if X = isn't in the data

    3.  We will almost always need to deliberately **adjust the scale of the predictor variables** so that they have 0 values that could be observed in our data

    4.  Is much bigger deal in models with random effects (MLM) or GLM once interactions are included

## Adjusting the Scale of Predictor Variables

-   For **continuous** (quantitative) predictors, we will make the intercept interpretable by centering:

    -   **Centering** = subtract as constant from each person's variable value so that the 0 value falls within the range of the new centered predictor variable

    -   Typical $\rightarrow$ Center around predictor's mean: $X_1^\prime = X_1 - \bar{X_1}$

    -   Better $\rightarrow$ Center around meaningful constant C: $X_1^\prime = X_1 - C$

```{r}
#| results: hold
x <- rnorm(100, mean = 1, sd = 1)
x_c <- x - mean(x)
mean(x)
mean(x_c)
```

------------------------------------------------------------------------

-   For **categorical** (grouping) predictors, [**either we or the program**]{.underline} will make the intercept interpretable by **creating a reference group:**

    -   Reference group is given a 0 value on all predictor variable created from the original group variable, such that the intercept is the expected outcome for that reference group specifically

    -   Accomplished via "dummy coding" or "reference group coding"

-   For **categorical** predictors with **more than two groups**

    -   We need to dummy coded the group variable using `factor()` in R
    -   For example, I dummy coded `group` variable with group 1 [as the reference]{style="color:red"}

```{r}
#| results: hold
dataTestExperiment$Group <- factor(dataTestExperiment$Group, 
                                   levels = 1:4, 
                                   labels = c("Ctl", "T1", "T2", "T3"))
mod_e0 <- lm(Test ~ Group, data = dataTestExperiment)
summary(mod_e0)$coefficients |> kable(digits = 3) 
```

------------------------------------------------------------------------

-   Variable `edu`: \# dummy variables = \# group -1

    -   Dummy variables with four levels - Control, Treatment1, Treatment2, Treatment3:

        -   d1 = *GroupT1* ([0, 1, 0, 0]{style="color: tomato;"}) $\rightarrow$ $\beta_1$ = difference between Treatment1 vs. Control

        -   d2 = *GroupT2* ([0, 0, 1, 0]{style="color: tomato"}) $\rightarrow$ $\beta_2$ = difference between Treatment2 vs. Control

        -   d3 = *GroupT3* ([0, 0, 0, 1]{style="color: tomato"}) $\rightarrow$ $\beta_3$ = difference between Treatment3 vs. Control

```{r}
#| output-location: default
model.matrix(mod_e0) |> cbind(dataTestExperiment) |> showtable(font_size = 33)
```

------------------------------------------------------------------------

-   Other examples of things people do to categorical predictors:

    -   "**Contrast/effect coding**" $\rightarrow$ Gender: -0.5 = Man, 0.5 = Women

        -   **Effect**: Man vs. Average \| Women vs. Average

    -   Test other contrasts among multiple groups

        -   Four-group variable: Control, Treatment1, Treatment2, Treatment3

        -   **Effect**: contrast1 = {-1, .33, .33, .34}

        -   Control vs. Any Treatment?

## Categorical Predictors: Manual Coding

-   $$
    \hat Y_p = \beta_0+\beta_1\text{GroupT1}_p+\beta_2\text{GroupT2}_p + \beta_3\text{GroupT3}_p
    $$

    -   d1 = *GroupT1* ([0, 1, 0, 0]{style="color: tomato;"}) $\rightarrow$ $\beta_1$ = mean difference between Treatment1 vs. Control
    -   d2 = *GroupT2* ([0, 0, 1, 0]{style="color: tomato"}) $\rightarrow$ $\beta_2$ = mean difference between Treatment2 vs. Control
    -   d3 = *GroupT3* ([0, 0, 0, 1]{style="color: tomato"}) $\rightarrow$ $\beta_3$ = mean difference between Treatment3 vs. Control

-   How does the model give us **all possible group difference**?

| Control Mean | Treatment 1 Mean  | Treatment 2 Mean  | Treatment 3 Mean  |
|:------------:|:-----------------:|:-----------------:|:-----------------:|
|  $\beta_0$   | $\beta_0+\beta_1$ | $\beta_0+\beta_2$ | $\beta_0+\beta_3$ |

-   The model (coefficients with dummy coding) directly provides 3 differences (control vs. each treatment), and indirectly provides another 3 differences (differences between treatments)

## Group differences from Dummy Codes

Set $J = 4$ as number of groups:

The total number of group differences is $J * (J-1) / 2 = 4*3/2 = 6$

| Control Mean | Treatment 1 Mean  | Treatment 2 Mean  | Treatment 3 Mean  |
|:------------:|:-----------------:|:-----------------:|:-----------------:|
|  $\beta_0$   | $\beta_0+\beta_1$ | $\beta_0+\beta_2$ | $\beta_0+\beta_3$ |

-   All group differences

|                |           Alt Group | Ref Group             | Difference            |
|------------------|-----------------:|:-----------------|:-----------------|
| Control vs. T1 | $(\beta_0+\beta_1)$ | \- $\beta_0$          | = $\beta_1$           |
| Control vs. T2 | $(\beta_0+\beta_2)$ | \- $\beta_0$          | = $\beta_2$           |
| Control vs. T3 | $(\beta_0+\beta_3)$ | \- $\beta_0$          | = $\beta_3$           |
| T1 vs. T2      | $(\beta_0+\beta_2)$ | \-$(\beta_0+\beta_1)$ | = $\beta_2-\beta_1$   |
| T1 vs. T3      | $(\beta_0+\beta_3)$ | \-$(\beta_0+\beta_1)$ | = $\beta_3-\beta_1$   |
| T2 vs. T3      | $(\beta_0+\beta_3)$ | \-$(\beta_0+\beta_2)$ | = $\beta_3 - \beta_2$ |

## R Code: Estimating All Group Differences in R

```{r}
#| code-fold: true
#| results: hide
#| output-location: default
library(multcomp)
mod_e0 <- lm(Test ~ Group, data = dataTestExperiment)
summary(mod_e0)
```

```{r}
#| output-location: default
contrast_model_matrix = matrix(c(
  0,  1, 0, 0,  # Control vs. T1
  0,  0, 1, 0,  # Control vs. T2
  0,  0, 0, 1,  # Control vs. T3
  0, -1, 1, 0,  # T1 vs. T2
  0, -1, 0, 1,  # T1 vs. T3
  0,  0,-1, 1   # T2 vs. T3
), nrow = 6, byrow = T)
rownames(contrast_model_matrix) <- c( "Control vs. T1", "Control vs. T2", "Control vs. T3", "T1 vs. T2", "T1 vs. T3", "T2 vs. T3" ) 
contrast_value <- glht(mod_e0, linfct = contrast_model_matrix)
summary(contrast_value)
```

## What the intercept should mean to you

-   **The model for the means** will describe what happens to the predicted outcome Y "as X increases" or "as Z increases" and so forth

-   But you wont what Y is actually supposed to be unless you know where the predictor variables are starting from!

-   Therefor, the intercept is the "YOU ARE HERE" sign in the map of your data... so it should be somewhere in the map\*!

```{r}
#| echo: false
#| fig-align: center
TestGroup <- dataTestExperiment |> 
  group_by(Group) |> 
  summarise(GroupMean = mean(Test))
ggplot(dataTestExperiment) +
  geom_point(aes(y = Test, x = Group, col = Group)) +
  geom_point(aes(y = GroupMean, x = Group, col = Group), 
             data = TestGroup, size = 4) +
  geom_label(aes(x = "Ctl", y = 80.20, label = "You are here"), nudge_x = .3, nudge_y = 1) +
  theme_bw() +
  theme(text = element_text(size = 33))
```

# Main Effects Within Interactions

## Interaction Effects

-   **Interaction = Moderation**: the effect of a predictor depends on the value of the interacting predictor

    -   Either predictor can be "the moderator" (interpretive distinction only)

-   Interaction can always be evaluated for any combination of categorical and continuous predictors, although

    1.  In ‚Äú**ANOVA**‚Äù: By default, all possible interactions are estimated

        -   Software does this for you; oddly enough, nonsignificant interactions usually still are kept in the model (even if only significant interactions are interpreted)

    2.  In ‚Äú**ANCOVA**‚Äù: Continuous predictors (‚Äúcovariates‚Äù) do not get to be part of interaction ‚û°Ô∏è make the ‚Äúhomogeneity of regression‚Äù assumption

        -   There is no reason to assume this ‚Äì it is a testable hypothesis!

    3.  In ‚Äú**Regression**‚Äù: No default ‚Äì effects of predictors are as you specify them

        -   Requires most thought, but gets annoying because in regression programs you usually have to manually create the interaction as an observed variable:

        -   e.g., XZ_interaction = centered_X \* centered_Z

## Main Effects in GLM with Interactions

::: callout-note
Main effects of predictors within interactions should remain in the model regardless of whether or not they are significant
:::

üò∂: $Y_p = \beta_0 + \beta_1 X_1 X_2$

üòÑ: $Y_p = \beta_0 + \beta_1X_1+\beta_2X_2+\beta_3 X_1 X_2$

-   **Reason**: the role of two-way interaction is to adjust its main effects

-   **However**, the original idea of a "main effect" **no longer applied** ... each main effect is **conditional** on the interacting predictor as 0 ($X_1X_2=0$)

-   Example:

    -   $\beta_1$ is the "conditional" main effect of X1 when X2 = 0

    -   $\beta_2$ is the "conditional" main effect of X2 when X1 = 0

## Model-Implied Simple Main Effects

::: callout-tip
The trick is keeping track of what 0 means for every interacting predictor, which depends on the way each predictor is being represented, as determined by you, or by the software without you!
:::

**Simple Main Effect = What it is + What modified it**

$\text{GPA}_p = 30 + 1\times \text{Motiv}_p +2 \times\text{Exam}_p+ 0.5 \times \text{Motiv}\times \text{Exam}_p$

-   GPA scores of anyone can be predicted by academic motivation, final exam scores, and their interaction by this model

-   Simple Main Effect of *Motiv* : $(1 + 0.5\times \text{Exam})$

    -   = 1 if Exam is 0; = 2 if Exam is 1; = 3 if Exam is 4

<!-- -->

-   Simple Main Effect of *Exam* : $(2 + 0.5\times \text{Motiv})$

    -   = 2 if Motiv is 0; = 3 if Motiv is 1; = 4 if Motiv is 4

## Interpretation

$$
\begin{aligned}
\text{GPA}_p = \beta_0 + \beta_1\times \text{Motiv}_p + \beta_2 \times\text{Exam}_p+ \beta_3 \times \text{Motiv}\times \text{Exam}_p
\\= 30 + 1\times \text{Motiv}_p +2 \times\text{Exam}_p+ 0.5 \times \text{Motiv}\times \text{Exam}_p
\end{aligned}
$$

-   $\beta_0$: Expected GPA when motivation is 0 and exam score is 0

-   $\beta_1$: Increase in GPA per unit motivation when exam score is 0

-   $\beta_2$: Increase in GPA per unit exam score when motivation is 0

-   $\beta_3$: Two ways of interpretation

    -   **Motivation is moderator**: Increase in effect of exam scores per unit motivation

        -   One unit of motivation leads to the effect of exam score $2 \rightarrow 2.5$

    -   **Exam Score is moderator**: Increase in effect of motivation per unit exam score

        -   One unit of exam score leads to the effect of motivation $1 \rightarrow 1.5$

::: callout-note
If interaction effect is significant, we typically report that motivation significantly moderates the effect of exam score on GPA
:::

## Why centering matters

When we **centered Exam Score** with 3 as centering point, then **intercept and the main effect** of motivation will change:

$$
\begin{align}
\text{GPA}_p = \color{tomato}{30} + \color{tomato}{1}\times \text{Motiv}_p +2 \times\text{Exam}_p+ 0.5 \times \text{Motiv}\times \text{Exam}_p
\\= \beta_0 + \beta_1\times \text{Motiv}_p + \beta_2 \times (\text{Exam}_p-3)+ \beta_3 \times \text{Motiv}\times (\text{Exam}_p-3)
\\= \color{red}{36} + \color{red}{2.5}\times \text{Motiv}_p +2 \times (\text{Exam}_p-3) + 0.5 \times \text{Motiv}\times (\text{Exam}_p-3)
\end{align}
$$

-   **Trick**: Predicted value stay the same

    -   Expected GPA score is [30 + 1\*0 + 2\*3 + 0.5\*0 = 36]{style="color: red"} when Motiv = 0 and Exam = 3

    -   Expected effect of Motiv is [1 + 0.5\*3 = 2.5]{style="color: red"} when Exam = 3

-   **Reason**: $\beta_0$ and $\beta_1$ are conditional on exam score while $\beta_2$ and $\beta_3$ are unconditional on exam score

## Quiz:

```{=html}
<iframe width="840px" height="800px" src="https://forms.office.com/r/WubsScScRz?embed=true" frameborder="0" marginwidth="0" marginheight="0" style="border: none; max-width:100%; max-height:100vh" allowfullscreen webkitallowfullscreen mozallowfullscreen msallowfullscreen></iframe>
```
