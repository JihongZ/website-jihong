{
  "hash": "b3b0d2fb493794826a3420d1f62c7f4b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"AI-Enhanced Psychometrics with R and Python Examples\"\ninstitute: | \n  Educational Statistics and Research Methods (ESRM) Program*\n  \n  University of Arkansas\ndate: \"2025-03-07\"\ndate-modified: \"2025-04-04\"\ndraft: false\nbibliography: references.bib\nimage: index_files/figure-html/plot-1.png\ntbl-cap-location: top\ncategories:\n  - R\n  - Python\n  - LLM\ncitation:\n  type: webpage\n  issued: 2025-03-07\nexecute: \n  warning: false\n  message: false  \nformat: \n  html:\n    code-tools: false\n    code-line-numbers: false\n    code-fold: false\n    code-summary: \"Click this to see R code\"\n---\n\n\n\n::: objectives\n## Overview {.unnumbered}\n\nIn the presentation at the Texas Universities Educational Statistics & Psychometrics (TUESAP) at Dallas, TX, Dr. Hong Jiao provided a fascinating talk about Computational Psychometric, a interdisciplinary area combining AI and psychometrics.\n\nThis blog aims to review the utilities of large language models in psychometrics with the following questions:\n\n1.  What is \"computational psychometrics\"?\n2.  What are applications of AI in educational psychometrics?\n:::\n\n::: rmdquote\nData is the new oil for training large AI models. However, the \"oil\" generated by humans may run out someday or grow much slower than the speed of AI consuming them. Moreover, the human-created data are less controllable in terms of quality, opinions, format, style, etc., and may lead to biases or privacy concerns when used for model training (Zhou, 2024).\n:::\n\nAI training needs human data but in a controlled way [@zhou2024].\n\n## Computational Psychometrics\n\nAccording to @vondavier2021, Computational Psychometrics provides \"*a new framework to re-conceptualize assessment theory and practices in the era of digital assessment with the advances in machine learning, natural language processing, and generative AI*\". As shown in @tbl-app, there are many AI-enhanced applications in psychometric research, including ML Statistics, Text Data analysis, Generative AI for Data Generation etc.\n\n+-----------------------------+------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| AI Areas                    | Type                   | Application                                                                                                                                                                                                                                                                                                                                                                     |\n+:============================+:=======================+:================================================================================================================================================================================================================================================================================================================================================================================+\n| Machine Learning Algorithm  | Supervised Learning    | Prediction, Classification                                                                                                                                                                                                                                                                                                                                                      |\n+-----------------------------+------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|                             | Unsupervised Learning  | Clustering, Association, Dimensionality Reduction                                                                                                                                                                                                                                                                                                                               |\n+-----------------------------+------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|                             | Reinforcement Learning |                                                                                                                                                                                                                                                                                                                                                                                 |\n+-----------------------------+------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Natural Language Processing | Language Models        | Text generation, Text summarization                                                                                                                                                                                                                                                                                                                                             |\n+-----------------------------+------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|                             | Semantic Analysis      | Text theme extraction, Text classification, Text understanding                                                                                                                                                                                                                                                                                                                  |\n+-----------------------------+------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|                             | Text data analysis     | Text processing, Item parameters prediction, Item quality check                                                                                                                                                                                                                                                                                                                 |\n+-----------------------------+------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Generative AI               | AI Agent               | Data generation and augmentation: Missing data imputation, [Item development and generation](https://education.umd.edu/research/centers/marc/selected-projects/ai-enhanced-assessment-methods/automated-item-generation), item review, [Automated scoring](https://education.umd.edu/research/centers/marc/selected-projects/ai-enhanced-assessment-methods/automated-scoring), |\n+-----------------------------+------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|                             | Large Language Models  | Trained LLMs for psychometric tasks: [Cheating detection](https://education.umd.edu/research/centers/marc/selected-projects/ai-enhanced-assessment-methods/cheating-detection)                                                                                                                                                                                                  |\n+-----------------------------+------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n: AI applications in Educational Psychometrics {#tbl-app tbl-colwidths=\"\\[25,25,50\\]\"}\n\nAI Agents in generative AI raises more attentions in Education because of the popularity and success of AI chat bots such as ChatGPT, Claude, Gemini. AI agents utilize many AI engineering techniques such as retrieval-augmented generation (RAG) and prompt engineering to enhancing the accuracy and reliability of output of large language models with information fetched from specific and relevant data sources[@merritt2025]. Some projects are based on Maryland Assessment Research Center ([MARC](https://education.umd.edu/research/centers/marc)).\n\n+----------------------------+--------------------------------------------------------------------------------------------------------------------+\n| Topic                      | Research Question                                                                                                  |\n+============================+====================================================================================================================+\n| Avoid misuse of AI         | -   Detect AI generated essays or homework assignments completed by generative AI                                  |\n+----------------------------+--------------------------------------------------------------------------------------------------------------------+\n| Understand AI Behaviors    | -   In automated scoring, compare human and AI rationale for automated scoring to safeguard human ratings with AI. |\n|                            |                                                                                                                    |\n|                            | -   Does AI think similarly like human raters in automated scoring?                                                |\n+----------------------------+--------------------------------------------------------------------------------------------------------------------+\n| AI-based Data Augmentation |                                                                                                                    |\n+----------------------------+--------------------------------------------------------------------------------------------------------------------+\n|                            |                                                                                                                    |\n+----------------------------+--------------------------------------------------------------------------------------------------------------------+\n|                            |                                                                                                                    |\n+----------------------------+--------------------------------------------------------------------------------------------------------------------+\n\n## Example 1: Construct LLM function calling with Python and R\n\nThe following section is inspired by the fascinating guide in the [post](https://pavelbazin.com/post/the-essential-guide-to-large-language-models-structured-output-and-function-calling/?utm_source=reddit&utm_medium=social&utm_campaign=structured_output&utm_content=sub_python) authored by Pavel Bazin.\n\nFirst of all, type in the following bash command in the terminal to install `openai` python module if you already have Python installed.\n\n\n\n::: {.cell}\n\n:::\n\n\n\n```bash\npip install openai\npython3 -m pip install openai\n```\n\nThe next step is to either create a new Python file (`.py`) or use `{python}` code chunk in Quarto, in which importing the `OpenAI` module and construct a python function called `llm_eval()`. This function can call OpenAI ChatGPT (e.g., `gpt-4o`) via the API key:\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Further down these imports will be ommited for brevity\nimport os\nfrom openai import OpenAI\n\n\ndef llm_eval(prompt: str, message: str, model: str = \"gpt-4o\"):\n    client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n    messages = [\n        {\"role\": \"system\", \"content\": prompt},\n        {\"role\": \"user\", \"content\": message},\n    ]\n\n    return client.chat.completions.create(\n        model=model,\n        messages=messages\n    )\n```\n:::\n\n\n\nThen, we should be able to call the function either in R (use `reticulate` package) or in Python:\n\n::: panel-tabset\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(reticulate)\n\nprompt = \"\nYou are a data parsing assistant. \nUser provides a list of groceries. \nYour goal is to output it as JSON.\n\"\nmessage = \"I'd like to buy some bread, pack of eggs, few apples, and a bottle of milk.\"\n\nres = py$llm_eval(prompt=prompt, message=message) #<1>\n\njson_data = res$choices[[1]]$message$content\n\ncat(json_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n````\n```json\n{\n  \"groceries\": [\n    \"bread\",\n    \"pack of eggs\",\n    \"apples\",\n    \"bottle of milk\"\n  ]\n}\n```\n````\n\n\n:::\n:::\n\n\n\n::: rmdnote\nThere are two things that should be noted: \n\n1. If you are using Quarto, use `py$<python object>` in R code chunk to have access to the python object. If you put python code and R code in multiple files, use `source_python(\"<Path to Python file>\")` to load the python function into R session.\n\n2. In contrast to use `res.choices[0].message.content` in Python,  note that the nested list in R is extract using `$` with the starting index as `1`.\n:::\n\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nprompt = \"\"\"\nYou are a data parsing assistant. \nUser provides a list of groceries. \nYour goal is to output it as JSON.\n\"\"\"\nmessage = \"I'd like to buy some bread, pack of eggs, few apples, and a bottle of milk.\"\n\nres = eval(prompt=prompt, message=message)\njson_data = res.choices[0].message.content\n\nprint(json_data)\n```\n:::\n\n\n\n:::\n\nLLM returned a markdown formatted string containing JSON. The reason is that we didn’t enable structured output in the API call.\n\nTo return the plain JSON text, structure output in python function:\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef llm_eval2(prompt: str, message: str, model: str = \"gpt-4o\"):\n    \n    client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n    messages = [\n        {\"role\": \"system\", \"content\": prompt},\n        {\"role\": \"user\", \"content\": message},\n    ]\n    \n    return client.chat.completions.create(\n        model=model,\n        messages=messages,\n        # Enable structured output capability\n        response_format={\"type\": \"json_object\"},\n    )\n```\n:::\n\n\n\nNow, running the same code will return plain JSON. That is great not only because we don’t need to parse anything extra, but it also guarantees that the LLM won’t include any free-form text such as “Sure, here is your data! \\{…\\}”.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres2 = py$llm_eval2(prompt=prompt, message=message)\n\njson_data2 = res2$choices[[1]]$message$content\n\ncat(json_data2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{\n  \"groceries\": [\n    \"bread\",\n    \"pack of eggs\",\n    \"few apples\",\n    \"bottle of milk\"\n  ]\n}\n```\n\n\n:::\n:::\n\n\n\nWe can further transform the json text into R list/data.frame.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist_data2 <- jsonlite::fromJSON(json_data2)\n\nstr(list_data2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nList of 1\n $ groceries: chr [1:4] \"bread\" \"pack of eggs\" \"few apples\" \"bottle of milk\"\n```\n\n\n:::\n\n```{.r .cell-code}\nas.data.frame(list_data2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       groceries\n1          bread\n2   pack of eggs\n3     few apples\n4 bottle of milk\n```\n\n\n:::\n:::\n\n\n\n### Structure as a HTML list\n\nTo further structure the output as HTML list (e.g., `<ul></ul>`), we can construct a simple sparser in Python and print it in R like this:\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport json\ndef render(data: str):\n    data_dict = json.loads(data)\n    backslash =\"\\n\\t\"\n\n    return f\"\"\"\n    <ul>\n        {\"\".join([ f\"<li>{x}</li>\" for x in data_dict[\"groceries\"]])}\n    </ul>\n    \"\"\"\n```\n:::\n\n\n```{.r .cell-code}\nlibrary(htmltools)\nHTML(py$render(json_data2))\n```\n\n```{=html}\n\n    <ul>\n        <li>bread</li><li>pack of eggs</li><li>few apples</li><li>bottle of milk</li>\n    </ul>\n    \n```\n\n\n\n\n### Utilize Schema to Define Data Shape\n\nThe problem is, we don’t have the data shape defined; let’s call it **JSON schema**. Our schema is now up to the LLM, and it might change based on user input. Let’s rephrase the user query to see it in action. Instead of asking, “I’d like to buy some bread, a pack of eggs, a few apples, and a bottle of milk,” let’s ask, “12 eggs, 2 bottles of milk, 6 sparkling waters.”\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmessage = \"12 eggs, 2 bottles of milk, 6 sparkling waters\"\n\nres = py$llm_eval2(prompt=prompt, message=message)\n\njson_data = res$choices[[1]]$message$content\n\ncat(json_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{\n  \"groceries\": [\n    {\n      \"item\": \"eggs\",\n      \"quantity\": 12,\n      \"unit\": \"\"\n    },\n    {\n      \"item\": \"milk\",\n      \"quantity\": 2,\n      \"unit\": \"bottles\"\n    },\n    {\n      \"item\": \"sparkling waters\",\n      \"quantity\": 6,\n      \"unit\": \"\"\n    }\n  ]\n}\n```\n\n\n:::\n:::\n\n\n\nAs seen in the output, ChatGPT can incorporate inputs with quantities into outputs with extra quantity attribute.\n\n::: rmdnote\nOpenAI introduced the next step for [Structured Output](https://platform.openai.com/docs/guides/structured-outputs/structured-outputs). You can get the same results using `response_format={\"type\": \"json_object\"}` and parse data yourself without using beta version of API which was not performing reliably in our products. \n:::\n\nFor the following experiment, let's create two prompts (No schema vs. With schema) and two inputs (Vague quantity vs. Precise quantity). We let LLM to generate the outputs for these 4 conditions:\n\n::: panel-tabset\n\n### R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprompt_old = \"\nYou are data parsing assistant. \nUser provides a list of groceries. \nYour goal is to output is as JSON.\n\"\n\nprompt_schema = \"\nYou are data parsing assistant. \nUser provides a list of groceries. \nUse the following JSON schema to generate your response:\n\n{{\n    'groceries': [\n        { 'name': ITEM_NAME, 'quantity': ITEM_QUANTITY }\n    ]\n}}\n\nName is any string, quantity is a numerical value.\n\"\n\nvague_input <- \"I'd like to buy some bread, pack of eggs, few apples, and a bottle of milk.\"\nprecise_input <- \"12 eggs, 2 bottles of milk, 6 sparkling waters.\"\n\ntabset_condition <- apply(expand.grid(c(\"No_Schema\", \"With_Schema\"), c(\"Vague_Input\", \"Precise_Input\")), 1, \\(x) paste0(x[1], \"+\", x[2]))\n\ndat_prompt_input <- data.frame(\n  expand.grid(\n    prompts = c(prompt_old, prompt_schema),\n    inputs = c(vague_input, precise_input), stringsAsFactors = FALSE\n  )\n  \n)\n\nget_response <- function(prompt, message) {\n  res <- py$llm_eval2(prompt=as.character(prompt), \n                      message=as.character(message))\n  output <- res$choices[[1]]$message$content\n  return(output)\n}\n\ndat_output <- dat_prompt_input |> \n  rowwise() |> \n  mutate(\n    json_data =get_response(prompt = prompts, message = inputs) \n  )\n```\n:::\n\n\n\n### Python\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nprompt = \"\"\"\nYou are data parsing assistant. \nUser provides a list of groceries. \nUse the following JSON schema to generate your response:\n\n{{\n    \"groceries\": [\n        { \"name\": ITEM_NAME, \"quantity\": ITEM_QUANTITY }\n    ]\n}}\n\nName is any string, quantity is a numerical value.\n\"\"\"\n\ninputs = [\n    \"I'd like to buy some bread, pack of eggs, few apples, and a bottle of milk.\",\n    \"12 eggs, 2 bottles of milk, 6 sparkling waters.\",\n]\n\nfor message in inputs:\n    res = eval(prompt=prompt, message=message)\n    json_data = res.choices[0].message.content\n    print(json_data)\n```\n:::\n\n\n:::\n\n\nThe outputs for 4 conditions show that the condition of the prompt with schema and the input with precise quantity has the most clear LLM output.\n\n::: macwindow\n\n\n\n```{.r .cell-code  code-fold=\"true\"}\ncontent <- paste0(glue(\"\n### {tabset_condition}\n**Prompt**:\\n{dat_output$prompts}\\n\\n\n**Input**:\\n\\n{dat_output$inputs}\\n\\n\n**LLMOutput**:\\n\\n{dat_output$json_data}\\n\\n\n\"), collapse = \"\")\nglue(\"::: panel-tabset\\n{content}:::\")\n```\n\n::: panel-tabset\n### No_Schema+Vague_Input\n**Prompt**:\n\nYou are data parsing assistant. \nUser provides a list of groceries. \nYour goal is to output is as JSON.\n\n\n\n**Input**:\n\nI'd like to buy some bread, pack of eggs, few apples, and a bottle of milk.\n\n\n**LLMOutput**:\n\n{\n  \"groceries\": [\n    \"bread\",\n    \"pack of eggs\",\n    \"few apples\",\n    \"bottle of milk\"\n  ]\n}\n\n### With_Schema+Vague_Input\n**Prompt**:\n\nYou are data parsing assistant. \nUser provides a list of groceries. \nUse the following JSON schema to generate your response:\n\n{{\n    'groceries': [\n        { 'name': ITEM_NAME, 'quantity': ITEM_QUANTITY }\n    ]\n}}\n\nName is any string, quantity is a numerical value.\n\n\n\n**Input**:\n\nI'd like to buy some bread, pack of eggs, few apples, and a bottle of milk.\n\n\n**LLMOutput**:\n\n{\n    \"groceries\": [\n        { \"name\": \"bread\", \"quantity\": 1 },\n        { \"name\": \"pack of eggs\", \"quantity\": 1 },\n        { \"name\": \"apples\", \"quantity\": 3 },\n        { \"name\": \"bottle of milk\", \"quantity\": 1 }\n    ]\n}\n\n### No_Schema+Precise_Input\n**Prompt**:\n\nYou are data parsing assistant. \nUser provides a list of groceries. \nYour goal is to output is as JSON.\n\n\n\n**Input**:\n\n12 eggs, 2 bottles of milk, 6 sparkling waters.\n\n\n**LLMOutput**:\n\n{\n  \"groceries\": [\n    {\n      \"item\": \"eggs\",\n      \"quantity\": 12\n    },\n    {\n      \"item\": \"milk\",\n      \"quantity\": 2,\n      \"unit\": \"bottles\"\n    },\n    {\n      \"item\": \"sparkling waters\",\n      \"quantity\": 6\n    }\n  ]\n}\n\n### With_Schema+Precise_Input\n**Prompt**:\n\nYou are data parsing assistant. \nUser provides a list of groceries. \nUse the following JSON schema to generate your response:\n\n{{\n    'groceries': [\n        { 'name': ITEM_NAME, 'quantity': ITEM_QUANTITY }\n    ]\n}}\n\nName is any string, quantity is a numerical value.\n\n\n\n**Input**:\n\n12 eggs, 2 bottles of milk, 6 sparkling waters.\n\n\n**LLMOutput**:\n\n{\n    \"groceries\": [\n        { \"name\": \"eggs\", \"quantity\": 12 },\n        { \"name\": \"bottles of milk\", \"quantity\": 2 },\n        { \"name\": \"sparkling waters\", \"quantity\": 6 }\n    ]\n}\n\n:::\n\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}