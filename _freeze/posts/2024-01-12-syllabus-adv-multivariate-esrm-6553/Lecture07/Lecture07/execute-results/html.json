{
  "hash": "42add19a5ebbf3f6e099de0ed704c4cd",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lecture 07\"\nsubtitle: \"Generalized Measurement Models: Modeling Observed Data\"\nauthor: \"Jihong Zhang\"\ninstitute: \"Educational Statistics and Research Methods\"\ntitle-slide-attributes:\n  data-background-image: ../Images/title_image.png\n  data-background-size: contain\n  data-background-opacity: \"0.9\"\nexecute: \n  echo: true\n  eval: false\nformat: \n  revealjs:\n    logo: ../Images/UA_Logo_Horizontal.png\n    incremental: false  # choose \"false \"if want to show all together\n    theme: [serif, ../pp.scss]\n    footer:  <https://jihongzhang.org/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553>\n    transition: slide\n    scrollable: true\n    background-transition: fade\n    slide-number: true\n    chalkboard: true\n    number-sections: false\n    code-line-numbers: true\n    code-link: true\n    code-annotations: hover\n    code-copy: true\n    highlight-style: nord\n    mermaid:\n      theme: neutral\n#bibliography: references.bib\n---\n\n\n## Last Class\n\n1.  We used two simulation data sets to introduce how Stan can be used for factor analysis\n\n-   A simple structure\n-   A structure with cross-loading\n\n2.  What we left is how to interpret parameters in factor analysis\n3.  We also need to refresh our memory of R coding and Stan coding we've learnt so far\n\n## Today's Lecture Objectives\n\n1.  Quickly go through our R code file so far\n2.  Show different modeling specifications for different types of item response data\n3.  Show how parameterization differs for standardized latent variables vs. marker item scale identification\n\n## Example Data: Conspiracy Theories\n\n-   Today's example is from a bootstrap resample of 177 undergraduate students at a large state university in the Midwest.\n\n-   The survey was a measure of 10 questions about their beliefs in various conspiracy theories that were being passed around the internet in the early 2010s\n\n-   All item responses were on a 5-point Likert scale with:\n\n    -   Strong Disagree\n\n    -   Disagree\n\n    -   Neither Agree nor Disagree\n\n    -   Agree\n\n    -   Strongly Agree\n\n-   The purpose of this survey was to study individual beliefs regarding conspiracies.\n\n-   Our purpose in using this instrument is to provide a context that we all may find relevant as many of these conspiracies are still prevalent.\n\n## Conspiracy Theory Q1-Q5[^1]\n\n[^1]: Built by Dr. Jonathan Templin\n\n1.  The U.S. invasion of Iraq was not part of a campaign to fight terrorism, but was driven by oil companies and Jews in the U.S. and Israel.\n2.  Certain U.S. government officials planned the attacks of September 11, 2001 because they wanted the United States to go to war in the Middle East.\n3.  President Barack Obama was not really born in the United States and does not have an authentic Hawaiian birth certificate.\n4.  The current financial crisis was secretly orchestrated by a small group of Wall Street bankers to extend the power of the Federal Reserve and further their control of the world's economy.\n5.  Vapor trails left by aircraft are actually chemical agents deliberately sprayed in a clandestine program directed by government officials.\n\n## Conspiracy Theory Q6-Q10\n\n1.  Billionaire George Soros is behind a hidden plot to destabilize the American government, take control of the media, and put the world under his control.\n\n2.  The U.S. government is mandating the switch to compact fluorescent light bulbs because such lights make people more obedient and easier to control.\n\n3.  Government officials are covertly Building a 12-lane \"NAFTA superhighway\" that runs from Mexico to Canada through America's heartland.\n\n4.  Government officials purposely developed and spread drugs like crack-cocaine and diseases like AIDS in order to destroy the African American community.\n\n5.  God sent Hurricane Katrina to punish America for its sins.\n\n## Response Distribution\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(tidyverse)\nlibrary(here)\nself_color <- c(\"#DB7093\", \"#AFEEEE\", \"#3CB371\", \"#9370DB\", \"#FFD700\")\nroot_dir <- \"posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code\"\ndat <- read.csv(here(root_dir, 'conspiracies.csv'))\nitemResp <- dat[,1:10]\ncolnames(itemResp) <- paste0('item', 1:10)\nitemResp |> \n  rownames_to_column(\"ID\") |> \n  pivot_longer(-ID, names_to = \"Item\", values_to = \"Response\") |> \n  mutate(Item = factor(Item, levels = paste0('item', 1:10)),\n         Response = factor(Response, levels = 1:5)) |> \n  ggplot() +\n  geom_bar(aes(x = Response, fill = Response, group = Response), \n           position = position_stack()) +\n  facet_wrap(~ Item, nrow = 3, ncol = 4) +\n  theme_classic() +\n  scale_fill_manual(values = self_color)\n```\n\n::: {.cell-output-display}\n![](Lecture07_files/figure-revealjs/unnamed-chunk-1-1.png){width=960}\n:::\n\n```{.r .cell-code  code-fold=\"true\"}\nconspiracyItems = itemResp\n```\n:::\n\n\n## Conspiracy Theories: Assumed Latent Variable\n\nFor today's lecture, we will assume each of the 10 items measures one single latent variable\n\n$\\theta$: tendency to believe in conspiracy theories\n\n-   Higher value of $\\theta$ suggests more likelihood of believing in conspiracy theories\n\n-   Let's denote this latent variable as $\\theta_p$ for individual *p*\n\n    -   *p* is the index for person with $p = \\{1, \\cdots, P\\}$\n\n-   We will assume this latent variable is:\n\n    -   Continuous\n\n    -   Normally distribution: $\\theta_p \\sim N(\\mu_\\theta, \\sigma_\\theta)$\n\n        -   We will make different assumptions about the response distribution to show how prior settings affect results\n\n-   Across all people, we will denote the set of vector of latent variable as\n\n$$\n\\Theta = \\begin{bmatrix}\\theta_1, \\cdots, \\theta_P\\end{bmatrix}^T\n$$\n\n# Building Measurement Model\n\n## Observed Variables with Normal Distributions\n\nA psychometric model posits that one or more hypothesized latent variable(s) is the common cause that can predict a person's response to observed items:\n\n1.  Our hypothesized latent variable: Tendency to Believe in Conspiracies ($\\theta_p$)\n2.  As we have only one variable, the model structure is called `Unidimensional`\n3.  All 10 items are considered as outcomes of the latent variable in the model\n4.  In today's class, we assume all item response follow a normal distribution:\n    -   This is the assumption underlying confirmatory factor analysis (CFA) models\n    -   This assumption is tenuous at best\n\n## Normal Distribution: Linear Regression\n\nA typical linear regression is like\n\n$$\nY_p =\\beta_0 +\\beta_1 X_p + e_p\n$$\n\nwith $e_p\\sim N(0, \\sigma_e)$\n\nIf we replace $X_p$ with latent variable $\\theta_p$, and replace $\\beta$ as factor loading $\\lambda$\n\nWe can get the linear regression function (**IRF**) for each item\n\n$$\nY_{p1} =\\mu_{0} +\\lambda_{1} \\theta_p + e_{p1}; \\ \\ \\ \\ \\ e_{p1}\\sim N(0, \\psi_1^2)\nY_{p2} =\\mu_{2} +\\lambda_{2} \\theta_p + e_{p2}; \\ \\ \\ \\ \\ e_{p2}\\sim N(0, \\psi_{2}^2)\nY_{p3} =\\mu_{3} +\\lambda_{3} \\theta_p + e_{p3}; \\ \\ \\ \\ \\ e_{p3}\\sim N(0, \\psi_{3}^2)\nY_{p4} =\\mu_{4} +\\lambda_{4} \\theta_p + e_{p4}; \\ \\ \\ \\ \\ e_{p4}\\sim N(0, \\psi_{4}^2)\nY_{p5} =\\mu_{5} +\\lambda_{5} \\theta_p + e_{p5}; \\ \\ \\ \\ \\ e_{p5}\\sim N(0, \\psi_{5}^2)\nY_{p6} =\\mu_{6} +\\lambda_{6} \\theta_p + e_{p6}; \\ \\ \\ \\ \\ e_{p6}\\sim N(0, \\psi_{6}^2)\nY_{p7} =\\mu_{7} +\\lambda_{7} \\theta_p + e_{p7}; \\ \\ \\ \\ \\ e_{p7}\\sim N(0, \\psi_{7}^2)\nY_{p8} =\\mu_{8} +\\lambda_{8} \\theta_p + e_{p8}; \\ \\ \\ \\ \\ e_{p8}\\sim N(0, \\psi_{8}^2)\nY_{p9} =\\mu_{9} +\\lambda_{9} \\theta_p + e_{p9}; \\ \\ \\ \\ \\ e_{p9}\\sim N(0, \\psi_{9}^2)\nY_{p10} =\\mu_{10} +\\lambda_{10} \\theta_p + e_{p10}; \\ \\ \\ \\ \\ e_{p10}\\sim N(0, \\psi_1{0}^2)\n$$\n\n## Interpretation of Parameters\n\n-   $\\mu_1$: Item intercept\n\n    -   Interpretation: the expected score on the item $i$ when $\\theta_p=0$\n\n    -   Higher Item intercept suggests more likely to believe in conspiracy for people with average level of conspiracy belief\n\n    -   So it is also called **item easiness** in item response theory (IRT)\n\n-   $\\lambda_i$: Factor loading or Item discrimination\n\n    -   The change in the expected score of an item for a one-unit increase in belief in conspiracy\n\n-   $\\psi_i^2$: Unique variance[^2]\n\n[^2]: In **Stan**, we will specify $\\psi_e$: the unique standard deviation\n\n## Measurement Model Identification\n\nWhen we specify measurement model, we need to choose on scale identification method for latent variable\n\n1.  Assume latent variable is normal distribution\n2.  Or, maker item has factor loading as \"1\"\n\nIn this study, we assume $\\theta_p \\sim N(0,1)$ which allows us to estimate all item parameters of the model\n\n-   This is what we call a **standardization identification method**\n\n-   Factor scores are like Z-scores\n\n## Implementing Normal Outcomes in Stan\n\nRecall that we can use matrix operation to make Stan estimate psychometric models with normal outcomes:\n\n-   The model (predictor) matrix cannot be used\n\n    -   This is because the latent variable will be sampled so that the model matrix cannot be formed as a constant\n\n-   The data will be imported as a matrix\n\n    -   More than one outcome means more than one column vector of data\n\n-   The parameters will be specified as vectors of each type\n\n    -   Each item will have its own set of parameters\n\n    -   Implications for the use of prior distributions\n\n## Stan's `data` Block\n\n\n::: {.cell output.var='display'}\n\n```{.stan .cell-code}\ndata {\n\n  int<lower=0> nObs;                 // number of observations #<1>\n  int<lower=0> nItems;               // number of items #<2>\n  matrix[nObs, nItems] Y;            // item responses in a matrix\n\n  vector[nItems] meanMu;\n  matrix[nItems, nItems] covMu;      // prior covariance matrix for coefficients #<3>\n\n  vector[nItems] meanLambda;         // prior mean vector for coefficients\n  matrix[nItems, nItems] covLambda;  // prior covariance matrix for coefficients #<4>\n\n  vector[nItems] psiRate;            // prior rate parameter for unique standard deviations #<5>\n}\n```\n:::\n\n\n1.  `nObs` is 177, declared as integer with lower bound as 0\n2.  `nItems` is 11, declared as integer with lower bound as 0\n3.  `meanMu` as `covMu` are prior mean and covariance matrix for $\\mu_i$\n4.  `meanLambda` and `covLambda` are prior mean and covariance matrix for $\\lambda_i$\n5.  `psiRate` is prior rate parameter for $\\psi_i$\n\n## Stan's `parameter` Block\n\n\n::: {.cell output.var='display'}\n\n```{.stan .cell-code}\nparameters {\n  vector[nObs] theta;                // the latent variables (one for each person)\n  vector[nItems] mu;                 // the item intercepts (one for each item)\n  vector[nItems] lambda;             // the factor loadings/item discriminations (one for each item)\n  vector<lower=0>[nItems] psi;       // the unique standard deviations (one for each item)   \n}\n```\n:::\n\n\nHere, the parameterization of $\\lambda$ (factor loadings / item discrimination) can lead to problems in estimation\n\n-   The issue: $\\lambda_i \\theta_p = (-\\lambda_i) (-\\theta_p)$\n\n    -   Depending on the random starting values of each of these parameters (per chain), a given chain may converge to a different region\n\n-   To demonstrate, we will start with different random number seed\n\n    -   Currently using **09102022**: works fine\n\n    -   Change to **25102022**: big problem\n\n## Stan's model Block\n\n\n::: {.cell output.var='display'}\n\n```{.stan .cell-code}\nmodel {\n  lambda ~ multi_normal(meanLambda, covLambda); // Prior for item discrimination/factor loadings\n  mu ~ multi_normal(meanMu, covMu);             // Prior for item intercepts\n  psi ~ exponential(psiRate);                   // Prior for unique standard deviations\n  \n  theta ~ normal(0, 1);                         // Prior for latent variable (with mean/sd specified)\n  \n  for (item in 1:nItems){\n    Y[,item] ~ normal(mu[item] + lambda[item]*theta, psi[item]);\n  }\n}\n```\n:::\n\n\nThe loop here conducts the model via item response function (**IRF**) for each item:\n\n-   Assumption of conditional independence enables this\n\n    -   Non-independence would need multivariate normal model\n\n-   The item mean is set by the conditional mean of the model\n\n    -   The item SD is set by the unique variance parameter\n\n-   The loop puts each item's parameters into the question\n\n## Choosing Prior Distributions for Parameters\n\nThere is not uniform agreement about the choices of prior distributions for item parameters\n\n-   We will use **uninformative** priors on each to begin\n\n    -   After first model analysis, we will discuss these choices and why they were made\n\n-   For now:\n\n    -   Item intercepts: $\\mu_i \\sim N(0, \\sigma_{\\mu_i}^2 = 1000)$\n\n    -   Factor loadings / item discrimination: $\\lambda_i \\sim N(0, \\sigma^2_{\\lambda_i}=1000)$\n\n    -   Unique standard deviations: $\\psi_i \\sim \\text{exponential}(r_{\\psi_i} = .01)$\n\n## Prior Density Function Plots\n\n::: columns\n::: {.column width=\"50%\"}\nPrior distribution for item intercepts, factor loadings\n\nN(0, 1000)\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nset.seed(1234)\ndata.frame(\n  x = seq(0, 5, .001),\n  y = dnorm(x = seq(0, 5, .001), mean = 0, sd = sqrt(1000))\n) |> \n  ggplot(aes(x=x, y =y)) +\n  geom_path(linewidth = 1.3) +\n  labs(x = \"\", y = \"Probability\") +\n  theme_classic() +\n  theme(text = element_text(size = 25))\n```\n\n::: {.cell-output-display}\n![](Lecture07_files/figure-revealjs/unnamed-chunk-5-1.png){width=960}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\nPrior distribution of unique standard deviations\n\nExp(.01)\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndata.frame(\n  x = seq(0, 2, .001),\n  y = dexp(x = seq(0, 2, .001), rate = .01)\n  ) |> \n  ggplot(aes(x=x, y =y)) +\n  geom_path(linewidth = 1.3) +\n  labs(x = \"\", y = \"Probability\") +\n  theme_classic() +\n  theme(text = element_text(size = 25))\n```\n\n::: {.cell-output-display}\n![](Lecture07_files/figure-revealjs/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n:::\n:::\n\n## R's Data List Object\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnObs = nrow(conspiracyItems)\nnItems = ncol(conspiracyItems)\n\n# item intercept hyperparameters\nmuMeanHyperParameter = 0\nmuMeanVecHP = rep(muMeanHyperParameter, nItems)\n\nmuVarianceHyperParameter = 1000\nmuCovarianceMatrixHP = diag(x = muVarianceHyperParameter, nrow = nItems)\n\n# item discrimination/factor loading hyperparameters\nlambdaMeanHyperParameter = 0\nlambdaMeanVecHP = rep(lambdaMeanHyperParameter, nItems)\n\nlambdaVarianceHyperParameter = 1000\nlambdaCovarianceMatrixHP = diag(x = lambdaVarianceHyperParameter, nrow = nItems)\n\n# unique standard deviation hyperparameters\npsiRateHyperParameter = .01\npsiRateVecHP = rep(psiRateHyperParameter, nItems)\n\nmodelCFA_data = list(\n  nObs = nObs,\n  nItems = nItems,\n  Y = conspiracyItems, \n  meanMu = muMeanVecHP,\n  covMu = muCovarianceMatrixHP,\n  meanLambda = lambdaMeanVecHP,\n  covLambda = lambdaCovarianceMatrixHP,\n  psiRate = psiRateVecHP\n)\n```\n:::\n\n\n## Running the model in Stan\n\nThe total number of parameters is <mark>207</mark>.\n\n- 177 person parameters ($\\theta_1$ to $\\theta_{177}$)\n- 10 estimated parameters for item intercepts ($\\mu_{1-10}$), factor loadings ($\\lambda_{1-10}$), and unique standard deviation ($\\psi_{1-10}$).\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelCFA_samples$metadata()$model_params\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  [1] \"lp__\"       \"theta[1]\"   \"theta[2]\"   \"theta[3]\"   \"theta[4]\"  \n  [6] \"theta[5]\"   \"theta[6]\"   \"theta[7]\"   \"theta[8]\"   \"theta[9]\"  \n [11] \"theta[10]\"  \"theta[11]\"  \"theta[12]\"  \"theta[13]\"  \"theta[14]\" \n [16] \"theta[15]\"  \"theta[16]\"  \"theta[17]\"  \"theta[18]\"  \"theta[19]\" \n [21] \"theta[20]\"  \"theta[21]\"  \"theta[22]\"  \"theta[23]\"  \"theta[24]\" \n [26] \"theta[25]\"  \"theta[26]\"  \"theta[27]\"  \"theta[28]\"  \"theta[29]\" \n [31] \"theta[30]\"  \"theta[31]\"  \"theta[32]\"  \"theta[33]\"  \"theta[34]\" \n [36] \"theta[35]\"  \"theta[36]\"  \"theta[37]\"  \"theta[38]\"  \"theta[39]\" \n [41] \"theta[40]\"  \"theta[41]\"  \"theta[42]\"  \"theta[43]\"  \"theta[44]\" \n [46] \"theta[45]\"  \"theta[46]\"  \"theta[47]\"  \"theta[48]\"  \"theta[49]\" \n [51] \"theta[50]\"  \"theta[51]\"  \"theta[52]\"  \"theta[53]\"  \"theta[54]\" \n [56] \"theta[55]\"  \"theta[56]\"  \"theta[57]\"  \"theta[58]\"  \"theta[59]\" \n [61] \"theta[60]\"  \"theta[61]\"  \"theta[62]\"  \"theta[63]\"  \"theta[64]\" \n [66] \"theta[65]\"  \"theta[66]\"  \"theta[67]\"  \"theta[68]\"  \"theta[69]\" \n [71] \"theta[70]\"  \"theta[71]\"  \"theta[72]\"  \"theta[73]\"  \"theta[74]\" \n [76] \"theta[75]\"  \"theta[76]\"  \"theta[77]\"  \"theta[78]\"  \"theta[79]\" \n [81] \"theta[80]\"  \"theta[81]\"  \"theta[82]\"  \"theta[83]\"  \"theta[84]\" \n [86] \"theta[85]\"  \"theta[86]\"  \"theta[87]\"  \"theta[88]\"  \"theta[89]\" \n [91] \"theta[90]\"  \"theta[91]\"  \"theta[92]\"  \"theta[93]\"  \"theta[94]\" \n [96] \"theta[95]\"  \"theta[96]\"  \"theta[97]\"  \"theta[98]\"  \"theta[99]\" \n[101] \"theta[100]\" \"theta[101]\" \"theta[102]\" \"theta[103]\" \"theta[104]\"\n[106] \"theta[105]\" \"theta[106]\" \"theta[107]\" \"theta[108]\" \"theta[109]\"\n[111] \"theta[110]\" \"theta[111]\" \"theta[112]\" \"theta[113]\" \"theta[114]\"\n[116] \"theta[115]\" \"theta[116]\" \"theta[117]\" \"theta[118]\" \"theta[119]\"\n[121] \"theta[120]\" \"theta[121]\" \"theta[122]\" \"theta[123]\" \"theta[124]\"\n[126] \"theta[125]\" \"theta[126]\" \"theta[127]\" \"theta[128]\" \"theta[129]\"\n[131] \"theta[130]\" \"theta[131]\" \"theta[132]\" \"theta[133]\" \"theta[134]\"\n[136] \"theta[135]\" \"theta[136]\" \"theta[137]\" \"theta[138]\" \"theta[139]\"\n[141] \"theta[140]\" \"theta[141]\" \"theta[142]\" \"theta[143]\" \"theta[144]\"\n[146] \"theta[145]\" \"theta[146]\" \"theta[147]\" \"theta[148]\" \"theta[149]\"\n[151] \"theta[150]\" \"theta[151]\" \"theta[152]\" \"theta[153]\" \"theta[154]\"\n[156] \"theta[155]\" \"theta[156]\" \"theta[157]\" \"theta[158]\" \"theta[159]\"\n[161] \"theta[160]\" \"theta[161]\" \"theta[162]\" \"theta[163]\" \"theta[164]\"\n[166] \"theta[165]\" \"theta[166]\" \"theta[167]\" \"theta[168]\" \"theta[169]\"\n[171] \"theta[170]\" \"theta[171]\" \"theta[172]\" \"theta[173]\" \"theta[174]\"\n[176] \"theta[175]\" \"theta[176]\" \"theta[177]\" \"mu[1]\"      \"mu[2]\"     \n[181] \"mu[3]\"      \"mu[4]\"      \"mu[5]\"      \"mu[6]\"      \"mu[7]\"     \n[186] \"mu[8]\"      \"mu[9]\"      \"mu[10]\"     \"lambda[1]\"  \"lambda[2]\" \n[191] \"lambda[3]\"  \"lambda[4]\"  \"lambda[5]\"  \"lambda[6]\"  \"lambda[7]\" \n[196] \"lambda[8]\"  \"lambda[9]\"  \"lambda[10]\" \"psi[1]\"     \"psi[2]\"    \n[201] \"psi[3]\"     \"psi[4]\"     \"psi[5]\"     \"psi[6]\"     \"psi[7]\"    \n[206] \"psi[8]\"     \"psi[9]\"     \"psi[10]\"   \n```\n\n\n:::\n:::\n\n\n## Running the model in Stan\n\nDifferent seed will have different initial values that may leads to convergence. \n\n- `cmdstanr` sampling call:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelCFA_samples = modelCFA_stan$sample(\n  data = modelCFA_data,\n  seed = 09102022,\n  chains = 4,\n  parallel_chains = 4,\n  iter_warmup = 1000,\n  iter_sampling = 2000\n)\n```\n:::\n\n\n- The running time is about 2 seconds on my Macbook\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n$total\n[1] 2.199301\n\n$chains\n  chain_id warmup sampling total\n1        1  0.707    1.340 2.047\n2        2  0.697    1.340 2.037\n3        3  0.708    1.341 2.049\n4        4  0.682    1.341 2.023\n```\n\n\n:::\n:::\n\n\n- Note: Typically, longer chains are needed for larger models like this\n    - These will become even more longer when we use non-normal distributions for observed data\n\n## Model Results\n\n-   Checking convergence with $\\hat R$ (PSRF):\n\n    -   The maximum of $\\hat R$ is\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.00334\n```\n\n\n:::\n:::\n\n\n-   Item Response Results\n\n\n::: {.cell}\n::: {.cell-output-display  html-table-processing=none}\n`````{=html}\n<table class=\" lightable-classic lightable-hover\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; width: auto !important; margin-left: auto; margin-right: auto;'>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> variable </th>\n   <th style=\"text-align:right;\"> mean </th>\n   <th style=\"text-align:right;\"> median </th>\n   <th style=\"text-align:right;\"> sd </th>\n   <th style=\"text-align:right;\"> mad </th>\n   <th style=\"text-align:right;\"> q5 </th>\n   <th style=\"text-align:right;\"> q95 </th>\n   <th style=\"text-align:right;\"> rhat </th>\n   <th style=\"text-align:right;\"> ess_bulk </th>\n   <th style=\"text-align:right;\"> ess_tail </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> mu[1] </td>\n   <td style=\"text-align:right;\"> 2.36 </td>\n   <td style=\"text-align:right;\"> 2.36 </td>\n   <td style=\"text-align:right;\"> 0.09 </td>\n   <td style=\"text-align:right;\"> 0.09 </td>\n   <td style=\"text-align:right;\"> 2.22 </td>\n   <td style=\"text-align:right;\"> 2.50 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1367.36 </td>\n   <td style=\"text-align:right;\"> 2823.03 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> mu[2] </td>\n   <td style=\"text-align:right;\"> 1.95 </td>\n   <td style=\"text-align:right;\"> 1.95 </td>\n   <td style=\"text-align:right;\"> 0.09 </td>\n   <td style=\"text-align:right;\"> 0.09 </td>\n   <td style=\"text-align:right;\"> 1.81 </td>\n   <td style=\"text-align:right;\"> 2.09 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1055.36 </td>\n   <td style=\"text-align:right;\"> 2376.43 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> mu[3] </td>\n   <td style=\"text-align:right;\"> 1.87 </td>\n   <td style=\"text-align:right;\"> 1.87 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 1.74 </td>\n   <td style=\"text-align:right;\"> 2.01 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1209.55 </td>\n   <td style=\"text-align:right;\"> 2367.33 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> mu[4] </td>\n   <td style=\"text-align:right;\"> 2.01 </td>\n   <td style=\"text-align:right;\"> 2.01 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 0.09 </td>\n   <td style=\"text-align:right;\"> 1.87 </td>\n   <td style=\"text-align:right;\"> 2.14 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1081.83 </td>\n   <td style=\"text-align:right;\"> 2686.73 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> mu[5] </td>\n   <td style=\"text-align:right;\"> 1.98 </td>\n   <td style=\"text-align:right;\"> 1.98 </td>\n   <td style=\"text-align:right;\"> 0.09 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 1.84 </td>\n   <td style=\"text-align:right;\"> 2.12 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 821.40 </td>\n   <td style=\"text-align:right;\"> 1759.97 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> mu[6] </td>\n   <td style=\"text-align:right;\"> 1.89 </td>\n   <td style=\"text-align:right;\"> 1.89 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 1.76 </td>\n   <td style=\"text-align:right;\"> 2.01 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 817.01 </td>\n   <td style=\"text-align:right;\"> 1839.81 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> mu[7] </td>\n   <td style=\"text-align:right;\"> 1.72 </td>\n   <td style=\"text-align:right;\"> 1.72 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 1.59 </td>\n   <td style=\"text-align:right;\"> 1.85 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1065.73 </td>\n   <td style=\"text-align:right;\"> 2404.71 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> mu[8] </td>\n   <td style=\"text-align:right;\"> 1.84 </td>\n   <td style=\"text-align:right;\"> 1.84 </td>\n   <td style=\"text-align:right;\"> 0.07 </td>\n   <td style=\"text-align:right;\"> 0.07 </td>\n   <td style=\"text-align:right;\"> 1.72 </td>\n   <td style=\"text-align:right;\"> 1.96 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 845.53 </td>\n   <td style=\"text-align:right;\"> 1718.28 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> mu[9] </td>\n   <td style=\"text-align:right;\"> 1.80 </td>\n   <td style=\"text-align:right;\"> 1.80 </td>\n   <td style=\"text-align:right;\"> 0.09 </td>\n   <td style=\"text-align:right;\"> 0.09 </td>\n   <td style=\"text-align:right;\"> 1.66 </td>\n   <td style=\"text-align:right;\"> 1.95 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1074.97 </td>\n   <td style=\"text-align:right;\"> 2372.27 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> mu[10] </td>\n   <td style=\"text-align:right;\"> 1.52 </td>\n   <td style=\"text-align:right;\"> 1.52 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 1.38 </td>\n   <td style=\"text-align:right;\"> 1.65 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1506.57 </td>\n   <td style=\"text-align:right;\"> 2666.10 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> lambda[1] </td>\n   <td style=\"text-align:right;\"> 0.74 </td>\n   <td style=\"text-align:right;\"> 0.74 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 0.60 </td>\n   <td style=\"text-align:right;\"> 0.88 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 2774.39 </td>\n   <td style=\"text-align:right;\"> 4171.35 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> lambda[2] </td>\n   <td style=\"text-align:right;\"> 0.87 </td>\n   <td style=\"text-align:right;\"> 0.87 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 0.75 </td>\n   <td style=\"text-align:right;\"> 1.00 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1893.32 </td>\n   <td style=\"text-align:right;\"> 3822.33 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> lambda[3] </td>\n   <td style=\"text-align:right;\"> 0.80 </td>\n   <td style=\"text-align:right;\"> 0.80 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 0.68 </td>\n   <td style=\"text-align:right;\"> 0.93 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 2352.69 </td>\n   <td style=\"text-align:right;\"> 4185.55 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> lambda[4] </td>\n   <td style=\"text-align:right;\"> 0.84 </td>\n   <td style=\"text-align:right;\"> 0.84 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 0.07 </td>\n   <td style=\"text-align:right;\"> 0.72 </td>\n   <td style=\"text-align:right;\"> 0.97 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 2128.91 </td>\n   <td style=\"text-align:right;\"> 4208.40 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> lambda[5] </td>\n   <td style=\"text-align:right;\"> 1.00 </td>\n   <td style=\"text-align:right;\"> 1.00 </td>\n   <td style=\"text-align:right;\"> 0.07 </td>\n   <td style=\"text-align:right;\"> 0.07 </td>\n   <td style=\"text-align:right;\"> 0.89 </td>\n   <td style=\"text-align:right;\"> 1.12 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1343.00 </td>\n   <td style=\"text-align:right;\"> 2760.32 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> lambda[6] </td>\n   <td style=\"text-align:right;\"> 0.90 </td>\n   <td style=\"text-align:right;\"> 0.90 </td>\n   <td style=\"text-align:right;\"> 0.06 </td>\n   <td style=\"text-align:right;\"> 0.06 </td>\n   <td style=\"text-align:right;\"> 0.80 </td>\n   <td style=\"text-align:right;\"> 1.01 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1256.83 </td>\n   <td style=\"text-align:right;\"> 2822.40 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> lambda[7] </td>\n   <td style=\"text-align:right;\"> 0.77 </td>\n   <td style=\"text-align:right;\"> 0.76 </td>\n   <td style=\"text-align:right;\"> 0.07 </td>\n   <td style=\"text-align:right;\"> 0.07 </td>\n   <td style=\"text-align:right;\"> 0.65 </td>\n   <td style=\"text-align:right;\"> 0.88 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1922.80 </td>\n   <td style=\"text-align:right;\"> 3637.63 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> lambda[8] </td>\n   <td style=\"text-align:right;\"> 0.85 </td>\n   <td style=\"text-align:right;\"> 0.85 </td>\n   <td style=\"text-align:right;\"> 0.06 </td>\n   <td style=\"text-align:right;\"> 0.06 </td>\n   <td style=\"text-align:right;\"> 0.76 </td>\n   <td style=\"text-align:right;\"> 0.96 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1348.54 </td>\n   <td style=\"text-align:right;\"> 2607.39 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> lambda[9] </td>\n   <td style=\"text-align:right;\"> 0.86 </td>\n   <td style=\"text-align:right;\"> 0.86 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 0.74 </td>\n   <td style=\"text-align:right;\"> 1.00 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 2033.57 </td>\n   <td style=\"text-align:right;\"> 3537.83 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> lambda[10] </td>\n   <td style=\"text-align:right;\"> 0.67 </td>\n   <td style=\"text-align:right;\"> 0.67 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 0.08 </td>\n   <td style=\"text-align:right;\"> 0.55 </td>\n   <td style=\"text-align:right;\"> 0.80 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 3476.29 </td>\n   <td style=\"text-align:right;\"> 4664.41 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> psi[1] </td>\n   <td style=\"text-align:right;\"> 0.89 </td>\n   <td style=\"text-align:right;\"> 0.89 </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n   <td style=\"text-align:right;\"> 0.81 </td>\n   <td style=\"text-align:right;\"> 0.98 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 14162.28 </td>\n   <td style=\"text-align:right;\"> 6228.69 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> psi[2] </td>\n   <td style=\"text-align:right;\"> 0.73 </td>\n   <td style=\"text-align:right;\"> 0.73 </td>\n   <td style=\"text-align:right;\"> 0.04 </td>\n   <td style=\"text-align:right;\"> 0.04 </td>\n   <td style=\"text-align:right;\"> 0.67 </td>\n   <td style=\"text-align:right;\"> 0.81 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 12697.11 </td>\n   <td style=\"text-align:right;\"> 6128.65 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> psi[3] </td>\n   <td style=\"text-align:right;\"> 0.78 </td>\n   <td style=\"text-align:right;\"> 0.78 </td>\n   <td style=\"text-align:right;\"> 0.04 </td>\n   <td style=\"text-align:right;\"> 0.04 </td>\n   <td style=\"text-align:right;\"> 0.71 </td>\n   <td style=\"text-align:right;\"> 0.86 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 13849.89 </td>\n   <td style=\"text-align:right;\"> 6613.76 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> psi[4] </td>\n   <td style=\"text-align:right;\"> 0.76 </td>\n   <td style=\"text-align:right;\"> 0.76 </td>\n   <td style=\"text-align:right;\"> 0.04 </td>\n   <td style=\"text-align:right;\"> 0.04 </td>\n   <td style=\"text-align:right;\"> 0.69 </td>\n   <td style=\"text-align:right;\"> 0.83 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 13945.87 </td>\n   <td style=\"text-align:right;\"> 6457.77 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> psi[5] </td>\n   <td style=\"text-align:right;\"> 0.54 </td>\n   <td style=\"text-align:right;\"> 0.54 </td>\n   <td style=\"text-align:right;\"> 0.04 </td>\n   <td style=\"text-align:right;\"> 0.04 </td>\n   <td style=\"text-align:right;\"> 0.49 </td>\n   <td style=\"text-align:right;\"> 0.61 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 8672.12 </td>\n   <td style=\"text-align:right;\"> 7261.97 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> psi[6] </td>\n   <td style=\"text-align:right;\"> 0.50 </td>\n   <td style=\"text-align:right;\"> 0.50 </td>\n   <td style=\"text-align:right;\"> 0.03 </td>\n   <td style=\"text-align:right;\"> 0.03 </td>\n   <td style=\"text-align:right;\"> 0.45 </td>\n   <td style=\"text-align:right;\"> 0.56 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 9470.43 </td>\n   <td style=\"text-align:right;\"> 6372.91 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> psi[7] </td>\n   <td style=\"text-align:right;\"> 0.69 </td>\n   <td style=\"text-align:right;\"> 0.68 </td>\n   <td style=\"text-align:right;\"> 0.04 </td>\n   <td style=\"text-align:right;\"> 0.04 </td>\n   <td style=\"text-align:right;\"> 0.62 </td>\n   <td style=\"text-align:right;\"> 0.75 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 12904.57 </td>\n   <td style=\"text-align:right;\"> 6743.24 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> psi[8] </td>\n   <td style=\"text-align:right;\"> 0.48 </td>\n   <td style=\"text-align:right;\"> 0.48 </td>\n   <td style=\"text-align:right;\"> 0.03 </td>\n   <td style=\"text-align:right;\"> 0.03 </td>\n   <td style=\"text-align:right;\"> 0.43 </td>\n   <td style=\"text-align:right;\"> 0.53 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 9533.77 </td>\n   <td style=\"text-align:right;\"> 6643.96 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> psi[9] </td>\n   <td style=\"text-align:right;\"> 0.78 </td>\n   <td style=\"text-align:right;\"> 0.78 </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n   <td style=\"text-align:right;\"> 0.71 </td>\n   <td style=\"text-align:right;\"> 0.86 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 12473.18 </td>\n   <td style=\"text-align:right;\"> 5860.73 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> psi[10] </td>\n   <td style=\"text-align:right;\"> 0.84 </td>\n   <td style=\"text-align:right;\"> 0.84 </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n   <td style=\"text-align:right;\"> 0.77 </td>\n   <td style=\"text-align:right;\"> 0.92 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 14582.38 </td>\n   <td style=\"text-align:right;\"> 6001.16 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n",
    "supporting": [
      "Lecture07_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}