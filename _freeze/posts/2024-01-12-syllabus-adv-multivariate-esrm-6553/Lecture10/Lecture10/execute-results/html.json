{
  "hash": "b81e4ef6862b45a565a15e17c721c81f",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Lecture 10\"\nsubtitle: \"Generalized Measurement Models: Modeling Observed Polytomous Data\"\nauthor: \"Jihong Zhang\"\ninstitute: \"Educational Statistics and Research Methods\"\ntitle-slide-attributes:\n  data-background-image: ../Images/title_image.png\n  data-background-size: contain\nexecute: \n  echo: false\n  eval: false\nformat: \n  revealjs:\n    logo: ../Images/UA_Logo_Horizontal.png\n    incremental: false  # choose \"false \"if want to show all together\n    transition: slide\n    background-transition: fade\n    theme: [simple, ../pp.scss]\n    footer:  <https://jihongzhang.org/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553>\n    scrollable: true\n    slide-number: true\n    chalkboard: true\n    number-sections: false\n    code-line-numbers: true\n    code-annotations: below\n    code-copy: true\n    code-summary: ''\n    highlight-style: arrow\n    view: 'scroll' # Activate the scroll view\n    scrollProgress: true # Force the scrollbar to remain visible\n    mermaid:\n      theme: neutral\n#bibliography: references.bib\n---\n\n## Previous Class\n\n1.  Dive deep into factor scoring\n2.  Show how different initial values affect Bayesian model estimation\n3.  Show how parameterization differs for standardized latent variables vs. marker item scale identification\n\n## Today's Lecture Objectives\n\n1.  Show how to estimate unidimensional latent variable models with polytomous data\n    -   Also know as [Polytomous]{.underline} I[tem response theory]{.underline} (IRT) or [Item factor analysis]{.underline} (IFA)\n2.  Distributions appropriate for polytomous (discrete; data with lower/upper limits)\n\n## Example Data: Conspiracy Theories\n\n-   Today's example is from a bootstrap resample of 177 undergraduate students at a large state university in the Midwest.\n-   The survey was a measure of 10 questions about their beliefs in various conspiracy theories that were being passed around the internet in the early 2010s\n-   All item responses were on a 5-point Likert scale with:\n    1.  Strong Disagree $\\rightarrow$ 0\n    2.  Disagree $\\rightarrow$ 0\n    3.  Neither Agree nor Disagree $\\rightarrow$ 0\n    4.  Agree $\\rightarrow$ 1\n    5.  Strongly Agree $\\rightarrow$ 1\n-   The purpose of this survey was to study individual beliefs regarding conspiracies.\n-   Our purpose in using this instrument is to provide a context that we all may find relevant as many of these conspiracies are still prevalent.\n\n## From Previous Lectures: CFA (Normal Outcomes)\n\nFor comparisons today, we will be using the model where we assumed each outcome was (conditionally) normally distributed:\n\nFor an item $i$ the model is:\n\n$$\nY_{pi}=\\mu_i+\\lambda_i\\theta_p+e_{pi}\\\\\ne_{pi}\\sim N(0,\\psi_i^2)\n$$\n\nRecall that this assumption wasn't good one as the type of data (discrete, bounded, some multimodality) did not match the normal distribution assumption.\n\n## Polytomous Data Characteristics\n\nAs we have done with each observed variable, we must decide which distribution to use\n\n-   To do this, we need to map the characteristics of our data on to distributions that share those characteristics\n\nOur observed data:\n\n-   Discrete responses\n-   Small set of known categories: 1,2,3,4,5\n-   Some observed item responses may be multimodal\n\n## Discrete Data Distributions\n\n[Stan](https://mc-stan.org/docs/functions-reference/bounded_discrete_distributions.html) has a list of distributions for bounded discrete data\n\n1.  Binomial distribution\n    -   Pro: Easy to use / code\n    -   Con: Unimodal distribution\n2.  Beta-binomial distribution\n    -   Not often used in psychometrics (but could be)\n    -   Generalizes binomial distribution to have different probability for each trial\n3.  Hypergeometric distribution\n    -   Not often used in psychometrics\n4.  Categorical distribution (sometimes called multinomial)\n    -   Most frequently used\n    -   Base distribution for graded response, partial credit, and nominal response models\n5.  Discrete range distribution (sometimes called uniform)\n    -   Not useful–doesn't have much information about latent variables\n\n# Binomial Distribution Models\n\n## Binomial Distribution Models\n\nThe binomial distribution is one of the easiest to use for polytomous items\n\n-   However, it assumes the distribution of responses are unimodal\n\nBinomial probability mass function (i.e., pdf):\n\n$$\nP(Y=y)=\\begin{pmatrix}n\\\\y\\end{pmatrix}p^y(1-p)^{(n-y)}\n$$\n\nParameters:\n\n-   n - \"number of trials\" (range: $n \\in \\{0, 1, \\dots\\}$)\n-   y - \"number of successes\" out of $n$ \"trials\" (range: $y\\in\\{0,1,\\dots,n\\}$)\n-   p - \"probability of success\" (range: \\[0, 1\\])\n-   Mean: $np$\n-   Variance: $np(1-p)$\n\n## Adapting the Binomial for Item Response Models\n\nAlthough it doesn't seem like our items fit with a binomial, we can actually use this distribution\n\n-   Item response: number of successes $y_i$\n    -   Needed: recode data so that lowest category is 0 (subtract one from each item)\n-   Highest (recoded) item response: number of trials $n$\n    -   For all out items, once recoded, $n_i = 4$\n-   Then, use a link function to model each item's $p_i$ as a function of the latent trait:\n\n$$\nP(Y_i=y_i)=\\begin{pmatrix}4\\\\y_i\\end{pmatrix}p^{y_i}(1-p)^{(4-y_i)}\n$$\n\nwhere probability of success of item $i$ for individual $p$ is as:\n\n$$\np_{pi}=\\frac{\\text{exp}(\\mu_i+\\lambda_i\\theta_p)}{1+\\text{exp}(\\mu_i+\\lambda_i\\theta_p)}\n$$\n\nNote:\n\n-   Shown with a logit link function (but could be any link)\n-   Shown in slope/intercept form (but could be distrimination/difficulty for unidimensional items)\n-   Could also include asymptote parameters ($c_i$ or $d_i$)\n\n## Binomial Item Response Model\n\nThe item response model, put into the PDF of the binomial is then:\n\n$$\nP(Y_{pi}|\\theta_p)=\\begin{pmatrix}n_i\\\\Y_{pi}\\end{pmatrix}(\\frac{\\text{exp}(\\mu_i+\\lambda_i\\theta_p)}{1+\\text{exp}(\\mu_i+\\lambda_i\\theta_p)})^{y_{pi}}(1-\\frac{\\text{exp}(\\mu_i+\\lambda_i\\theta_p)}{1+\\text{exp}(\\mu_i+\\lambda_i\\theta_p)})^{4-y_{pi}}\n$$\n\nFurther, we can use the same priors as before on each of our item parameters\n\n-   $\\mu_i$: Normal Prior $N(0, 100)$\n\n-   $\\lambda_i$: Normal prior $N(0, 100)$\n\nLikewise, we can identify the scale of the latent variable as before, too:\n\n-   $\\theta_p \\sim N(0,1)$\n\n## `model{}`  for the Binomial Model in Stan\n\n\n```{stan, output.var='display'}\n#| echo: true\nmodel {\n  lambda ~ multi_normal(meanLambda, covLambda); // Prior for item discrimination/factor loadings\n  mu ~ multi_normal(meanMu, covMu);             // Prior for item intercepts\n  theta ~ normal(0, 1);                         // Prior for latent variable (with mean/sd specified)\n  for (item in 1:nItems){\n    Y[item] ~ binomial(maxItem[item], inv_logit(mu[item] + lambda[item]*theta));\n  }\n}\n```\n\n\nHere, the binomial [item response function]{.underline} has two arguments:\n\n-   The **first** part: (`maxItem[Item]`) is the number of \"trials\" $n_i$ (here, our maximum score minus one – 4)\n-   The **second** part: (`inv_logit(mu[item] + lambda[item]*theta)`) is the probability from our model ($p_i$)\n\nThe data `Y[item]` must be:\n\n-   Type: integer\n-   Range: 0 through `maxItem[item]`\n\n## `parameters{}` for the Binomial Model in Stan\n\n\n```{stan, output.var='display'}\n#| echo: true\nparameters{\n  vector[nObs] theta;                // the latent variables (one for each person)\n  vector[nItems] mu;                 // the item intercepts (one for each item)\n  vector[nItems] lambda;             // the factor loadings/item discriminations (one for each item)\n}\n```\n\n\nNo changes from any of our previous slope/intercept models\n\n## `data{}` for the Binomial Model in Stan\n\n\n```{stan, output.var='display'}\n#| echo: true\ndata {\n  int<lower=0> nObs;                     // number of observations\n  int<lower=0> nItems;                   // number of items\n  array[nItems] int<lower=0> maxItem;    // maximum value of Item (should be 4 for 5-point Likert)\n  \n  array[nItems, nObs] int<lower=0>  Y;   // item responses in an array\n\n  vector[nItems] meanMu;                 // prior mean vector for intercept parameters\n  matrix[nItems, nItems] covMu;          // prior covariance matrix for intercept parameters\n  \n  vector[nItems] meanLambda;             // prior mean vector for discrimination parameters\n  matrix[nItems, nItems] covLambda;      // prior covariance matrix for discrimination parameters\n}\n```\n\n\nNote:\n\n-   Need to supply `maxItem` (maximum score minus one for each item)\n\n-   The data are the same (integer) as in the binary/dichotomous item syntax\n\n## Discriminatin/Difficulty Parameterization\n\nThe slope/intercept form\n\n## Resources\n\n-   [Dr. Templin's slide](https://jonathantemplin.github.io/Bayesian-Psychometric-Modeling-Course-Fall2022/lectures/lecture04d/04d_Modeling_Observed_Polytomous_Data#/binomial-model-data-block)\n\n",
    "supporting": [
      "Lecture10_files"
    ],
    "filters": [],
    "includes": {}
  }
}