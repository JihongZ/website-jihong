{
  "hash": "ec0f7bb1fc175793cd223ffd696ba0b8",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lecture 04\"\nsubtitle: \"Linear Regression Model with Stan II\"\nauthor: \"Jihong Zhang\"\ninstitute: \"Educational Statistics and Research Methods\"\ntitle-slide-attributes:\n  data-background-image: ../Images/title_image.png\n  data-background-size: contain\n  data-background-opacity: \"0.9\"\nexecute: \n  echo: true\nformat: \n  revealjs:\n    logo: ../Images/UA_Logo_Horizontal.png\n    incremental: true  # choose \"false \"if want to show all together\n    theme: [serif, ../pp.scss]\n    footer:  <https://jihongzhang.org/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553>\n    transition: slide\n    background-transition: fade\n    slide-number: true\n    chalkboard: true\n    number-sections: false\n    code-line-numbers: true\n    code-link: true\n    code-annotations: hover\n    code-copy: true\n    highlight-style: arrow\n    code-block-border-left: true\n    code-block-background: \"#b22222\"\n---\n\n\n## Today's Lecture Objectives\n\n1.  Making Stan Syntax Shorter\n\n2.  Computing Functions of Model Parameters\n\n    **Download R file [DietDataExample2.R]{.underline}**\n\n## In previous class...\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R code for data read in\"}\nlibrary(cmdstanr)\nlibrary(bayesplot)\nlibrary(tidyr)\nlibrary(dplyr)\ncolor_scheme_set('brightblue')\ndat <- read.csv(here::here(\"posts\", \"2024-01-12-syllabus-adv-multivariate-esrm-6553\", \"Lecture03\", \"Code\", \"DietData.csv\"))\ndat$DietGroup <- factor(dat$DietGroup, levels = 1:3)\ndat$HeightIN60 <- dat$HeightIN - 60\nkableExtra::kable( rbind(head(dat), tail(dat)) ) |> kableExtra::kable_classic_2() |> \n  kableExtra::kable_styling(full_width = F, font_size = 15)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-classic-2 table\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; margin-left: auto; margin-right: auto; font-size: 15px; width: auto !important; margin-left: auto; margin-right: auto;'>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> Respondent </th>\n   <th style=\"text-align:left;\"> DietGroup </th>\n   <th style=\"text-align:right;\"> HeightIN </th>\n   <th style=\"text-align:right;\"> WeightLB </th>\n   <th style=\"text-align:right;\"> HeightIN60 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:right;\"> 56 </td>\n   <td style=\"text-align:right;\"> 140 </td>\n   <td style=\"text-align:right;\"> -4 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:right;\"> 60 </td>\n   <td style=\"text-align:right;\"> 155 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3 </td>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:right;\"> 64 </td>\n   <td style=\"text-align:right;\"> 143 </td>\n   <td style=\"text-align:right;\"> 4 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4 </td>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:right;\"> 68 </td>\n   <td style=\"text-align:right;\"> 161 </td>\n   <td style=\"text-align:right;\"> 8 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 5 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:right;\"> 72 </td>\n   <td style=\"text-align:right;\"> 139 </td>\n   <td style=\"text-align:right;\"> 12 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 6 </td>\n   <td style=\"text-align:right;\"> 6 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:right;\"> 54 </td>\n   <td style=\"text-align:right;\"> 159 </td>\n   <td style=\"text-align:right;\"> -6 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 25 </td>\n   <td style=\"text-align:right;\"> 25 </td>\n   <td style=\"text-align:left;\"> 3 </td>\n   <td style=\"text-align:right;\"> 70 </td>\n   <td style=\"text-align:right;\"> 259 </td>\n   <td style=\"text-align:right;\"> 10 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 26 </td>\n   <td style=\"text-align:right;\"> 26 </td>\n   <td style=\"text-align:left;\"> 3 </td>\n   <td style=\"text-align:right;\"> 52 </td>\n   <td style=\"text-align:right;\"> 201 </td>\n   <td style=\"text-align:right;\"> -8 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 27 </td>\n   <td style=\"text-align:right;\"> 27 </td>\n   <td style=\"text-align:left;\"> 3 </td>\n   <td style=\"text-align:right;\"> 59 </td>\n   <td style=\"text-align:right;\"> 228 </td>\n   <td style=\"text-align:right;\"> -1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 28 </td>\n   <td style=\"text-align:right;\"> 28 </td>\n   <td style=\"text-align:left;\"> 3 </td>\n   <td style=\"text-align:right;\"> 64 </td>\n   <td style=\"text-align:right;\"> 245 </td>\n   <td style=\"text-align:right;\"> 4 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 29 </td>\n   <td style=\"text-align:right;\"> 29 </td>\n   <td style=\"text-align:left;\"> 3 </td>\n   <td style=\"text-align:right;\"> 65 </td>\n   <td style=\"text-align:right;\"> 241 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 30 </td>\n   <td style=\"text-align:right;\"> 30 </td>\n   <td style=\"text-align:left;\"> 3 </td>\n   <td style=\"text-align:right;\"> 72 </td>\n   <td style=\"text-align:right;\"> 269 </td>\n   <td style=\"text-align:right;\"> 12 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n1.  Introduce the empty model\n2.  Example: Post-Diet Weights\n    -   WeightLB (*Dependent Variable*): The respondents' weight in pounds\n    -   HeightIN: The respondents' height in inches\n    -   DietGroup: 1, 2, 3 representing the group to which a respondent was assigned\n3.  The empty model has two parameters to be estimated: (1) $\\beta_0$, (2) $\\sigma_e$\n4.  The posterior mean/median of $\\beta_0$ should be mean of WeightLB\n5.  The posterior mean/median of $\\sigma_e$ should be sd of WeightLB\n:::\n:::\n\n## Making `Stan` Code Short and Efficient\n\nThe Stan syntax from our previous model was lengthy:\n\n-   A declared variable for each parameter\n-   The linear combination of coefficients by multiplying predictors\n\nStan has built-in features to shorten syntax:\n\n-   Matrices/Vectors\n-   Matrix products\n-   Multivariate distribution (initially for prior distributions)\n-   Built-in Functions (`sum()` better than `+=`)\n\nNote: if you are interested in Efficiency tuning in Stan, look at this [Charpter](https://mc-stan.org/docs/stan-users-guide/efficiency-tuning.html) for more details.\n\n------------------------------------------------------------------------\n\n## Linear Models without Matrices\n\nThe linear model from our example was:\n\n$$\n\\text{WeightLB}_p = \\beta_0 + \\beta_1 \\text{HeightIN}_p + \\beta_2 \\text{Group2}_p + \\beta_3\\text{Group3}_p \\\\ \n+\\beta_4 \\text{HeightIN}_p\\text{Group2}_p \\\\\n+\\beta_5 \\text{HeightIN}_p\\text{Group3}_p \\\\\n+ e_p\n$$\n\nwith:\n\n-   $\\text{Group2}_p$ the binary indicator of person $p$ being in group 2\n\n-   $\\text{Group}3_p$ the binary indicator of person $p$ being in group 3\n\n-   $e_p \\sim N(0, \\sigma_e)$\n\n------------------------------------------------------------------------\n\n### Path Diagram of the Full Model\n\n\n```{mermaid}\n%%| echo: false\n%%| label: fig-diagram\ngraph LR;\n  HeightIN60 --> WeightLB;\n  DietGroup2 --> WeightLB;\n  DietGroup3 --> WeightLB;\n  HeightIN60xDietGroup2 --> WeightLB;\n  HeightIN60xDietGroup3 --> WeightLB;\n```\n\n\n------------------------------------------------------------------------\n\n## Linear Models with Matrices\n\n::: columns\n::: {.column width=\"50%\"}\nModel (predictor) matrix with the size 30 (rows) $\\times$ 6 (columns)\n\n$$\n\\mathbf{X} = \\begin{bmatrix}1 & -4 & 0 & 0 & 0 & 0\\\\\n\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n1 & 12 & 0 & 1 & 0 & 12 \\end{bmatrix}\n$$\n:::\n\n::: {.column width=\"50%\"}\nCoefficients vectors with the size 6 (rows) $\\times$ 1 (column):\n\n$$\n\\mathbf{\\beta} =\n\\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\beta_2 \\\\\n\\beta_3 \\\\\n\\beta_4 \\\\\n\\beta_5 \\\\\n\\end{bmatrix}\n$$\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nFullModelFormula = as.formula(\"WeightLB ~ HeightIN60 + DietGroup + HeightIN60*DietGroup\")\nmodel.matrix(FullModelFormula, data = dat) |> head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  (Intercept) HeightIN60 DietGroup2 DietGroup3 HeightIN60:DietGroup2\n1           1         -4          0          0                     0\n2           1          0          0          0                     0\n3           1          4          0          0                     0\n4           1          8          0          0                     0\n5           1         12          0          0                     0\n6           1         -6          0          0                     0\n  HeightIN60:DietGroup3\n1                     0\n2                     0\n3                     0\n4                     0\n5                     0\n6                     0\n```\n\n\n:::\n:::\n\n\n## Linear Models with Matrices (Cont.)\n\nWe then rewrite the equation from\n\n$$\n\\text{WeightLB}_p = \\beta_0 + \\beta_1 \\text{HeightIN}_p + \\beta_2 \\text{Group2}_p + \\beta_3\\text{Group3}_p \\\\ \n+\\beta_4 \\text{HeightIN}_p\\text{Group2}_p \\\\\n+\\beta_5 \\text{HeightIN}_p\\text{Group3}_p \\\\\n+ e_p\n$$\n\nto:\n\n$$\n\\mathbf{WeightLB} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{e} \n$$\n\nWhere:\n\n-   $\\mathbf{WeightLB}$ is the vector of outcome (N $\\times$ 1)\n\n-   $\\mathbf{X}$ is the model (predictor) matrix (N $\\times$ P for P - 1 predictors)\n\n-   $\\boldsymbol{\\beta}$ is the coefficients vector (P $\\times$ 1)\n\n-   $\\mathbf{e}$ is the vector for residuals (N $\\times$ 1)\n\n------------------------------------------------------------------------\n\n### Example: Predicted Values and $\\text{R}^2$\n\n::: columns\n::: {.column width=\"50%\"}\n**Similar to Monte Carlo Simulation, given** matrices $P$ **and** $\\boldsymbol{\\beta}$\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nset.seed(1234)\nfit_lm <- lm(formula = FullModelFormula, data = dat)\n\nbeta = coefficients(fit_lm)\nP = length(beta)\nX = model.matrix(FullModelFormula, data = dat)\nhead(X%*%beta)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      [,1]\n1 149.0639\n2 147.5566\n3 146.0493\n4 144.5419\n5 143.0346\n6 149.8176\n```\n\n\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n**Calculating** $R^2$ **and adjusted** $R^2$**:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrss = crossprod(dat$WeightLB - X%*%beta) # residual sum of squares\ntss = crossprod(dat$WeightLB - mean(dat$WeightLB)) # total sum of squares\nR2 = 1 - rss / tss\nR2.adjust = 1 - (rss/(nrow(dat)-P)) / (tss/((nrow(dat)-1)))\ndata.frame(\n  R2, # r-square\n  R2.adjust # adjusted. r-square\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         R2 R2.adjust\n1 0.9786724 0.9742292\n```\n\n\n:::\n:::\n\n\n**`lm` function:** $R^2$ **and adjusted** $R^2$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary_lm <- summary(fit_lm)\nsummary_lm$r.squared\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9786724\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary_lm$adj.r.squared\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9742292\n```\n\n\n:::\n:::\n\n:::\n:::\n\n## Vectorize prior distributions\n\nPreviously, we defined a normal distribution for each regression coefficient $$\n\\beta_0 \\sim normal(0, 1) \\\\\n\\vdots \\\\\n\\beta_p \\sim normal(0, 1)\n$$\n\n-   They are all univariate normal distribution\n-   Issue: Each parameter had a prior that was independent of the other parameter; then the correlation between betas is low and cannot be changed.\n\nFor example, the code shows two betas with univariate normal distribution have low correlation (r = -0.025)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\nbeta0 = rnorm(100, 0, 1)\nbeta1 = rnorm(100, 0, 1)\ncor(beta0, beta1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.02538285\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Vectorize prior distributions (Cont.)\n\nWhen combining all parameters into a vector, a natural extension is a multivariate normal distribution, so that the betas have a pre-defined correlation strength\n\n-   The syntax shows the two betas generated by the multivariate normal distribution with correlation of .5\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\nsigma_of_betas = matrix(c(1, 0.5, 0.5, 1), ncol = 2)\nbetas = mvtnorm::rmvnorm(100, mean = c(0, 0), sigma = sigma_of_betas)\nbeta0 = betas[,1]\nbeta1 = betas[,2]\ncor(beta0, beta1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.5453899\n```\n\n\n:::\n:::\n\n\nBack to the `stan` code, we need to specify:\n\n-   Mean vector of betas (`meanBeta`; size P $\\times$ 1)\n    -   Put all prior means for those coefficients into a vector\n-   Covariance matrix for betas (`covBeta`; size P $\\times$ P)\n    -   Put all prior variances into the diagonal; zeros for off diagonal; 'cause we are not sure the potential correlation between betas\n\n## Syntax Changes: Data Section\n\n::: columns\n::: {.column width=\"50%\"}\n::: nonincremental\n-   **Old syntax without matrix:**\n\n\n::: {.cell output.var='display'}\n\n```{.stan .cell-code}\ndata{\n    int<lower=0> N;\n    vector[N] weightLB;\n    vector[N] height60IN;\n    vector[N] group2;\n    vector[N] group3;\n    vector[N] heightXgroup2;\n    vector[N] heightXgroup3;\n}\n```\n:::\n\n:::\n:::\n\n::: {.column width=\"50%\"}\n::: nonincremental\n-   **New syntax with matrix:**\n:::\n\n\n::: {.cell output.var='display'}\n\n```{.stan .cell-code}\ndata{\n  int<lower=0> N;         // number of observations\n  int<lower=0> P;         // number of predictors (plus column for intercept)\n  matrix[N, P] X;         // model.matrix() from R \n  vector[N] weightLB;     // outcome\n  real sigmaRate;         // hyperparameter: rate parameter for residual standard deviation\n}\n```\n:::\n\n:::\n:::\n\n## Syntax Changes: Parameters Section\n\n::: columns\n::: {.column width=\"50%\"}\n::: nonincremental\n-   **Old syntax without matrix:**\n:::\n\n\n::: {.cell output.var='display'}\n\n```{.stan .cell-code}\nparameters {\n  real beta0;\n  real betaHeight;\n  real betaGroup2;\n  real betaGroup3;\n  real betaHxG2;\n  real betaHxG3;\n  real<lower=0> sigma;\n}\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n::: nonincremental\n-   **New syntax with matrix:**\n:::\n\n\n::: {.cell output.var='display'}\n\n```{.stan .cell-code}\nparameters {\n  vector[P] beta;         // vector of coefficients for Beta\n  real<lower=0> sigma;    // residual standard deviation\n}\n```\n:::\n\n:::\n:::\n\n## Syntax Changes: Prior Distributions Definition\n\n::: columns\n::: {.column width=\"50%\"}\n::: nonincremental\n-   **Old syntax without matrix:**\n:::\n\n\n::: {.cell output.var='display'}\n\n```{.stan .cell-code  code-line-numbers=\"|2-8|9-12\"}\nmodel {\n  beta0 ~ normal(0,100);\n  betaHeight ~ normal(0,100);\n  betaGroup2 ~ normal(0,100);\n  betaGroup3 ~ normal(0,100);\n  betaHxG2 ~ normal(0,100);\n  betaHxG3 ~ normal(0,100);\n  sigma ~ exponential(.1); // prior for sigma\n  weightLB ~ normal(\n    beta0 + betaHeight * height60IN + betaGroup2 * group2 + \n    betaGroup3*group3 + betaHxG2*heightXgroup2 +\n    betaHxG3*heightXgroup3, sigma);\n}\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n**New syntax with matrix:**\n\n::: nonincremental\n-   `multi_normal()` is the multivariate normal sampling in Stan, similar to `rmvnorm()` in R; For uninformative, we did not need to specify\n-   `exponential()` is the exponential distribution sampling in Stan, similar to `rexp()` in R\n:::\n\n\n::: {.cell output.var='display'}\n\n```{.stan .cell-code  code-line-numbers=\"|3\"}\nmodel {\n  sigma ~ exponential(sigmaRate);         // prior for sigma\n  weightLB ~ normal(X*beta, sigma);       // linear model\n}\n```\n:::\n\n:::\n:::\n\n------------------------------------------------------------------------\n\n### A little more about exponential distribution\n\n-   The mean of the exp. distribution is $\\frac{1}{\\lambda}$, where $\\lambda$ is called **rate parameter**\n-   The variance of the exp. distribution is $\\frac{1}{\\lambda^2}$\n-   It is typically positive skewed (skewness is 2)\n-   Question: which hyperparameter rate $\\lambda$ is most informative/uninformative\n\n\n::: {.cell .fig-cap-location-top output-location='slide'}\n\n```{.r .cell-code  code-line-numbers=\"1-3|4|5|7-16\"}\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(ggplot2)\nrate_list = seq(0.1, 1, 0.2)\npdf_points = sapply(rate_list, \\(x) dexp(seq(0, 20, 0.01), x)) |> as.data.frame()\ncolnames(pdf_points) <- rate_list\npdf_points$x = seq(0, 20, 0.01)\npdf_points %>% \n  pivot_longer(-x, values_to = 'y') %>% \n  mutate(\n    sigmaRate = factor(name, levels = rate_list)\n    ) %>% \n  ggplot() +\n  geom_path(aes(x = x, y = y, color = sigmaRate, group = sigmaRate), size = 1.2) +\n  scale_x_continuous(limits = c(0, 20)) +\n  labs(x = \"Sigma\")\n```\n\n::: {.cell-output-display}\n![PDF for the exponential distribution by varied rate parameters](Lecture04_files/figure-revealjs/fig-pdf-exp-1.png){#fig-pdf-exp width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Since we talked about Exponential distribution...\n\n::: columns\n::: {.column width=\"50%\"}\nLet's dive deeper into Laplace distribution. It is sometimes called double-exponential distribution. Exponential distribution is positive part of Laplace distribution.\n\n$$\n\\text{PDF}_{exp.} = \\lambda e^{-\\lambda x}\n$$\n\n$$\n\\text{PDF}_{laplace} = \\frac{1}{2b} e^{-\\frac{|x - u|}{b}}\n$$\n\n-   Thus, we know that for x \\> 0, exponential distribution is a special case of Laplace distribution with scale parameter $b$ as $\\frac{1}{\\lambda}$ and location parameter as 0.\n\n-   Laplace-based distribution, Cauchy, and Horseshoe distribution all belong to so-called \"**shrinkage**\" priors.\n:::\n\n::: {.column width=\"50%\"}\n-   Shrinkage priors will be very useful for high-dimensional data (say P = 1000) and variable selection\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(LaplacesDemon)\nb_list = 1 / rate_list * 2\npdf_points = sapply(b_list, \\(x) dlaplace(seq(-20, 20, 0.01), scale = x, location = 0)) |> as.data.frame()\ncolnames(pdf_points) <- round(b_list, 2)\npdf_points$x = seq(-20, 20, 0.01)\npdf_points %>% \n  pivot_longer(-x, values_to = 'y') %>% \n  mutate(\n    scale = factor(name, levels = round(b_list, 2))\n    ) %>% \n  ggplot() +\n  geom_path(aes(x = x, y = y, color = scale, group = scale), size = 1.2) +\n  scale_x_continuous(limits = c(-20, 20)) +\n  labs(x = \"\")\n```\n\n::: {.cell-output-display}\n![](Lecture04_files/figure-revealjs/unnamed-chunk-16-1.png){width=960}\n:::\n:::\n\n:::\n:::\n\n------------------------------------------------------------------------\n\n## Compare results and computational time\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmod_full_old <- cmdstan_model(\"Code/FullModel_Old.stan\")\ndata_full_old <- list(\n  N = nrow(dat),\n  weightLB = dat$WeightLB,\n  height60IN = dat$HeightIN60,\n  group2 = as.numeric(dat$DietGroup == 2),\n  group3 = as.numeric(dat$DietGroup == 3),\n  heightXgroup2 = as.numeric(dat$DietGroup == 2) * dat$HeightIN60,\n  heightXgroup3 = as.numeric(dat$DietGroup == 3) * dat$HeightIN60\n)\nfit_full_old <- mod_full_old$sample(\n  data = data_full_old,\n  seed = 1234,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 0\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_full_old$summary()[, -c(9, 10)]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 8 × 8\n  variable      mean  median    sd   mad     q5     q95  rhat\n  <chr>        <dbl>   <dbl> <dbl> <dbl>  <dbl>   <dbl> <dbl>\n1 lp__       -76.7   -76.3   2.17  2.00  -80.8  -73.8    1.00\n2 beta0      148.    148.    3.26  3.20  142.   153.     1.00\n3 betaHeight  -0.370  -0.378 0.495 0.488  -1.17   0.437  1.00\n4 betaGroup2 -24.2   -24.1   4.59  4.52  -31.6  -16.4    1.00\n5 betaGroup3  81.2    81.1   4.31  4.36   74.6   88.5    1.00\n6 betaHxG2     2.46    2.45  0.690 0.678   1.34   3.59   1.00\n7 betaHxG3     3.56    3.55  0.658 0.648   2.48   4.66   1.00\n8 sigma        8.26    8.10  1.23  1.13    6.52  10.5    1.00\n```\n\n\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmod_full_new <- cmdstan_model(\"Code/FullModel_New.stan\")\nFullModelFormula = as.formula(\"WeightLB ~ HeightIN60 + DietGroup + HeightIN60*DietGroup\")\nX = model.matrix(FullModelFormula, data = dat)\ndata_full_new <- list(\n  N = nrow(dat),\n  P = ncol(X),\n  X = X, \n  weightLB = dat$WeightLB,\n  sigmaRate = 0.1\n)\nfit_full_new <- mod_full_new$sample(\n  data = data_full_new,\n  seed = 1234,\n  chains = 4,\n  parallel_chains = 4\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_full_new$summary()[, -c(9, 10)]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 8 × 8\n  variable    mean  median    sd   mad     q5     q95  rhat\n  <chr>      <dbl>   <dbl> <dbl> <dbl>  <dbl>   <dbl> <dbl>\n1 lp__     -76.6   -76.3   2.15  2.00  -80.6  -73.9    1.00\n2 beta[1]  148.    148.    3.27  3.23  142.   153.     1.00\n3 beta[2]   -0.374  -0.372 0.483 0.479  -1.16   0.414  1.00\n4 beta[3]  -24.1   -24.2   4.59  4.45  -31.6  -16.5    1.00\n5 beta[4]   81.3    81.3   4.44  4.40   74.1   88.5    1.00\n6 beta[5]    2.47    2.48  0.683 0.676   1.32   3.56   1.00\n7 beta[6]    3.57    3.57  0.646 0.643   2.52   4.62   1.00\n8 sigma      8.25    8.10  1.26  1.20    6.50  10.5    1.00\n```\n\n\n:::\n:::\n\n:::\n:::\n\nThe differences between two method:\n\n-   `betaGroup3` has the largest differences between two methods\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncbind(fit_full_old$summary()[,1], fit_full_old$summary()[, -c(1, 9, 10)] - fit_full_new$summary()[, -c(1, 9, 10)])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    variable         mean     median            sd          mad        q5\n1       lp__ -0.007672400  0.0063000  0.0242926098  0.007931910 -0.115880\n2      beta0  0.071524500  0.1155000 -0.0135811270 -0.029652000 -0.102200\n3 betaHeight  0.004062205 -0.0067305  0.0121231572  0.008502340 -0.018165\n4 betaGroup2 -0.013670300  0.0513000 -0.0005405792  0.069904590 -0.037665\n5 betaGroup3 -0.103896750 -0.2107500 -0.1281290904 -0.041068020  0.468720\n6   betaHxG2 -0.019823355 -0.0341300  0.0072874047  0.001823598  0.020645\n7   betaHxG3 -0.010911025 -0.0213900  0.0116900063  0.005040840 -0.041349\n8      sigma  0.011585872  0.0005500 -0.0326167204 -0.068377512  0.021184\n          q95          rhat\n1  0.03527000  2.381442e-03\n2  0.00740000  1.491287e-04\n3  0.02306265  1.225973e-03\n4  0.07863000  4.621964e-05\n5 -0.04479000 -4.035145e-05\n6  0.02261500  5.967744e-04\n7  0.03879350  6.457172e-05\n8 -0.00486500  2.857860e-04\n```\n\n\n:::\n:::\n\n\n## Compare computational time\n\n-   The Stan code with matrix has faster computation:\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_full_old$time()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$total\n[1] 0.2029581\n\n$chains\n  chain_id warmup sampling total\n1        1  0.054    0.043 0.097\n2        2  0.063    0.050 0.113\n3        3  0.057    0.053 0.110\n4        4  0.054    0.044 0.098\n```\n\n\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_full_new$time()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$total\n[1] 0.16032\n\n$chains\n  chain_id warmup sampling total\n1        1  0.030    0.028 0.058\n2        2  0.036    0.033 0.069\n3        3  0.036    0.033 0.069\n4        4  0.032    0.030 0.062\n```\n\n\n:::\n:::\n\n:::\n:::\n\n-   Pros: With matrices, there is less syntax to write\n\n    -   Model is equivalent\n    -   More efficient for sampling (sample from matrix space)\n    -   More flexible: modify matrix elements in R instead of individual parameters in Stan\n\n-   Cons: Output, however, is not labeled with respect to parameters\n\n    -   May have to label output\n\n## Computing Functions of Parameters\n\n-   Often, we need to compute some linear or non-linear function of parameters in a linear model\n\n    -   Missing effects - beta for diet group 2 and 3\n\n    -   Model fit indices: $R^2$\n\n    -   Transformed effects - residual variance $\\sigma^2$\n\n-   In non-Bayesian (frequentist) analyses, there are often formed with the point estimates of parameters (with standard errors - second derivative of likelihood function)\n\n-   For Bayesian analyses, however, we seek to build the posterior distribution for any function of parameters\n\n    -   This means applying the function to all posterior samples\n    -   It is especially useful when you want to propose your new statistic\n\n------------------------------------------------------------------------\n\n### Example: Need Slope for Diet Group 2\n\nRecall our model:\n\n$$\n\\text{WeightLB}_p = \\beta_0 + \\beta_1 \\text{HeightIN}_p + \\beta_2 \\text{Group2}_p + \\beta_3\\text{Group3}_p \\\\ \n+\\beta_4 \\text{HeightIN}_p\\text{Group2}_p \\\\\n+\\beta_5 \\text{HeightIN}_p\\text{Group3}_p \\\\\n+ e_p\n$$\n\nHere, $\\beta_1$ denotes the average change in $\\text{WeightLB}$ with one-unit increase in $\\text{HeightIN}$ for members in the reference group— Diet Group 1.\n\nQuestion: What about the slope for members in Diet Group 2.\n\n-   Typically, we can calculate by hand by assign $\\text{Group2}$ as 1 and all effects regarding $\\text{HeightIN}$:\n\n    $$\n    \\beta_{\\text{group2}}*\\text{HeightIN} = (\\beta_1 + \\beta_4*1 + \\beta_5*0)*\\text{HeightIN}\n    $$\n\n    $$\n    \\beta_{\\text{group2}}= \\beta_1 +\\beta_4\n    $$\n\n-   Similarly, the intercept for Group2 - the average mean of $\\text{WeightLB}$ is $\\beta_0 + \\beta_2$.\n\n------------------------------------------------------------------------\n\n### Computing slope for Diet Group 2\n\nOur task: Create posterior distribution for Diet Group 2\n\n-   We must do so for each iteration we've kept from our MCMC chain\n\n-   A somewhat tedious way to do this is after using Stan\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_full_new$summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 8 × 10\n  variable    mean  median    sd   mad     q5     q95  rhat ess_bulk ess_tail\n  <chr>      <dbl>   <dbl> <dbl> <dbl>  <dbl>   <dbl> <dbl>    <dbl>    <dbl>\n1 lp__     -76.6   -76.3   2.15  2.00  -80.6  -73.9    1.00    1401.    1886.\n2 beta[1]  148.    148.    3.27  3.23  142.   153.     1.00    1402.    1838.\n3 beta[2]   -0.374  -0.372 0.483 0.479  -1.16   0.414  1.00    1522.    2019.\n4 beta[3]  -24.1   -24.2   4.59  4.45  -31.6  -16.5    1.00    1746.    2190.\n5 beta[4]   81.3    81.3   4.44  4.40   74.1   88.5    1.00    1538.    2091.\n6 beta[5]    2.47    2.48  0.683 0.676   1.32   3.56   1.00    1805.    2118.\n7 beta[6]    3.57    3.57  0.646 0.643   2.52   4.62   1.00    1678.    2218.\n8 sigma      8.25    8.10  1.26  1.20    6.50  10.5    1.00    2265.    2212.\n```\n\n\n:::\n\n```{.r .cell-code}\nbeta_group2 <- fit_full_new$draws(\"beta[2]\")  + fit_full_new$draws(\"beta[5]\")\nsummary(beta_group2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 10\n  variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n  <chr>    <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n1 beta[2]   2.10   2.09 0.478 0.478  1.32  2.88  1.00    4032.    3211.\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Computing slope within Stan\n\nStan can compute these values for us-with the \"generated quantities\" section of the syntax\n\n\n::: {.cell output.var='display'}\n\n```{.stan .cell-code  code-fold=\"true\" code-summary=\"Stan code\" code-line-numbers=\"16-20\"}\ndata{\n  int<lower=0> N;         // number of observations\n  int<lower=0> P;         // number of predictors (plus column for intercept)\n  matrix[N, P] X;         // model.matrix() from R \n  vector[N] weightLB;     // outcome\n  real sigmaRate;         // hyperparameter: prior rate parameter for residual standard deviation\n}\nparameters {\n  vector[P] beta;         // vector of coefficients for Beta\n  real<lower=0> sigma;    // residual standard deviation\n}\nmodel {\n  sigma ~ exponential(sigmaRate);         // prior for sigma\n  weightLB ~ normal(X*beta, sigma);       // linear model\n}\ngenerated quantities{\n  real slopeG2;\n  slopeG2 = beta[2] + beta[5];\n}\n```\n:::\n\n\nThe generated quantities block computes values that do not affect the posterior distributions of the parameters–they are computed after the sampling from each iteration\n\n-   The values are then added to the Stan object and can be seen in the summary\n\n    -   They can also be plotted using `bayesplot` package\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_full_compute <- cmdstan_model(\"Code/FullModel_compute.stan\")\nfit_full_compute <- mod_full_compute$sample(\n  data = data_full_new,\n  seed = 1234,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 0\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_full_compute$summary('slopeG2')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 10\n  variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n  <chr>    <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n1 slopeG2   2.10   2.09 0.478 0.478  1.32  2.88  1.00    4032.    3211.\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbayesplot::mcmc_dens_chains(fit_full_compute$draws('slopeG2'))\n```\n\n::: {.cell-output-display}\n![](Lecture04_files/figure-revealjs/unnamed-chunk-28-1.png){width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Alternative way of computing the slope with Matrix\n\nThis is a little more complicated but more flexible method.\n\nThat is, we can make use of matrix operation and form a contrast matrix\n\n-   Contrasts are linear combinations of parameters\n\n    -   You may have used these in R using `glht` package\n\nFor use, we form a contrast matrix that is size of $C \\times P$ where C is the number of contrasts:\n\n-   The entries of this matrix are the values that multiplying the coefficients\n\n    -   For $(\\beta_1 + \\beta_2)$ this would be:\n\n        -   a \"1\" in the corresponding entry for $\\beta_1$\n\n        -   a \"1\" in the corresponding entry for $\\beta_4$\n\n        -   \"0\"s elsewhere\n\n    -   $$\n        \\mathbf{C} = \\begin{bmatrix}\n        0\\ \\mathbf{1}\\ 0\\ 0\\ \\mathbf{1}\\ 0\n        \\end{bmatrix}\n        $$\n\n-   Then, the contrast matrix is multiplied by the coefficients vector to form the values:\n\n    -   $\\mathbf{C} * \\beta$\n\n------------------------------------------------------------------------\n\n### Contrasts in Stan\n\n\n::: {.cell output.var='display'}\n\n```{.stan .cell-code  code-fold=\"true\" code-summary=\"Stan code\" code-line-numbers=\"7-8,18-21\"}\ndata{\n  int<lower=0> N;         // number of observations\n  int<lower=0> P;         // number of predictors (plus column for intercept)\n  matrix[N, P] X;         // model.matrix() from R \n  vector[N] weightLB;     // outcome\n  real sigmaRate;         // hyperparameter: prior rate parameter for residual standard deviation\n  int<lower=0> nContrasts;\n  matrix[nContrasts, P] contrast; // C matrix \n}\nparameters {\n  vector[P] beta;         // vector of coefficients for Beta\n  real<lower=0> sigma;    // residual standard deviation\n}\nmodel {\n  sigma ~ exponential(sigmaRate);         // prior for sigma\n  weightLB ~ normal(X*beta, sigma);       // linear model\n}\ngenerated quantities{\n  vector[nContrasts] computedEffects;\n  computedEffects = contrast*beta;\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"R code\" code-line-numbers=\"2-9,11\"}\nmod_full_contrast <- cmdstan_model(\"Code/FullModel_contrast.stan\")\ncontrast_dat <- list(\n  nContrasts = 2,\n  contrast = matrix(\n    c(0,1,0,0,1,0, # slope for diet group2\n      1,0,1,0,0,0),# intercept for diet group 2\n    nrow = 2, byrow = TRUE\n  )\n)\nfit_full_contrast <- mod_full_contrast$sample(\n  data = c(data_full_new, contrast_dat),\n  seed = 1234,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 0\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_full_contrast$summary('computedEffects')[, -c(9, 10)]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 8\n  variable             mean median    sd   mad     q5    q95  rhat\n  <chr>               <dbl>  <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl>\n1 computedEffects[1]   2.10   2.09 0.478 0.478   1.32   2.88  1.00\n2 computedEffects[2] 123.   123.   3.16  3.02  118.   129.    1.00\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbayesplot::mcmc_hist(fit_full_contrast$draws('computedEffects'))\n```\n\n::: {.cell-output-display}\n![](Lecture04_files/figure-revealjs/unnamed-chunk-32-1.png){width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Computing $\\text{R}^2$\n\nWe can use the `generated quantities` section to build a posterior distribution for $\\text{R}^2$\n\nThere are several formulas for $\\text{R}^2$, we will use the following:\n\n$$\n\\text{R}^2 = 1-\\frac{RSS}{TSS} = 1- \\frac{\\Sigma_{p=1}^{N}(y_p -\\hat{y}_p)}{\\Sigma_{p=1}^{N}(y_p -\\bar{y}_p)}\n$$ Where:\n\n1.  RSS is the residual sum of squares\n2.  TSS is the total sum of squares of dependent variable\n3.  $\\hat{y}_p$ is the predicted values: $\\hat{y}_p = \\mathbf{X}\\boldsymbol{\\beta}$\n4.  $\\bar{y}_p$ is the mean value of dependent variable: $\\bar{y}_p = \\frac{\\Sigma_{p=1}^{N}y_p}{N}$\n\nNotice: RSS depends on sampled parameters, so we will use this to build our posterior distribution for $\\text{R}^2$\n\n------------------------------------------------------------------------\n\nFor adjusted $\\text{R}^2$, we use the following:\n\n$$\n\\text{adj.R}^2 = 1-\\frac{RSS/(N-P)}{TSS/(N-1)} = 1- \\frac{\\Sigma_{p=1}^{N}(y_p -\\hat{y}_p)}{\\Sigma_{p=1}^{N}(y_p -\\bar{y}_p)}*\\frac{N-P}{N-1}\n$$\n\nThen, we can calculate the how to calculate $\\text{adj.R}^2$ by $\\text{R}^2$:\n\n$$\n\\text{adj.R}^2 = 1-(1-\\text{R}^2)*\\frac{N-P}{N-1} = \\frac{(P-1)+(N-1)R^2}{N-P}\n$$\n\n------------------------------------------------------------------------\n\n### `Stan` code for Computing $\\text{R}^2$\n\n\n::: {.cell output.var='display'}\n\n```{.stan .cell-code  code-fold=\"true\" code-summary=\"Stan code\" code-line-numbers=\"4-15\"}\ngenerated quantities{\n  vector[nContrasts] computedEffects;\n  computedEffects = contrast*beta;\n  // compute R2\n  real rss;\n  real tss;\n  real R2;\n  real R2adj;\n  {// anything in these brackets will not appear in summary table\n    vector[N] pred = X*beta;\n    rss = dot_self(weightLB-pred); // dot_self is stan function for matrix square\n    tss = dot_self(weightLB-mean(weightLB));\n  }\n  R2 = 1-rss/tss;\n  R2adj = 1-(rss/(N-P))/(tss/(N-1));\n}\n```\n:::\n\n\nRecall that our `lm` function provides $\\text{R}^2$ as 0.9787 and adjusted $\\text{R}^2$ as 0.9742\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_full_contrast$summary(c('rss', 'tss', 'R2','R2adj'))[, -c(9, 10)]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 8\n  variable      mean    median        sd       mad        q5       q95  rhat\n  <chr>        <dbl>     <dbl>     <dbl>     <dbl>     <dbl>     <dbl> <dbl>\n1 rss       1941.     1877.    285.      226.       1616.     2499.     1.00\n2 tss      71112     71112       0         0       71112     71112     NA   \n3 R2           0.973     0.974   0.00401   0.00317     0.965     0.977  1.00\n4 R2adj        0.967     0.968   0.00484   0.00384     0.958     0.973  1.00\n```\n\n\n:::\n\n```{.r .cell-code}\nbayesplot::mcmc_hist(fit_full_contrast$draws(c('R2', 'R2adj')))\n```\n\n::: {.cell-output-display}\n![](Lecture04_files/figure-revealjs/unnamed-chunk-34-1.png){width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Get posterior mode\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create the function.\ngetmode <- function(v) {\n   uniqv <- unique(v)\n   uniqv[which.max(tabulate(match(v, uniqv)))]\n}\n\n# Calculate the mode using the user function.\ngetmode(fit_full_contrast$draws('R2'))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.974917\n```\n\n\n:::\n\n```{.r .cell-code}\ngetmode(fit_full_contrast$draws('R2adj'))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.96674\n```\n\n\n:::\n:::\n\n\n## Wrapping up\n\nToday we further added generated quantities into our Bayesian toolset:\n\n-   How to make `Stan` use less syntax using matrices\n-   How to form posterior distributions for functions of parameters\n\nWe will use both of these features in psychometric models.\n\n## Next Class\n\n1.  Bayesian Model fit\n2.  Bayesian Model Comparison\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}