{
  "hash": "c867d17bb0f25456832d144fe85e8c83",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lecture 08\"\nsubtitle: \"Generalized Measurement Models: Modeling Observed Data II\"\nauthor: \"Jihong Zhang\"\ninstitute: \"Educational Statistics and Research Methods\"\ntitle-slide-attributes:\n  data-background-image: ../Images/title_image.png\n  data-background-size: contain\nexecute: \n  echo: false\n  eval: false\nformat: \n  revealjs:\n    logo: ../Images/UA_Logo_Horizontal.png\n    incremental: false  # choose \"false \"if want to show all together\n    transition: slide\n    background-transition: fade\n    theme: [simple, ../pp.scss]\n    footer:  <https://jihongzhang.org/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553>\n    scrollable: true\n    slide-number: true\n    chalkboard: true\n    number-sections: false\n    code-line-numbers: true\n    code-annotations: below\n    code-copy: true\n    code-summary: ''\n    highlight-style: arrow\n    view: 'scroll' # Activate the scroll view\n    scrollProgress: true # Force the scrollbar to remain visible\n    mermaid:\n      theme: neutral\n\n#bibliography: references.bib\n---\n\n\n\n# Review Previous Class\n\n## In Previous Class...\n\n1.  We introduced a self-reported survey data, called `Conspiracy Theories`\n\n-   The scale has 10 items with 5-point Likert scale response\n-   Items have varied item difficult and Positive skewed item response distribution\n\n2.  We talked about using if factor analysis is a proper method when normality assumption is violated\n3.  We checked the item characteristics curves\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Lecture08_files/figure-revealjs/unnamed-chunk-1-1.png){width=1728}\n:::\n:::\n\n\n\n## Today's Lecture Objectives\n\n1.  Quickly go through our R code file so far\n2.  Show different modeling specifications for different types of item response data\n3.  Show how parameterization differs for standardized latent variables vs. marker item scale identification\n\n## Posterior Distribution for Item Parameters\n\nBefore moving onto the latent variable, let's note the posterior distribution of item parameters (for a single item):\n\n$$\nf(\\mu_i,\\lambda_i,\\psi_i\\mid\\boldsymbol{Y})\\propto f(\\boldsymbol{Y}\\mid\\mu_i,\\lambda_i,\\psi_i)f(\\mu_i, \\lambda_i,\\psi_i)\n$$\n\nwhere $f(\\boldsymbol{Y}\\mid\\mu_i,\\lambda_i,\\psi_i)$ is the (joint) posterior distribution of the parameters for item $i$ conditional on the adta\n\n$f(\\boldsymbol{Y}\\mid\\mu_i,\\lambda_i,\\psi_i)$ is the distribution we defined for our observed data:\n\n$$\nf(\\boldsymbol{Y}\\mid\\mu_i,\\lambda_i,\\psi_i)\\sim N(\\mu_i+\\lambda_i\\theta_p, \\psi_i)\n$$\n\n$f(\\mu_i, \\lambda_i, \\psi_i)$ is the (joint) prior distribution for each of the parameters, which, are independent:\n\n$$\nf(\\mu_i, \\lambda_i, \\psi_i) = f(\\mu_i)f(\\lambda_i)f(\\psi_i)\n$$\n\n## Investigating the Latent Variables\n\nThe estimated latent variables are then:\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 177 × 10\n   variable     mean  median    sd   mad     q5     q95  rhat ess_bulk ess_tail\n   <chr>       <dbl>   <dbl> <dbl> <dbl>  <dbl>   <dbl> <dbl>    <dbl>    <dbl>\n 1 theta[1]   0.0221  0.0222 0.246 0.250 -0.386  0.419   1.00    5122.    5185.\n 2 theta[2]   1.53    1.53   0.257 0.254  1.11   1.96    1.00    3754.    4698.\n 3 theta[3]   1.71    1.71   0.264 0.263  1.27   2.14    1.00    3809.    4720.\n 4 theta[4]  -0.927  -0.924  0.250 0.246 -1.34  -0.517   1.00    4936.    4752.\n 5 theta[5]   0.0443  0.0485 0.248 0.244 -0.368  0.449   1.00    5126.    4699.\n 6 theta[6]  -0.976  -0.972  0.252 0.249 -1.40  -0.566   1.00    3786.    4650.\n 7 theta[7]  -0.336  -0.338  0.254 0.249 -0.754  0.0846  1.00    4421.    4882.\n 8 theta[8]  -0.0520 -0.0548 0.248 0.247 -0.460  0.349   1.00    5037.    5503.\n 9 theta[9]  -0.785  -0.784  0.244 0.248 -1.19  -0.388   1.00    4633.    5479.\n10 theta[10]  0.0477  0.0460 0.248 0.250 -0.357  0.455   1.00    5000.    4896.\n# ℹ 167 more rows\n```\n\n\n:::\n:::\n\n\n\n## EAP Estimates of Latent Variables\n\n![](/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code/EAP_Estimates.png)\n\n## Density of EAP Estimates\n\n![](/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code/EAP_Estimates_density.png)\n\n## Density of 500 Posterior draws of θ\n\n![](/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code/Theta_Draws_density.png)\n\n## Comparing Posterior Distribution for Individuals\n\n![](/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code/Theta_density_ThreeIndividuals.png)\n\n## Comparing EAP Estimate with Posterior SD\n\n![](/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code/EAP_SD.png)\n\n## Comparing EAP Estimate with Sum Score\n\n![](/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code/EAP_SumScore.png)\n\n## Comparing EAP Estimate with Factor Score by `lavaan`\n\n![](/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code/EAP_FactorScore.png)\n\n## Posterior Distribution for Person Parameter θ\n\nThe posterior distribution of the person parameters (the latent variable for a single person):\n\n$$\nf(\\theta_p\\mid\\boldsymbol{Y}) \\propto f(\\boldsymbol{Y} \\mid \\theta_p)f(\\theta_p)\n$$\n\nHere:\n\n-   $f(\\theta_p\\mid\\boldsymbol{Y})$ is the posterior distribution of the latent variable conditional on the observed data;\n\n-   $f(\\boldsymbol{Y} \\mid \\theta_p)$ is the model (data) likelihood:\n\n    $$\n    f(\\boldsymbol{Y} \\mid \\theta_p) = \\prod_{i=1}^{I} f(Y_i\\mid\\theta_p)\n    $$\n\n    -   $f(Y_i \\mid \\theta_p)$ is one individual item's data likelihood: $f(Y_i \\mid \\theta_p) \\sim N(\\mu_i+\\lambda_i\\theta_p, \\psi_i)$;\n\n-   $f(\\theta_p) \\sim N(0,1)$ is the prior distribution for the latent variable – $\\theta_p$\n\n# Measurement Model Estimation Fails\n\n## Recall: Stan's `parameters {}` Block\n\n\n\n::: {.cell output.var='display'}\n\n```{.stan .cell-code}\nparameters {\n  vector[nObs] theta;                // the latent variables (one for each person)\n  vector[nItems] mu;                 // the item intercepts (one for each item)\n  vector[nItems] lambda;             // the factor loadings/item discriminations (one for each item)\n  vector<lower=0>[nItems] psi;       // the unique standard deviations (one for each item)   \n}\n```\n:::\n\n\n\nHere, the parameterization of $\\lambda$ (factor loadings / discrimination parameters) can lead to problems in estimation\n\n-   The issue is $\\lambda_i\\theta_p=(-\\lambda_i)(-\\theta_p)$\n\n    -   Depending on the random starting values of each of these parameters (per Markov chain), a given chain may converge to different region with others\n\n-   To demonstrate, we will start with different random number seend\n\n    -   Currently use 09102022: works fine\n\n    -   Change to 25102022: big problem\n\n## New Samples Syntax\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|3\"}\nmodelCFA_samplesFail = modelCFA_stan$sample(\n  data = modelCFA_data,\n  seed = 25102022,\n  chains = 4,\n  parallel_chains = 4,\n  iter_warmup = 1000,\n  iter_sampling = 2000\n)\n```\n:::\n\n\n\nConvergence fail with maximum of $\\hat R$ as:\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.73562\n```\n\n\n:::\n:::\n\n\n\n## Why Convergence Failed\n\n-   The issue of exchangeable likelihood: $\\lambda_i\\theta_p=(-\\lambda_i)(-\\theta_p)$\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 10\n   variable     mean median    sd   mad     q5   q95  rhat ess_bulk ess_tail\n   <chr>       <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>    <dbl>    <dbl>\n 1 lambda[1]  -0.001  0.01  0.743 1.09  -0.843 0.841  1.73     6.08     106.\n 2 lambda[2]  -0.002 -0.004 0.873 1.29  -0.972 0.969  1.73     6.10     121.\n 3 lambda[3]  -0.002  0.007 0.805 1.19  -0.901 0.899  1.73     6.08     113.\n 4 lambda[4]  -0.001 -0.012 0.846 1.25  -0.945 0.941  1.73     6.09     113.\n 5 lambda[5]  -0.001 -0.002 0.999 1.47  -1.09  1.09   1.73     6.13     122.\n 6 lambda[6]  -0.001  0.008 0.9   1.33  -0.983 0.98   1.73     6.14     103.\n 7 lambda[7]  -0.002 -0.002 0.767 1.13  -0.855 0.85   1.73     6.08     118.\n 8 lambda[8]  -0.001 -0.002 0.855 1.26  -0.931 0.932  1.73     6.09     108.\n 9 lambda[9]  -0.002  0.029 0.863 1.27  -0.963 0.962  1.73     6.12     101.\n10 lambda[10] -0.001 -0.003 0.677 0.993 -0.775 0.774  1.73     6.08     105.\n```\n\n\n:::\n:::\n\n\n\n## Posterior Trace Plots of λ\n\nUnfortunately, we are unable to extract initial values that were generated automatically by `cmdstanr`. See [here](https://mc-stan.org/cmdstanr/reference/fit-method-init.html) for more details.\n\n![](/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code/Posterior_lambda.png){fig-align=\"center\"}\n\n## Posterior Density Plots of λ\n\n![](/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code/Posterior_lambda_density.png){fig-align=\"center\"}\n\n## Examining Latent Variable\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 177 × 10\n    variable     mean median    sd   mad     q5   q95  rhat ess_bulk ess_tail\n    <chr>       <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>    <dbl>    <dbl>\n  1 theta[1]   -0.002  0.001 0.247 0.245 -0.414 0.405  1.00  3167.     4819. \n  2 theta[2]   -0.001  0.004 1.56  2.27  -1.87  1.87   1.73     6.08    104. \n  3 theta[3]    0      0.029 1.73  2.53  -2.06  2.05   1.73     6.07    105. \n  4 theta[4]   -0.008  0.018 0.962 1.37  -1.26  1.24   1.73     6.07    130. \n  5 theta[5]    0.001  0     0.247 0.249 -0.403 0.410  1.02   177.     4690. \n  6 theta[6]   -0.004  0.05  1.01  1.45  -1.30  1.30   1.73     6.07    106. \n  7 theta[7]   -0.005 -0.002 0.422 0.503 -0.672 0.656  1.60     6.65    104. \n  8 theta[8]   -0.003 -0.001 0.254 0.248 -0.427 0.417  1.03   112.     3799. \n  9 theta[9]   -0.009  0.015 0.825 1.16  -1.11  1.09   1.73     6.06    113. \n 10 theta[10]  -0.004 -0.004 0.252 0.251 -0.416 0.418  1.02   168.     3352. \n 11 theta[11]  -0.006 -0.055 1.01  1.45  -1.30  1.29   1.73     6.07     99.4\n 12 theta[12]  -0.004 -0.006 0.356 0.395 -0.571 0.578  1.46     7.62    105. \n 13 theta[13]  -0.007 -0.025 0.787 1.11  -1.07  1.06   1.73     6.06    106. \n 14 theta[14]  -0.006 -0.101 1.01  1.45  -1.32  1.29   1.73     6.06     99.0\n 15 theta[15]  -0.005  0.037 0.875 1.24  -1.16  1.14   1.73     6.06     97.9\n 16 theta[16]  -0.004 -0.005 0.259 0.259 -0.434 0.424  1.03    82.2    3490. \n 17 theta[17]  -0.004 -0.006 0.263 0.263 -0.438 0.430  1.03    88.1    4232. \n 18 theta[18]  -0.006 -0.017 0.710 0.985 -0.984 0.984  1.73     6.08    101. \n 19 theta[19]   0.001 -0.005 1.89  2.77  -2.22  2.23   1.73     6.07    116. \n 20 theta[20]  -0.007  0.072 0.962 1.37  -1.26  1.25   1.74     6.05    110. \n 21 theta[21]  -0.008  0     0.350 0.390 -0.571 0.548  1.45     7.81    104. \n 22 theta[22]  -0.005 -0.051 1.01  1.45  -1.30  1.30   1.73     6.08    109. \n 23 theta[23]  -0.003  0.032 1.01  1.45  -1.30  1.29   1.73     6.06    114. \n 24 theta[24]  -0.008 -0.027 1.01  1.43  -1.30  1.30   1.73     6.06    108. \n 25 theta[25]  -0.005 -0.008 0.602 0.807 -0.883 0.865  1.73     6.07    106. \n 26 theta[26]  -0.003 -0.009 0.779 1.09  -1.07  1.06   1.73     6.07    107. \n 27 theta[27]  -0.002 -0.007 0.276 0.275 -0.452 0.451  1.10    24.5     375. \n 28 theta[28]  -0.002  0.091 1.24  1.80  -1.55  1.55   1.73     6.07     99.7\n 29 theta[29]  -0.004 -0.032 0.928 1.32  -1.23  1.21   1.73     6.06    107. \n 30 theta[30]  -0.001 -0.057 1.70  2.49  -2.03  2.04   1.73     6.07    112. \n 31 theta[31]  -0.003 -0.004 0.602 0.803 -0.877 0.871  1.73     6.09    111. \n 32 theta[32]  -0.003 -0.005 0.487 0.619 -0.743 0.736  1.69     6.24    106. \n 33 theta[33]  -0.003 -0.003 0.412 0.486 -0.654 0.649  1.58     6.79    107. \n 34 theta[34]  -0.007 -0.068 1.01  1.45  -1.30  1.28   1.73     6.07    107. \n 35 theta[35]  -0.007 -0.034 0.710 0.981 -0.991 0.977  1.73     6.08    107. \n 36 theta[36]  -0.006  0.035 0.834 1.17  -1.13  1.10   1.73     6.07    103. \n 37 theta[37]  -0.005  0.031 1.01  1.45  -1.29  1.30   1.73     6.07    109. \n 38 theta[38]  -0.005 -0.002 0.324 0.348 -0.533 0.517  1.36     8.87    128. \n 39 theta[39]  -0.007 -0.072 1.01  1.44  -1.32  1.27   1.73     6.06    102. \n 40 theta[40]  -0.002 -0.003 0.249 0.250 -0.408 0.409  1.02   169.     3659. \n 41 theta[41]  -0.008  0.044 1.01  1.45  -1.30  1.28   1.73     6.08    115. \n 42 theta[42]  -0.005 -0.007 0.265 0.262 -0.437 0.427  1.06    39.6    1019. \n 43 theta[43]  -0.006 -0.014 0.686 0.951 -0.962 0.950  1.73     6.08    108. \n 44 theta[44]  -0.004 -0.003 0.258 0.254 -0.425 0.420  1.04    72.9    3059. \n 45 theta[45]  -0.003  0.001 0.455 0.566 -0.700 0.692  1.67     6.33    110. \n 46 theta[46]  -0.003 -0.007 0.361 0.406 -0.574 0.580  1.49     7.39    107. \n 47 theta[47]  -0.005 -0.027 0.564 0.749 -0.821 0.827  1.73     6.09    107. \n 48 theta[48]  -0.005 -0.021 0.869 1.23  -1.17  1.15   1.73     6.08    111. \n 49 theta[49]  -0.009 -0.033 1.01  1.44  -1.29  1.30   1.73     6.06    101. \n 50 theta[50]  -0.006 -0.008 0.304 0.308 -0.505 0.497  1.21    12.8     142. \n 51 theta[51]  -0.005  0.058 1.01  1.44  -1.31  1.29   1.73     6.07    124. \n 52 theta[52]  -0.006 -0.003 0.408 0.483 -0.654 0.640  1.58     6.75    115. \n 53 theta[53]  -0.008 -0.031 1.01  1.46  -1.31  1.29   1.73     6.06    109. \n 54 theta[54]  -0.001  0.02  1.24  1.80  -1.54  1.53   1.73     6.07    109. \n 55 theta[55]  -0.006 -0.001 1.01  1.45  -1.31  1.30   1.73     6.07    109. \n 56 theta[56]  -0.005  0.06  1.01  1.45  -1.30  1.29   1.73     6.06    121. \n 57 theta[57]  -0.006 -0.001 0.771 1.07  -1.05  1.04   1.73     6.07    108. \n 58 theta[58]  -0.006  0.027 1.01  1.45  -1.31  1.28   1.73     6.06    100. \n 59 theta[59]  -0.003 -0.004 0.263 0.265 -0.434 0.433  1.05    56.3     974. \n 60 theta[60]  -0.005 -0.008 0.686 0.949 -0.958 0.955  1.73     6.08    109. \n 61 theta[61]  -0.002 -0.006 1.41  2.05  -1.71  1.71   1.73     6.07     99.2\n 62 theta[62]  -0.004 -0.012 0.407 0.482 -0.633 0.642  1.60     6.67    111. \n 63 theta[63]  -0.006  0.012 1.01  1.45  -1.32  1.29   1.73     6.07    112. \n 64 theta[64]  -0.004  0.039 1.40  2.04  -1.71  1.70   1.73     6.07    118. \n 65 theta[65]   0     -0.025 1.24  1.80  -1.53  1.54   1.73     6.07    122. \n 66 theta[66]  -0.006 -0.011 0.788 1.10  -1.08  1.06   1.73     6.06    109. \n 67 theta[67]  -0.005 -0.011 0.604 0.805 -0.881 0.873  1.73     6.09    108. \n 68 theta[68]  -0.005  0.01  0.896 1.26  -1.19  1.18   1.73     6.07    114. \n 69 theta[69]  -0.004 -0.009 0.588 0.792 -0.867 0.846  1.73     6.10    101. \n 70 theta[70]  -0.004 -0.041 0.923 1.31  -1.21  1.21   1.73     6.08    114. \n 71 theta[71]  -0.009 -0.008 0.252 0.250 -0.431 0.404  1.04    69.1    2621. \n 72 theta[72]  -0.004 -0.055 1.08  1.55  -1.39  1.40   1.73     6.07    114. \n 73 theta[73]  -0.004  0     0.247 0.250 -0.411 0.401  1.00  3708.     4860. \n 74 theta[74]  -0.005  0.044 1.01  1.45  -1.31  1.29   1.73     6.07    105. \n 75 theta[75]  -0.006 -0.099 1.01  1.44  -1.31  1.30   1.73     6.06    109. \n 76 theta[76]   0.003 -0.065 3.27  4.82  -3.64  3.64   1.73     6.08    112. \n 77 theta[77]  -0.002 -0.032 0.826 1.16  -1.11  1.10   1.73     6.07    108. \n 78 theta[78]  -0.001 -0.065 1.18  1.70  -1.48  1.48   1.73     6.07     97.5\n 79 theta[79]  -0.004  0.059 1.89  2.77  -2.23  2.21   1.73     6.08    105. \n 80 theta[80]  -0.003 -0.016 0.666 0.909 -0.944 0.943  1.73     6.08    114. \n 81 theta[81]  -0.006 -0.005 0.253 0.254 -0.426 0.404  1.02   146.     3265. \n 82 theta[82]  -0.004 -0.001 0.249 0.250 -0.411 0.402  1.01  2604.     4613. \n 83 theta[83]  -0.004  0.085 1.01  1.45  -1.31  1.29   1.73     6.06    103. \n 84 theta[84]  -0.001 -0.062 1.60  2.33  -1.92  1.92   1.73     6.07     98.9\n 85 theta[85]  -0.006 -0.007 0.327 0.344 -0.538 0.517  1.33     9.36    125. \n 86 theta[86]  -0.008 -0.021 1.01  1.44  -1.30  1.29   1.74     6.06    107. \n 87 theta[87]  -0.005 -0.006 0.308 0.319 -0.508 0.503  1.23    12.4     164. \n 88 theta[88]  -0.004  0     0.405 0.475 -0.637 0.645  1.57     6.80    103. \n 89 theta[89]  -0.009 -0.054 1.01  1.45  -1.32  1.29   1.73     6.07    115. \n 90 theta[90]  -0.005  0.045 0.880 1.24  -1.18  1.16   1.73     6.07    116. \n 91 theta[91]  -0.004  0.034 0.872 1.24  -1.16  1.14   1.73     6.06    106. \n 92 theta[92]  -0.002 -0.04  1.09  1.56  -1.39  1.39   1.73     6.05    106. \n 93 theta[93]  -0.007 -0.012 0.247 0.249 -0.412 0.399  1.00  3345.     4727. \n 94 theta[94]  -0.003  0.073 2.61  3.84  -2.96  2.96   1.73     6.09    115. \n 95 theta[95]  -0.003 -0.231 1.68  2.46  -2.00  2.00   1.73     6.09    112. \n 96 theta[96]  -0.003 -0.005 0.408 0.484 -0.639 0.636  1.60     6.67    121. \n 97 theta[97]  -0.001 -0.007 0.364 0.407 -0.581 0.592  1.48     7.44    100. \n 98 theta[98]  -0.007  0.089 1.01  1.44  -1.30  1.30   1.73     6.06    124. \n 99 theta[99]  -0.001  0.08  1.24  1.79  -1.54  1.55   1.73     6.07    110. \n100 theta[100] -0.003  0.129 0.958 1.37  -1.25  1.24   1.73     6.07    109. \n101 theta[101] -0.006 -0.011 0.751 1.05  -1.03  1.02   1.73     6.06    104. \n102 theta[102]  0.001  0.033 2.83  4.17  -3.18  3.19   1.73     6.08     96.6\n103 theta[103] -0.005  0.01  0.709 0.981 -0.988 0.968  1.73     6.09    101. \n104 theta[104] -0.004 -0.037 0.900 1.27  -1.20  1.20   1.73     6.07    110. \n105 theta[105] -0.006 -0.007 0.266 0.261 -0.436 0.434  1.06    40.5    2806. \n106 theta[106] -0.003  0.035 1.16  1.67  -1.46  1.46   1.73     6.07    108. \n107 theta[107] -0.005  0.021 1.60  2.34  -1.91  1.91   1.73     6.07    106. \n108 theta[108] -0.001 -0.016 0.879 1.24  -1.17  1.17   1.73     6.09    106. \n109 theta[109] -0.003 -0.197 1.07  1.54  -1.36  1.36   1.73     6.06    112. \n110 theta[110] -0.006 -0.004 0.255 0.255 -0.426 0.408  1.02   179.     3672. \n111 theta[111] -0.004 -0.008 0.276 0.276 -0.460 0.449  1.12    20.8     196. \n112 theta[112] -0.006 -0.028 0.685 0.945 -0.962 0.951  1.73     6.07     96.1\n113 theta[113] -0.002 -0.011 0.449 0.557 -0.682 0.693  1.66     6.39    104. \n114 theta[114] -0.004 -0.001 0.403 0.476 -0.645 0.630  1.57     6.80    114. \n115 theta[115] -0.004  0.013 0.903 1.27  -1.21  1.20   1.73     6.09    110. \n116 theta[116] -0.002  0.001 0.297 0.306 -0.494 0.480  1.24    12.0     115. \n117 theta[117] -0.002 -0.006 0.254 0.255 -0.418 0.416  1.04    71.7    3080. \n118 theta[118] -0.006 -0.007 0.409 0.482 -0.651 0.637  1.60     6.67    106. \n119 theta[119] -0.007 -0.038 0.873 1.23  -1.17  1.16   1.74     6.07    117. \n120 theta[120] -0.006 -0.059 1.01  1.45  -1.31  1.28   1.73     6.07    113. \n121 theta[121] -0.005 -0.002 0.323 0.333 -0.536 0.521  1.31     9.80    120. \n122 theta[122] -0.003 -0.005 0.683 0.941 -0.952 0.952  1.73     6.06    108. \n123 theta[123] -0.002  0.031 1.24  1.80  -1.54  1.53   1.73     6.08    120. \n124 theta[124] -0.002  0.003 1.07  1.53  -1.36  1.35   1.73     6.06    108. \n125 theta[125] -0.006 -0.009 1.01  1.44  -1.30  1.29   1.73     6.06    103. \n126 theta[126] -0.009  0.004 0.687 0.945 -0.966 0.949  1.73     6.08    101. \n127 theta[127] -0.003 -0.031 1.16  1.67  -1.46  1.46   1.73     6.08    114. \n128 theta[128] -0.008  0.037 0.883 1.25  -1.17  1.16   1.74     6.06    103. \n129 theta[129] -0.009  0.003 0.706 0.981 -0.986 0.964  1.73     6.06    107. \n130 theta[130]  0      0.033 1.88  2.75  -2.22  2.21   1.73     6.07    107. \n131 theta[131] -0.004  0.002 0.419 0.507 -0.660 0.651  1.62     6.58    113. \n132 theta[132]  0     -0.095 1.68  2.46  -2.01  1.99   1.73     6.08    110. \n133 theta[133] -0.008 -0.135 1.01  1.45  -1.32  1.30   1.73     6.06    103. \n134 theta[134]  0.001 -0.084 2.61  3.84  -2.95  2.96   1.73     6.08    118. \n135 theta[135] -0.005  0.009 0.826 1.17  -1.11  1.11   1.73     6.07    113. \n136 theta[136] -0.007  0.037 1.01  1.45  -1.30  1.30   1.73     6.06    109. \n137 theta[137] -0.002  0.012 0.816 1.15  -1.10  1.10   1.73     6.06    108. \n138 theta[138] -0.003  0.038 0.826 1.17  -1.11  1.11   1.74     6.05    108. \n139 theta[139] -0.004 -0.004 0.256 0.253 -0.425 0.411  1.02   166.     4446. \n140 theta[140] -0.004 -0.002 0.249 0.246 -0.416 0.402  1.03   111.     3771. \n141 theta[141] -0.004  0.004 0.872 1.24  -1.17  1.15   1.73     6.07    104. \n142 theta[142] -0.007 -0.107 1.01  1.45  -1.31  1.29   1.73     6.06    103. \n143 theta[143] -0.005  0.023 1.01  1.44  -1.29  1.31   1.73     6.07    113. \n144 theta[144] -0.001  0.035 0.855 1.21  -1.14  1.13   1.73     6.06    104. \n145 theta[145] -0.008  0.009 1.01  1.44  -1.31  1.29   1.73     6.07    109. \n146 theta[146] -0.004  0.007 0.663 0.910 -0.932 0.930  1.73     6.07    120. \n147 theta[147]  0.001 -0.001 0.894 1.27  -1.19  1.18   1.73     6.07    103. \n148 theta[148] -0.002 -0.005 0.279 0.280 -0.455 0.460  1.13    19.9     279. \n149 theta[149] -0.006 -0.05  1.01  1.44  -1.30  1.31   1.73     6.07    108. \n150 theta[150] -0.009 -0.135 1.01  1.46  -1.30  1.28   1.73     6.07    102. \n151 theta[151] -0.006 -0.029 0.689 0.947 -0.969 0.957  1.73     6.07    105. \n152 theta[152] -0.005 -0.024 1.01  1.44  -1.31  1.30   1.73     6.07    100. \n153 theta[153] -0.001  0.011 1.55  2.26  -1.87  1.87   1.73     6.07    116. \n154 theta[154] -0.007 -0.019 0.960 1.37  -1.25  1.24   1.73     6.07    114. \n155 theta[155] -0.008  0.114 1.01  1.45  -1.29  1.29   1.73     6.07    100. \n156 theta[156] -0.006 -0.071 0.870 1.24  -1.16  1.15   1.73     6.07    102. \n157 theta[157] -0.008 -0.011 0.869 1.24  -1.16  1.14   1.73     6.07    114. \n158 theta[158] -0.005 -0.004 0.248 0.248 -0.412 0.403  1.00  4189.     4432. \n159 theta[159] -0.004  0     0.664 0.916 -0.940 0.934  1.73     6.07    101. \n160 theta[160] -0.008 -0.003 1.01  1.45  -1.30  1.29   1.73     6.08    104. \n161 theta[161] -0.002 -0.087 1.33  1.92  -1.63  1.62   1.73     6.07    118. \n162 theta[162] -0.003 -0.005 0.307 0.314 -0.500 0.509  1.24    11.8     133. \n163 theta[163] -0.007 -0.068 1.01  1.45  -1.30  1.29   1.73     6.08    105. \n164 theta[164] -0.005 -0.01  0.595 0.798 -0.864 0.869  1.73     6.08    102. \n165 theta[165] -0.004  0     0.308 0.316 -0.517 0.491  1.21    12.9     142. \n166 theta[166] -0.007 -0.005 1.01  1.45  -1.32  1.29   1.73     6.07    120. \n167 theta[167] -0.004 -0.005 0.410 0.484 -0.651 0.639  1.58     6.77    105. \n168 theta[168] -0.001 -0.069 1.40  2.04  -1.71  1.73   1.73     6.07    112. \n169 theta[169] -0.005 -0.008 0.428 0.515 -0.674 0.655  1.64     6.48    100. \n170 theta[170] -0.006 -0.005 0.273 0.271 -0.459 0.445  1.13    20.3     244. \n171 theta[171] -0.007 -0.005 0.789 1.11  -1.09  1.06   1.73     6.09    102. \n172 theta[172] -0.003 -0.007 0.318 0.333 -0.516 0.525  1.32     9.58    128. \n173 theta[173] -0.003  0.016 0.663 0.911 -0.941 0.930  1.73     6.07    112. \n174 theta[174] -0.004  0.027 0.747 1.04  -1.04  1.02   1.73     6.05     98.2\n175 theta[175] -0.004 -0.009 0.707 0.982 -0.980 0.967  1.73     6.09     99.9\n176 theta[176] -0.007 -0.012 0.827 1.17  -1.11  1.11   1.73     6.07    104. \n177 theta[177] -0.005 -0.006 0.501 0.642 -0.760 0.753  1.70     6.17    106. \n```\n\n\n:::\n:::\n\n\n\n## Posterior Trace Plots of θ\n\n![](/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code/Posterior_theta_traceplot.png){fig-align=\"center\"}\n\n## Posterior Density Plots of θ\n\n![](/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code/Posterior_theta_density.png)\n\n## Fixing Convergence\n\n`Stan` allows starting values to be set via `cmdstanr`\n\n-   Documentation is very lacking, I can show you one method but it may change in the future.\n\nAlternatively:\n\n-   In `Stan` file, restrict $\\lambda$ to be positive: `vector<lower=0>[nItems] lambda;`\n\n-   Can also choose prior that has strictly positive range (like log-normal distribution)\n\n-   Note: the restriction on the space of $\\lambda$ will not permit truely negative values\n\n    -   Not ideals as negative $\\lambda$ values are informative as a problem with data\n\n\n\n    ::: {.cell output.var='display'}\n    \n    ```{.stan .cell-code}\n    parameters {\n      vector[nObs] theta;                // the latent variables (one for each person)\n      vector[nItems] mu;                 // the item intercepts (one for each item)\n      vector<lower=0>[nItems] lambda;    // the factor loadings/item discriminations (one for each item)\n      vector<lower=0>[nItems] psi;       // the unique standard deviations (one for each item)   \n    }\n    ```\n    :::\n\n\n\n## Setting Starting (Inital) Values in `Stan`\n\nStarting values (initial values) are the first values used when an MCMC chain starts\n\n-   In `Stan`, by default, parameters are randomly started between -2 and 2\n\n    -   Bounded parameters are transformed so they are unbounded in the algorithm\n\n-   What we need:\n\n    -   Randomly start all $\\lambda$ parameters so that they converge to the $\\lambda_i\\theta_p$ mode\n\n    -   As opposed to the (-$\\lambda_i$)(-$\\theta_p$) mode\n\n## `cmdstanr` Syntax for Initial Values\n\nAdd the init option to the `$sample()` function of the `cmdstanr` object:\n\n\n\n::: {.cell output.var='display'}\n\n```{.stan .cell-code}\n# set starting values for some of the parameters\nmodelCFA_samples2fixed = modelCFA_stan$sample(\n  data = modelCFA_data,\n  seed = 25102022,\n  chains = 4,\n  parallel_chains = 4,\n  iter_warmup = 2000,\n  iter_sampling = 2000, \n  init = function() list(lambda=rnorm(nItems, mean=10, sd=2))\n)\n```\n:::\n\n\n\nThe `init` option can be specified as a function, here, randomly starting each $\\lambda$ following a normal distribution\n\n## Initialization Process\n\nSee the lecture R syntax for information on how to confirm starting values are set.\n\nYou should find the initial values using `$init()` function\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelCFA_samplesFix$init()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n[[1]]$lambda\n [1]  7.505537  8.652382 13.870335 11.813123 11.473054 10.293251 10.566242\n [8] 11.178553 10.431699 10.310106\n\n\n[[2]]\n[[2]]$lambda\n [1] 11.907653  9.668295 10.510007  8.205055 13.167940 12.785517  6.375484\n [8]  9.567361 11.099712 10.965472\n\n\n[[3]]\n[[3]]$lambda\n [1] 11.521697  9.108684  7.589333 10.602933  6.921710 11.270741 11.405904\n [8]  6.188234 11.877843  9.551016\n\n\n[[4]]\n[[4]]$lambda\n [1]  8.652366 10.891575 12.561234 13.130260  7.598908  9.124610 10.292763\n [8] 10.132038  9.109928  5.315775\n```\n\n\n:::\n:::\n\n\n\n## Final Results: Parameters\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check convergence\nmax(modelCFA_samplesFix$summary()$'rhat')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.006357\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(modelCFA_samplesFix$summary(c(\"mu\", \"lambda\", \"psi\"),.cores = 4) |> mutate(across(c(mean, median), \\(x) round(x, 3))), n = Inf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 30 × 10\n   variable    mean median     sd    mad    q5   q95  rhat ess_bulk ess_tail\n   <chr>      <dbl>  <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n 1 mu[1]      2.37   2.37  0.0866 0.0851 2.22  2.51   1.00    1317.    3146.\n 2 mu[2]      1.95   1.95  0.0857 0.0846 1.81  2.09   1.01     908.    2329.\n 3 mu[3]      1.87   1.87  0.0839 0.0848 1.74  2.01   1.00    1111.    3011.\n 4 mu[4]      2.01   2.01  0.0847 0.0844 1.87  2.15   1.00    1040.    2582.\n 5 mu[5]      1.98   1.98  0.0859 0.0868 1.84  2.12   1.01     790.    2080.\n 6 mu[6]      1.89   1.89  0.0766 0.0768 1.77  2.02   1.01     750.    2168.\n 7 mu[7]      1.72   1.72  0.0767 0.0740 1.59  1.85   1.01    1000.    2708.\n 8 mu[8]      1.84   1.84  0.0723 0.0719 1.72  1.96   1.01     775.    2012.\n 9 mu[9]      1.80   1.81  0.0863 0.0854 1.66  1.95   1.00    1010.    2552.\n10 mu[10]     1.52   1.52  0.0807 0.0805 1.39  1.65   1.00    1428.    3074.\n11 lambda[1]  0.738  0.737 0.0823 0.0817 0.606 0.877  1.00    3138.    5274.\n12 lambda[2]  0.87   0.867 0.0743 0.0743 0.752 0.993  1.00    1903.    3675.\n13 lambda[3]  0.802  0.8   0.0777 0.0765 0.678 0.934  1.00    2452.    4289.\n14 lambda[4]  0.843  0.839 0.0765 0.0750 0.723 0.971  1.00    2267.    4160.\n15 lambda[5]  0.997  0.995 0.0700 0.0687 0.886 1.12   1.00    1393.    3095.\n16 lambda[6]  0.899  0.896 0.0637 0.0646 0.800 1.01   1.00    1439.    3092.\n17 lambda[7]  0.765  0.764 0.0689 0.0701 0.654 0.879  1.00    2213.    4109.\n18 lambda[8]  0.853  0.851 0.0611 0.0612 0.755 0.957  1.00    1443.    2821.\n19 lambda[9]  0.861  0.858 0.0784 0.0785 0.736 0.996  1.00    2267.    4043.\n20 lambda[10] 0.673  0.672 0.0773 0.0764 0.549 0.800  1.00    3313.    4230.\n21 psi[1]     0.891  0.889 0.0494 0.0491 0.814 0.976  1.00   15504.    6185.\n22 psi[2]     0.735  0.733 0.0433 0.0436 0.667 0.809  1.00   11583.    5925.\n23 psi[3]     0.782  0.78  0.0443 0.0442 0.712 0.858  1.00   13289.    6547.\n24 psi[4]     0.757  0.755 0.0445 0.0443 0.687 0.833  1.00   12802.    6653.\n25 psi[5]     0.545  0.544 0.0366 0.0369 0.486 0.607  1.00    7541.    6505.\n26 psi[6]     0.505  0.503 0.0336 0.0334 0.452 0.563  1.00    9362.    6500.\n27 psi[7]     0.686  0.685 0.0404 0.0401 0.623 0.755  1.00   14624.    6491.\n28 psi[8]     0.48   0.479 0.0318 0.0315 0.430 0.534  1.00    9793.    7087.\n29 psi[9]     0.781  0.779 0.0458 0.0455 0.708 0.858  1.00   11809.    7030.\n30 psi[10]    0.839  0.837 0.0467 0.0450 0.766 0.920  1.00   15303.    5988.\n```\n\n\n:::\n:::\n\n\n\n## Comparing Results with different inits\n\n![](/posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code/EAP_mu_lambda_psi_theta.png){fig-align=\"center\"}\n\nCorrelation of all parameters across both algorithm runs:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(modelCFA_samplesFix$summary(variables = c(\"mu\", \"lambda\", \"psi\", \"theta\"), .cores = 4)$mean,\n    modelCFA_samples$summary(variables = c(\"mu\", \"lambda\", \"psi\", \"theta\"), .cores = 4)$mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9999963\n```\n\n\n:::\n:::\n\n\n\n## Wrapping up\n\nToday, we showed how to model observed data using a normal distribution\n\n-   Assumptions of Confirmatory Factor Analysis\n\n    -   Not appropriate for our data\n\n    -   May not be appropriate for many data sets\n\n-   We will have to keep our loading/discrimination parameters positive to ensure converges to the same posterior mode\n\n    -   This will continue through the next types of data\n\n    -   \n\n## Next Class\n\n-   Next up, categorical distributions for observed data\n\n    -   More appropriate for these data as they are discrete categorical responses\n",
    "supporting": [
      "Lecture08_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}