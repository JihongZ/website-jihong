{
  "hash": "ce97f1aa5399bf6e276ea40cfa91fe2b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lecture 10: Mixed Models for Multivariate Regression\"\nsubtitle: \"\"\nauthor: \"Jihong Zhang*, Ph.D\"\ninstitute: | \n  Educational Statistics and Research Methods (ESRM) Program*\n  \n  University of Arkansas\ndate: \"2024-10-09\"\ndate-modified: \"2024-10-11\"\nsidebar: false\nexecute: \n  echo: true\n  warning: false\noutput-location: default\ncode-annotations: below\nhighlight-style: \"nord\"\nformat: \n  uark-revealjs:\n    scrollable: true\n    chalkboard: true\n    embed-resources: false\n    code-fold: false\n    number-sections: false\n    footer: \"ESRM 64503 - Lecture 09: Absolute Model fit and Path Analysis\"\n    slide-number: c/t\n    tbl-colwidths: auto\n    output-file: slides-index.html\n  html: \n    page-layout: full\n    toc: true\n    toc-depth: 2\n    toc-expand: true\n    lightbox: true\n    code-fold: false\n    fig-align: center\nfilters:\n  - quarto\n  - line-highlight\n---\n\n\n\n\n## \n\n\n\n\n```{=html}\n<div class=\"card shadow\">\n    <div class=\"ml-3 mt-2\">\n        <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"54\" height=\"14\" viewBox=\"0 0 54 14\">\n            <g fill=\"none\" fill-rule=\"evenodd\" transform=\"translate(1 1)\">\n                <circle cx=\"6\" cy=\"6\" r=\"6\" fill=\"#FF5F56\" stroke=\"#E0443E\" stroke-width=\".5\"></circle>\n                <circle cx=\"26\" cy=\"6\" r=\"6\" fill=\"#FFBD2E\" stroke=\"#DEA123\" stroke-width=\".5\"></circle>\n                <circle cx=\"46\" cy=\"6\" r=\"6\" fill=\"#27C93F\" stroke=\"#1AAB29\" stroke-width=\".5\"></circle>\n            </g>\n        </svg>\n    </div>\n    <div class=\"card-body\">\n        <h4 class=\"card-title\"><b>Today's Class</b></h4>\n        <ul>\n          <li>Multivaraite regression via mixed models</li>\n          <li>Comparing and contrasting path analysis with mixed models</li>\n          <ul>\n            <li>Differences in model fit measures </li>\n            <li>Differences in software estimation methods </li>\n            <li>Model comparisons via multivariate Wald tests (instead of LRTs) </li>\n            <li>How to compute R-square </li>\n          </ul>\n        </ul>\n    </div>\n</div>\n```\n\n\n\n## R Setup\n\n\n\n\n::: {.cell output-location='default'}\n\n```{.r .cell-code}\nlibrary(ESRM64503)\nlibrary(kableExtra)\nlibrary(tidyverse)\nlibrary(DescTools) # Desc() allows you to quick screen data\nlibrary(lavaan) # Desc() allows you to quick screen data\nhead(dataMath)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  id hsl cc use msc mas mse perf female\n1  1  NA  9  44  55  39  NA   14      1\n2  2   3  2  77  70  42  71   12      0\n3  3  NA 12  64  52  31  NA   NA      1\n4  4   6 20  71  65  39  84   19      0\n5  5   2 15  48  19   2  60   12      0\n6  6  NA 15  61  62  42  87   18      0\n```\n\n\n:::\n\n```{.r .cell-code}\ndim(dataMath)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 350   9\n```\n\n\n:::\n:::\n\n\n\n\n## Correction about `fixed.x` argument in previous lecture\n\n-   If TRUE, the exogenous ‘x’ covariates are considered fixed variables and the means, variances and covariances of these variables are fixed to their sample values.\n\n-   If FALSE, they are considered random, and the means, variances and covariances are free parameters.\n\n-   If \"default\", the value is set depending on the mimic option.\n\n[Thus, we considered the distributions of exogenous variables as known parameters.]{.underline}\n\n## Big Picture\n\n> A **mixed model**, **mixed-effects model** or **Linear mixed models** (LMMs) is a [statistical model](https://en.wikipedia.org/wiki/Statistical_model \"Statistical model\") containing both [fixed effects](https://en.wikipedia.org/wiki/Fixed_effect \"Fixed effect\") and [random effects](https://en.wikipedia.org/wiki/Random_effect \"Random effect\"). These models are useful in a wide variety of disciplines in the physical, biological and social sciences.\n\n-   Mixed model can answer similar research questions as Path Analysis (or structural equation model):\n\n    -   Relationships among multiple endogenous variables\n\n## Properties of Mixed Models\n\n1.  Mixed models are used for many types of analyses:\n    -   Analogous to **MANOVA** and M-Regression (so repeated measures analyses)\n    -   Multilevel models for *clustered*, *longitudinal*, and *crossed-effects* data\n2.  The biggest difference between mixed models and path analysis software is the [assumed distribution of the exogenous variables]{.underline}：\n    -   Mixed models: no distribution assumed\n    -   Path analysis: most software assumes multivariate normal distribution\n    -   This affects how missing data are managed – mixed models cannot have any missing IVs\n3.  Mixed models also do not allow endogenous variables to predict other endogenous variables\n    -   No indirect effects are possible from a single analysis (multiple analyses needed)\n4.  Mixed models software also often needs variables to be stored in so-called “stacked” or long-format data (one row per DV)\n    -   We used **wide-format** data for `lavaan` (one row per person)\n\n## Wide to Long Data Transformation\n\n-   Original wide-format data (all DVs for a person on one row)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat <- dataMath\ndat$cc10 <- dat$cc - 10\n(dat_wide <- dat |> select(id, perf, use, female, cc10))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     id perf use female cc10\n1     1   14  44      1   -1\n2     2   12  77      0   -8\n3     3   NA  64      1    2\n4     4   19  71      0   10\n5     5   12  48      0    5\n6     6   18  61      0    5\n7     7   10  51      0  -10\n8     8   NA  45      0    3\n9     9   14  51      0    2\n10   10   13  36      0   12\n11   11   13  78      0    5\n12   12   16  51      1   -6\n13   13   15  73      0   -2\n14   14    8  27      1  -10\n15   15   15  34      0   11\n16   16   NA  46      0    1\n17   17   16  NA      1    1\n18   18   14  65      0    1\n19   19   15  78      0    0\n20   20   12  60      0    5\n21   21   15  35      1   -6\n22   22   NA  25      0   NA\n23   23   11  67      1    6\n24   24   23  67      0    9\n25   25   NA  62      1  -10\n26   26   22  50      0    0\n27   27   14  84      1   10\n28   28   12  NA      0    0\n29   29   16  58      1   -8\n30   30   13  58      0   -1\n31   31   11  50      0   -8\n32   32   13  51      1   -1\n33   33   11  65      0   -6\n34   34   10  65      0   -1\n35   35   13  70      0   -5\n36   36   14  77      0    5\n37   37   14  58      0   -4\n38   38   14  51      1    4\n39   39   12  65      0    0\n40   40   13  51      0    4\n41   41   15  57      0   -1\n42   42   10  33      0  -10\n43   43   14  57      0   -2\n44   44   NA  52      0    2\n45   45   13  59      0   -7\n46   46   16  44      1   -5\n47   47   12  52      0    5\n48   48   13  47      0   -7\n49   49   17  25      0   -3\n50   50   12  47      1   NA\n51   51   NA  25      0    3\n52   52   15  63      0   NA\n53   53   NA  58      1   NA\n54   54   NA  50      1  -10\n55   55   NA  38      1   -2\n56   56   15  56      0    3\n57   57    9  32      0   -6\n58   58   13  54      1    3\n59   59   16  38      0   -6\n60   60    5  44      0    0\n61   61   13  44      0   NA\n62   62   13  47      1  -10\n63   63   22  51      1    5\n64   64   14  53      1   -7\n65   65   12  36      0   -5\n66   66   13  50      0   -7\n67   67   19  49      0    2\n68   68    9  78      0   -5\n69   69   11  31      0    6\n70   70   11  66      1   -3\n71   71   20  19      0   -6\n72   72   14  73      0   -2\n73   73   13  50      1    5\n74   74   13  63      0    0\n75   75   17  68      1   -2\n76   76   14  53      1   NA\n77   77   12  54      0  -10\n78   78   NA  52      1   -9\n79   79   16  64      0    4\n80   80   NA  61      0   NA\n81   81   19  86      0    6\n82   82   14  69      0    9\n83   83   11  51      0   -4\n84   84   15  65      0    2\n85   85   12  60      0  -10\n86   86   18  73      0    5\n87   87   18  63      0    4\n88   88   16  NA      0   -2\n89   89   12  75      0   -2\n90   90   13  38      0   -9\n91   91   15  62      1   -3\n92   92   14  64      0   15\n93   93   NA  66      1    3\n94   94    9  39      0  -10\n95   95   17  40      0    1\n96   96   11  43      0   NA\n97   97    9  NA      0  -10\n98   98   14  NA      0    3\n99   99   14  42      0   -7\n100 100   15  71      0   -2\n101 101   NA  50      1    0\n102 102   NA  NA      1    1\n103 103   11  54      1    0\n104 104   NA  62      1   NA\n105 105   11  NA      1   -3\n106 106   10  28      0   -8\n107 107   NA  38      1   -8\n108 108   15  45      0    1\n109 109   13  50      0   -3\n110 110   16  38      0    0\n111 111   13  49      0   -5\n112 112    9  NA      0   12\n113 113   10  39      1   -5\n114 114   NA  63      0    2\n115 115   12  81      1    5\n116 116   NA  51      1    2\n117 117    9  36      0   -2\n118 118   15  20      0    0\n119 119   NA  66      1    1\n120 120   NA  22      1   -4\n121 121   18  83      0   12\n122 122   12  83      0   -1\n123 123   12  62      1  -10\n124 124    8  54      0   -3\n125 125   17   0      0   -3\n126 126   16  68      0    7\n127 127   13  71      0    9\n128 128   17  73      0   NA\n129 129   14  52      0    6\n130 130   13  31      0   -3\n131 131   12  55      0    7\n132 132   17  47      0   -5\n133 133   16  68      1    0\n134 134   13  51      0   -5\n135 135   17  34      1   -3\n136 136   13  47      0    9\n137 137   NA  49      0   -4\n138 138   16  45      0   -1\n139 139   NA  32      0   -9\n140 140   NA  58      0    2\n141 141   NA  48      0   NA\n142 142   17  95      0    4\n143 143   14  42      0    4\n144 144   15  NA      0    4\n145 145   15  80      0   -7\n146 146   NA  49      0    0\n147 147   14  NA      1    5\n148 148   18  42      1    9\n149 149   12  30      0    2\n150 150   14  37      0    4\n151 151   16  56      1   NA\n152 152   NA  NA      0   10\n153 153   12  31      0    2\n154 154   16  62      1    0\n155 155   21  66      1    9\n156 156   11  35      0    7\n157 157   NA  59      1    0\n158 158   14  47      1    0\n159 159   19  84      1    2\n160 160   15  54      0    0\n161 161   19  58      1    2\n162 162   13  54      1   -4\n163 163   20  64      0   11\n164 164   10  58      0    3\n165 165   16  47      0   NA\n166 166   16  35      0   NA\n167 167   14  NA      0    4\n168 168   12  63      0   -4\n169 169   13  29      1   -6\n170 170   NA  51      0   -1\n171 171   17  29      0    2\n172 172   NA  42      1   11\n173 173   15  28      0   17\n174 174   NA  39      0   -6\n175 175   16  60      0   NA\n176 176   13  NA      0   -8\n177 177   16  53      0  -10\n178 178   16  43      0   NA\n179 179   NA  45      0   -4\n180 180   12 100      0    1\n181 181   17  36      1    3\n182 182   21  34      0   -3\n183 183   18  70      0   NA\n184 184   11  NA      0   10\n185 185   18  64      0    3\n186 186   10  41      1   NA\n187 187   14  72      1   -3\n188 188   16  69      0   NA\n189 189   19  59      1   -2\n190 190   13  51      0   -5\n191 191   14  53      1    0\n192 192   12  49      0    9\n193 193   18  65      1    1\n194 194   17  49      0    4\n195 195   NA  73      0    1\n196 196   19  33      1    9\n197 197   14  78      0    1\n198 198   NA  71      0   14\n199 199   15  52      0   -2\n200 200   11  55      0   NA\n201 201   NA  41      1   -3\n202 202   12  35      0   -4\n203 203   13  64      1   NA\n204 204   14  31      0    8\n205 205   15  44      1    7\n206 206   NA  45      1   -9\n207 207   NA  36      0    3\n208 208   10  13      0    3\n209 209   11  46      1    5\n210 210   15  72      0   -4\n211 211   13  32      0   NA\n212 212   17  44      1    5\n213 213   12  NA      1    5\n214 214   NA  36      0    6\n215 215   15  55      0   NA\n216 216   19  63      1   -5\n217 217   16  64      0  -10\n218 218   11  41      1   -5\n219 219   10  NA      0   NA\n220 220   17  34      0   12\n221 221   16  76      1  -10\n222 222   11  50      0  -10\n223 223   11  65      0   NA\n224 224   11  51      0    2\n225 225   NA  52      0    2\n226 226   16  25      0   -2\n227 227   15  39      0   -6\n228 228   16  46      0   10\n229 229   11  79      1   -2\n230 230   17  77      1   12\n231 231   15  15      0  -10\n232 232   12  49      1   NA\n233 233   15  70      1    8\n234 234    7  NA      1  -10\n235 235   15  57      0   13\n236 236   11  71      0   -5\n237 237    7  57      0    3\n238 238   12  50      0    0\n239 239   12  48      0    0\n240 240   13  63      0    6\n241 241   13  45      1   -5\n242 242   NA  50      0    3\n243 243   NA  60      0   -3\n244 244   13  36      1   -6\n245 245   14  38      0    9\n246 246   16  57      0    1\n247 247   17  53      0    4\n248 248   20  48      0   11\n249 249   NA  66      1    4\n250 250   15  48      0   -4\n251 251   12  72      1    2\n252 252   15  37      0    7\n253 253   15  70      1   -1\n254 254   11  54      1    0\n255 255    9  37      0   -2\n256 256   11  49      1  -10\n257 257   NA  65      1    0\n258 258   14  65      1   -6\n259 259   13  44      1   -1\n260 260   11  NA      1    8\n261 261   NA  55      0   -2\n262 262   16  67      0   -6\n263 263   15  76      1    2\n264 264   15  NA      1    3\n265 265   NA  52      0    0\n266 266   17  68      1    2\n267 267   NA  68      0   NA\n268 268   NA  71      0   -4\n269 269   11  55      0   -4\n270 270   13  68      0    9\n271 271   12  47      1   -2\n272 272   NA  22      0   NA\n273 273   16  67      1    3\n274 274   10  23      1   -3\n275 275   12  45      1   -8\n276 276   13  NA      1   NA\n277 277   15  54      0   10\n278 278   17  16      1    3\n279 279    6  37      0    5\n280 280   10  43      1    0\n281 281   16  19      0   -1\n282 282   15  61      0   -8\n283 283   12  24      0    9\n284 284    8  44      1   -2\n285 285   12  48      1    2\n286 286   15  51      0   10\n287 287   11  65      0   -5\n288 288   15  78      0    4\n289 289   NA  44      1   -1\n290 290   18  52      1   11\n291 291   15  52      0   NA\n292 292   19  66      0    2\n293 293   NA  53      0    3\n294 294   14  49      1   -4\n295 295   11  35      0   -2\n296 296   13  60      0    5\n297 297   12  NA      0  -10\n298 298   17  45      1    8\n299 299   14  62      0   -1\n300 300   19  NA      0   -9\n301 301   10  30      1   -3\n302 302   NA  44      0    5\n303 303   12  46      1   -2\n304 304   18  NA      1   NA\n305 305   NA  43      0    3\n306 306   16  42      0   -2\n307 307   17  64      0    7\n308 308   16  27      0    6\n309 309   13  58      1   NA\n310 310   17  61      1   -1\n311 311   15  29      1    1\n312 312   18  40      0    1\n313 313   16  47      0    2\n314 314   13  63      0    6\n315 315   13  57      0    3\n316 316   14  54      1    3\n317 317   NA  68      1  -10\n318 318   15  42      1    0\n319 319   NA  70      0   -1\n320 320   11  NA      0   -7\n321 321   NA  69      0    0\n322 322   15  79      0   16\n323 323   14  59      0    0\n324 324   NA  30      0    2\n325 325   11  31      0    3\n326 326   11  63      1    4\n327 327   13  32      1   -1\n328 328    9  59      0   -7\n329 329   NA  66      0   -1\n330 330   21  57      1    7\n331 331   11  30      0    9\n332 332   15  64      1   -5\n333 333   NA  66      0    0\n334 334   14  63      0    3\n335 335   10  23      0    3\n336 336   16  43      0    3\n337 337   10  64      0    3\n338 338   11  27      0    1\n339 339   18  92      1    3\n340 340   20  70      1  -10\n341 341   18  63      0   NA\n342 342   10  74      0    9\n343 343   14  45      1   NA\n344 344   12  50      1   -8\n345 345   13  64      1   NA\n346 346   16  61      0    2\n347 347   NA  24      0    3\n348 348   13  73      0   -7\n349 349   15  39      0   NA\n350 350   NA  65      0   NA\n```\n\n\n:::\n:::\n\n\n\n\n-   Reshape with `pivot_longer()` function and Resulting data:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_long <- dat_wide |> \n  pivot_longer(cols = c(perf, use), \n               names_to = \"DV\", \n               values_to = \"score\") |> \n  mutate(dPerf = ifelse(DV == 'perf', 0, 1)) # convert DVs into indicator variable - dperf\ndat_long\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 700 × 6\n      id female  cc10 DV    score dPerf\n   <int>  <int> <dbl> <chr> <int> <dbl>\n 1     1      1    -1 perf     14     0\n 2     1      1    -1 use      44     1\n 3     2      0    -8 perf     12     0\n 4     2      0    -8 use      77     1\n 5     3      1     2 perf     NA     0\n 6     3      1     2 use      64     1\n 7     4      0    10 perf     19     0\n 8     4      0    10 use      71     1\n 9     5      0     5 perf     12     0\n10     5      0     5 use      48     1\n# ℹ 690 more rows\n```\n\n\n:::\n:::\n\n\n\n\n## Path Model VS. Mixed Model\n\n-   Before we dive into mixed models, we will begin with a multivariate regression model:\n    -   Predicting mathematics performance (PERF) with female (F), college math experience (CC), and the interaction between female and college math experience (FxCC)\n    -   Predicting perceived usefulness (USE) with female (F), college math experience (CC), and the interaction between female and college math experience (FxCC)\n\n$$\nPERF_i = \\beta_{0,PERF} + \\beta_{F,PERF} F_i + \\beta_{CC,PERF}CC_i + \\beta_{F*CC,PERF}F_i*CC_i + e_{i,PERF}\n$$ {#eq-pathmodel1} $$\nUSE_i = \\beta_{0,USE} + \\beta_{F,USE} F_i + \\beta_{CC,USE}CC_i + \\beta_{F*CC,USE}F_i*CC_i + e_{i,USE}\n$$ {#eq-pathmodel2}\n\n-   Mixed Model: Here I use the symbol $\\delta$ to represent each fixed effect in the multivariate model from the mixed model perspective\n\n$$\nScore_i = (\\delta_{0,PERF} + \\delta_{0, dPERF}) + (\\delta_{F,PERF} + \\delta_{F, dPERF}) F_i + (\\delta_{CC,PERF} \\\\ + \\delta_{CC, dPERF}) CC_i + (\\delta_{F*CC,PERF} + \\delta_{F*CC,dPERF}) F_i*CC_i + e_{i,PERF} + e_{i,dPERF}\n$$ {#eq-mixedmodel1}\n\n$$\nScore_i = \\delta_{0,PERF} + \\delta_{0, dPERF}dPERF_i + \\delta_{F,PERF} F_i + \\delta_{F, dPERF}dPERF_i * F_i \\\\ \n+ \\delta_{CC,PERF} CC_i + \\delta_{CC, dPERF} dPERF_i * CC_i \\\\ \n+ \\delta_{F*CC,PERF} F_i*CC_i + \\delta_{F*CC,dPERF} dPERF_i * F_i*CC_i + e_{i,PERF} + e_{i,dPERF}\n$$ {#eq-mixedmodel2}\n\n# Build the Empty Model: Not So Empty\n\n## Statistical Form\n\n-   For illustration, let's start from the empty model\n\n-   A multivariate model using mixed model software uses the dummy code for DV to make all effects conditional on the specific DV in the model\n\n    -   I will compare/contrast these with the symbols $\\beta$ from the fixed effects in path analysis\n\n-   For instance, our empty model is thus:\n\n    -   Where *Score* is condition on the value of *dPerf*:\n        -   When $dPerf = 0$ $\\rightarrow$ DV = \"Use\" $\\rightarrow$ $Score_i = Use_i = \\delta_0 + e_{i, Use}$\n        -   When $dPerf = 1$ $\\rightarrow$ DV = \"Perf\" $\\rightarrow$ $Score_i = Perf_i = \\delta_0 + \\delta_1 + e_{i, perf}$\n\n$$\nScore_{i, DV} = \\delta_0 + \\delta_1 dPerf_i + e_{i, DV}\n$$\n\n## Estimating the Empty Model\n\n-   From the `nlme` library, we will use the `gls()` function\n\n    -   Be sure the library is installed and loaded before trying this!\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(nlme)\n\ndat_long <- dat_long[complete.cases(dat_long), ]\n# create empty model using REML estimation to attempt to mirror initial analysis:\nmodel01_mixed = gls(model = score ~ 1 + dPerf, #<1>\n                    data = dat_long,\n                    method = \"REML\", #<2>\n                    correlation = corSymm(form = ~1|id), #<3>\n                    weights = varIdent(form = ~1|DV)) #<4>\nsummary(model01_mixed)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGeneralized least squares fit by REML\n  Model: score ~ 1 + dPerf \n  Data: dat_long \n       AIC      BIC    logLik\n  3774.313 3795.871 -1882.156\n\nCorrelation Structure: General\n Formula: ~1 | id \n Parameter estimate(s):\n Correlation: \n  1    \n2 0.136\nVariance function:\n Structure: Different standard deviations per stratum\n Formula: ~1 | DV \n Parameter estimates:\n    perf      use \n1.000000 5.337397 \n\nCoefficients:\n               Value Std.Error  t-value p-value\n(Intercept) 13.94085 0.1868631 74.60461       0\ndPerf       38.46901 0.9399708 40.92575       0\n\n Correlation: \n      (Intr)\ndPerf -0.079\n\nStandardized residuals:\n        Min          Q1         Med          Q3         Max \n-3.24789265 -0.64196261  0.01956532  0.68109325  2.99644101 \n\nResidual standard error: 3.023304 \nDegrees of freedom: 553 total; 551 residual\n```\n\n\n:::\n:::\n\n\n\n\n1.  `score ~ 1 + dPerf`: $Score_{i, DV} = \\delta_0 + \\delta_1 dPerf_i + e_{i, DV}$\n2.  \"REML\": Residual Maximum Likelihood Estimation\n3.  Provides estimates of all unique correlations; Needs `id` variable name after | for program to know which data comes from which person\n4.  Estimates a different (residual) variance for each DV; With correlation line ensures an unstructured model is estimated\n  \n## Empty Model Results I: Covariance Matrix of DVs\n\n-   The covariance matrix of DVs comes from the `getVarCov()` function\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngetVarCov(model01_mixed)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMarginal variance covariance matrix\n       [,1]     [,2]\n[1,] 9.1404   6.6311\n[2,] 6.6311 260.3900\n  Standard Deviations: 3.0233 16.137 \n```\n\n\n:::\n:::\n\n\n\n-   Estimated variance-covariance matrix of PERF and USE scores.\n\n## Mapping Multivariate Mixed Models onto Path Models\n\n-   To compare this result with the path analyses we conducted previously, we’ll have to use this data set\n    -   Omit the same observations\n    \n-   So, we’ll need to take our long-format data and reshape it into wide-format:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(dat_wide)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  id perf use female cc10\n1  1   14  44      1   -1\n2  2   12  77      0   -8\n3  3   NA  64      1    2\n4  4   19  71      0   10\n5  5   12  48      0    5\n6  6   18  61      0    5\n```\n\n\n:::\n:::\n\n::: {.cell output-location='slide'}\n\n```{.r .cell-code}\nlibrary(lavaan)\nmodel01_mirror.syntax = \"\n# Means:\nperf ~ 1\nuse ~ 1\n\n# Variances:\nperf ~~ perf\nuse ~~ use\n\n# Covariance:\nperf ~~ use\n\"\n\nmodel01_path_noNA.fit = sem(model01_mirror.syntax, data = dat_wide,\n                            fixed.x = TRUE, \n                            mimic = \"MPLUS\", \n                            estimator = \"MLR\")\nsummary(model01_path_noNA.fit, \n        fit.measures = TRUE,\n        standardized = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlavaan 0.6-19 ended normally after 29 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         5\n\n                                                  Used       Total\n  Number of observations                           348         350\n  Number of missing patterns                         3            \n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                                 0.000       0.000\n  Degrees of freedom                                 0           0\n\nModel Test Baseline Model:\n\n  Test statistic                                 6.064       5.573\n  Degrees of freedom                                 1           1\n  P-value                                        0.014       0.018\n  Scaling correction factor                                  1.088\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000       1.000\n  Tucker-Lewis Index (TLI)                       1.000       1.000\n                                                                  \n  Robust Comparative Fit Index (CFI)                         1.000\n  Robust Tucker-Lewis Index (TLI)                            1.000\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -2085.032   -2085.032\n  Loglikelihood unrestricted model (H1)      -2085.032   -2085.032\n                                                                  \n  Akaike (AIC)                                4180.064    4180.064\n  Bayesian (BIC)                              4199.325    4199.325\n  Sample-size adjusted Bayesian (SABIC)       4183.464    4183.464\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000          NA\n  90 Percent confidence interval - lower         0.000          NA\n  90 Percent confidence interval - upper         0.000          NA\n  P-value H_0: RMSEA <= 0.050                       NA          NA\n  P-value H_0: RMSEA >= 0.080                       NA          NA\n                                                                  \n  Robust RMSEA                                               0.000\n  90 Percent confidence interval - lower                     0.000\n  90 Percent confidence interval - upper                     0.000\n  P-value H_0: Robust RMSEA <= 0.050                            NA\n  P-value H_0: Robust RMSEA >= 0.080                            NA\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.000       0.000\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  perf ~~                                                               \n    use               6.847    2.850    2.403    0.016    6.847    0.147\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n    perf             13.959    0.174   80.442    0.000   13.959    4.721\n    use              52.440    0.872   60.140    0.000   52.440    3.322\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n    perf              8.742    0.754   11.596    0.000    8.742    1.000\n    use             249.245   19.212   12.973    0.000  249.245    1.000\n```\n\n\n:::\n:::\n\n\n\n\n## Comparing and Contrasting Results: Intercept (fixed effect)\n\n-   $\\beta_{0,Perf}$ and $\\beta_{0,Use}$:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nparameterestimates(model01_path_noNA.fit) |> filter(op == \"~1\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   lhs op rhs    est    se      z pvalue ci.lower ci.upper\n1 perf ~1     13.959 0.174 80.442      0   13.619   14.299\n2  use ~1     52.440 0.872 60.140      0   50.731   54.149\n```\n\n\n:::\n:::\n\n\n\n\n-   $\\delta_{0,DV}$ and $\\delta_{1,DV}$:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(model01_mixed)$tTable\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               Value Std.Error  t-value       p-value\n(Intercept) 13.94085 0.1868631 74.60461 3.552065e-290\ndPerf       38.46901 0.9399708 40.92575 3.477058e-169\n```\n\n\n:::\n:::\n\n\n\n\n$\\delta_{0,DV} + \\delta_{1,DV}$: 52.40986 is close to $\\beta_{0,Use}$\n\n## Comparing and Contrasting Results: Residual variance coviarance\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nparameterestimates(model01_path_noNA.fit) |> filter(op == \"~~\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   lhs op  rhs     est     se      z pvalue ci.lower ci.upper\n1 perf ~~ perf   8.742  0.754 11.596  0.000    7.264   10.219\n2  use ~~  use 249.245 19.212 12.973  0.000  211.590  286.900\n3 perf ~~  use   6.847  2.850  2.403  0.016    1.261   12.433\n```\n\n\n:::\n:::\n\n\n\nIn mixed model, we cannot get the z-value (significance testing)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngetVarCov(model01_mixed)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMarginal variance covariance matrix\n       [,1]     [,2]\n[1,] 9.1404   6.6311\n[2,] 6.6311 260.3900\n  Standard Deviations: 3.0233 16.137 \n```\n\n\n:::\n:::\n\n\n\n\n## Residual Maximum Likelihood Estimation\n\n-   The ML estimator is nice, but the variance estimate is downward biased (too small)\n    -   Remember – it divides by N for the residual covariance matrix\n    \n-   In small samples, this is likely to lead to biased estimates and incorrect p-values    \n    -   The variance goes into the SE, which goes into the Wald test, which dictates the p-value for the beta\n    \n-   Instead, another maximum likelihood technique has been developed: Residual Maximum Likelihood (REML) \n    -   Maximizes the likelihood of the residuals rather than the data\n    -   Has unbiased estimates of the residual covariance matrix\n    -   Is the default method of estimation for most mixed model estimation packages\n    \n-   There is one catch to REML: you cannot use a LRT to compare nested models with differing fixed effects\n    -   Because the algorithm uses residuals not data likelihood, if the residuals change, the likelihood changes\n    -   Residuals come from the fixed effects $\\rightarrow$ if fixed effects are different, then residuals change, causing the likelihood to change\n    -   Can use multivariate Wald test for fixed effects\n    \n-   Don't mix ML and REML for the same analysis    \n\n# ADDING PREDICTORS TO THE MODEL\n\n## Adding more predictors\n\n-   Adding predictors to the model is similar to adding predictors in regular regression models\n\n-   By using REML we cannot compare models using likelihood ratio tests\n    -   REML LRTs must have same fixed effects\n    -   Adding predictors adds new fixed effects to the empty model\n    \n-   We are predicting each DV with `female`, `cc10`, and `female*cc10`\n\n## Model with Predictors: Syntax\n\n\n\n\n::: {.cell output-location='slide'}\n\n```{.r .cell-code}\n# Model 02: all predictors included\nmodel02_formula = as.formula(\"score ~ 1 + dPerf + female + dPerf*female + cc10 + dPerf*cc10 + female*cc10 + dPerf*female*cc10\")\nmodel02_mixed <- gls(model = model02_formula, method = \"REML\",\n                     data = dat_long, \n                     correlation = corSymm(form = ~1|id),\n                     weights = varIdent(form = ~1|DV))\nsummary(model02_mixed)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngetVarCov(model02_mixed)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMarginal variance covariance matrix\n       [,1]     [,2]\n[1,] 8.5491   5.0582\n[2,] 5.0582 259.5200\n  Standard Deviations: 2.9239 16.11 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(model02_mixed)$tTable |> round(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                   Value Std.Error t-value p-value\n(Intercept)       13.689     0.224  61.183   0.000\ndPerf             38.110     1.175  32.429   0.000\nfemale             0.658     0.384   1.715   0.087\ncc10               0.099     0.035   2.786   0.006\ndPerf:female       1.177     2.007   0.587   0.558\ndPerf:cc10         0.097     0.198   0.488   0.626\nfemale:cc10        0.094     0.067   1.396   0.163\ndPerf:female:cc10  0.166     0.353   0.472   0.637\n```\n\n\n:::\n:::\n\n\n\n\n       \n             \n             \n               \n       \n         \n        \n  \n\n1. $\\beta_0 = 13.689, p < .001$\n2. $\\beta_{dPerf} = 38.110, p < .001$\n3. $\\beta_{female} = 0.658, p = 0.087$\n4. $\\beta_{cc10} = 0.099, p = 0.006$\n5. $\\beta_{dPerf*female} = 1.177, p = 0.558$\n6. $\\beta_{dPerf*cc10} = 0.097, p = 0.626$\n7. $\\beta_{female*cc10} = 0.094, p = 0.163$\n8. $\\beta_{dPerf*female*cc10} = 0.166, p = 0.637$\n\n## First Question: Which Model “Fits” Better?\n\n-   After adding the predictors (estimating their betas) to the model, we must first ask which model fits better\n\n-   A likelihood ratio test (LRT) cannot be performed as we are using REML\n\n-   Use multivariate wald test\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(multcomp)\nmodel2_model_matrix <- diag(rep(1, 8))\nrownames(model2_model_matrix) <- c(\n  \"Intercept\",\n  \"dPerf\",\n  \"female\",\n  \"cc10\",\n  \"dPerf:female\",\n  \"dPerf:cc10\",\n  \"female:cc10\",\n  \"dPerf:female:cc10\"\n)\neffects <- glht(model = model02_mixed, linfct = model2_model_matrix)\nsummary(effects)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\t Simultaneous Tests for General Linear Hypotheses\n\nFit: gls(model = model02_formula, data = dat_long, correlation = corSymm(form = ~1 | \n    id), weights = varIdent(form = ~1 | DV), method = \"REML\")\n\nLinear Hypotheses:\n                       Estimate Std. Error z value Pr(>|z|)    \nIntercept == 0         13.68949    0.22375  61.183   <1e-04 ***\ndPerf == 0             38.10983    1.17517  32.429   <1e-04 ***\nfemale == 0             0.65832    0.38378   1.715   0.4735    \ncc10 == 0               0.09871    0.03543   2.786   0.0396 *  \ndPerf:female == 0       1.17738    2.00682   0.587   0.9973    \ndPerf:cc10 == 0         0.09653    0.19790   0.488   0.9992    \nfemale:cc10 == 0        0.09377    0.06716   1.396   0.7130    \ndPerf:female:cc10 == 0  0.16641    0.35291   0.472   0.9994    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(effects, test = Ftest())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\t General Linear Hypotheses\n\nLinear Hypotheses:\n                       Estimate\nIntercept == 0         13.68949\ndPerf == 0             38.10983\nfemale == 0             0.65832\ncc10 == 0               0.09871\ndPerf:female == 0       1.17738\ndPerf:cc10 == 0         0.09653\nfemale:cc10 == 0        0.09377\ndPerf:female:cc10 == 0  0.16641\n\nGlobal Test:\n  Chisq DF Pr(>Chisq)\n1  8328  8          0\n```\n\n\n:::\n:::\n\n\n\n\n- Note: R’s `nlme` function doesn’t do a good job with df.residual and provides a Chi-square test\n\n- Also note there are 6 degrees of freedom (one for each additional beta weight in the model)\n\n## Questions that can be answered \n\n- What is the effect of college experience on usefulness for males?\n- What is the effect of college experience on usefulness for females?\n- What is the difference between males and females ratings of usefulness when college experience = 10?\n- How did the difference between males and females ratings change for each additional hour of college experience?\n- What is the effect of college experience on performance for males?\n- What is the effect of college experience on performance for females?\n- What is the difference between males and females performance when college experience = 10?\n- How did the difference between males and females performance change for each additional hour of college experience?\n\n## Model R-squared\n\nTo determine the model R-squared, we have to compare the variance/covariance matrix from model01 and model02 and make the statistics ourselves:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nVmodel01 = getVarCov(model01_mixed)\nVmodel02 = getVarCov(model02_mixed)\n\n## Rsquare for Performance and Usefulness\n(diag(Vmodel01) - diag(Vmodel02)) / diag(Vmodel01)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.064686450 0.003341706\n```\n\n\n:::\n:::\n\n\n\n- 6.47% variance of performance was explained by added predictors.\n- 0.33% variance of usefulness was explained by added predictors.\n\n## Wrapping up\n\n- Things we get directly from path models that we do not get directly in mixed models:\n      - Tests for approximate model fit\n      - Scaled Chi-square for some types of non-normal data\n      - Standardized parameter coefficients\n      - Tests for indirect effects\n      - R-squared statistics\n- Things we get directly in mixed models that we do not get in path models:\n      - REML (unbiased estimates of variances/covariances)\n      \n- In this lecture we discussed the basics of mixed model analyses for multivariate models\n      - Model specification/identification\n      - Model estimation\n      - Model modification and re-estimation\n      - Final model parameter interpretation\n- There is a lot to the analysis – but what is important to remember is the over-arching principal of multivariate analyses: covariance between variables is important\n      - Mixed models imply very specific covariance structures\n      - The validity of the results still hinge upon accurately finding an approximation to the covariance matrix      ",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}