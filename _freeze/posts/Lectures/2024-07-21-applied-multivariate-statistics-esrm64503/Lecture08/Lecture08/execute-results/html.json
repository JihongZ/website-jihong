{
  "hash": "e0d303906300ceaae1c89a5d9fc814e6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lecture 08: Multivariate Analysis\"\nsubtitle: \"Model Setup and Assumptions\"\nauthor: \"Jihong Zhang*, Ph.D\"\ninstitute: | \n  Educational Statistics and Research Methods (ESRM) Program*\n  \n  University of Arkansas\ndate: \"2024-10-09\"\ndate-modified: \"2024-10-09\"\nsidebar: false\nexecute: \n  echo: true\n  warning: false\noutput-location: column\ncode-annotations: below\nformat: \n  uark-revealjs:\n    scrollable: true\n    chalkboard: true\n    embed-resources: false\n    code-fold: false\n    number-sections: false\n    footer: \"ESRM 64503 - Lecture 08: Multivariate Analysis\"\n    slide-number: c/t\n    tbl-colwidths: auto\n    output-file: slides-index.html\n  html: \n    page-layout: full\n    toc: true\n    toc-depth: 2\n    toc-expand: true\n    lightbox: true\n    code-fold: false\n    fig-align: center\nfilters:\n  - quarto\n  - line-highlight\n---\n\n\n\n\n## Today's Class\n\n-   Multivariate linear models: an introduction\n-   How to form multivariate models in `lavaan`\n-   What parameters mean\n-   How they relate to the multivariate normal distribution\n\n# Multivariate Models: An Introduction\n\n## Multivariate Linear Models\n\n-   The next set of lectures are provided to give an overview of multivariate linear models\n    -   Models for **more than one** dependent/outcome variables\n-   Our focus will be on models where the DV is plausibly continuous\n    -   so we’ll use error terms that are multivariate normally distributed\n    -   Not a necessity – **generalized multivariate models** are possible\n\n## Classical vs. Contemporary Methods\n\n-   In \"classical\" multivariate textbooks and classes multivariate linear models fall under the names of Multivariate ANOVA (MANOVA) and Multivariate Regression\n\n-   These methods rely upon least squares estimation which:\n\n    1.  Inadequate with missing data\n    2.  Offers very limited methods of setting covariance matrix structures\n    3.  Does not allow for different sets predictor variables for each outcome\n    4.  Does not give much information about model fit\n    5.  Does not provide adequate model comparison procedures\n\n-   The classical methods have been subsumed into the modern (likelihood or Bayes-based) multivariate methods\n\n    -   Subsume: include or absorb (something) in something else\n    -   Meaning: modern methods do what classical methods do (and more)\n\n## Contemporary Methods for Estimating Multivariate Linear Models\n\n-   We will discuss three large classes of multivariate linear modeling methods:\n\n    -   Path analysis models (typically through structural equation modeling and path analysis software)\n    -   Linear mixed models (typically through linear models software)\n    -   Psychological network models (typically through psychological network software)\n    -   Bayesian networks (frequently not mentioned in social sciences but subsume all we are doing)\n\n-   The theory behind each is identical – the main difference is in software\n\n    -   Some software does a lot (`Mplus` software is likely the most complete), but none (as of 2024) do it all\n\n-   We will start with path analysis (via the `lavaan` package) as the modeling method is more direct but then move to linear mixed models software (via the `nlme` and `lme4` packages)\n\n-   Bayesian networks will be discussed in the Bayes section of the course and will use entirely different software\n\n## The \"Curse\" of Dimensionality: Shared Across Models\n\n-   Having lots of parameters creates a number of problems\n\n    -   Estimation issues for small sample sizes\n    -   Power to detect effects\n    -   Model fit issues for large numbers of outcomes\n\n-   **Curse of dimensionality**: for multivariate normal data, there's a quadratic increase in the number of parameters as the number of outcomes increases linearly\n\n-   To be used as an analysis model, however, a covariance structure must “fit” as well as the saturated/unstructured covariance matrix\n\n## Biggest Difference From Univariate Models: Model Fit\n\n1.  In univariate linear models the \"model for the variance\" wasn’t much of a model - There was one variance term possible and one term estimated\n    -   A saturated model - all variances/covariances are freely estimated without any constrains - Model fit was always perfect\n2.  In multivariate linear models, because of the number of variances/covariances, oftentimes models are not saturated for the variances\n    -   Therefore, model fit becomes an issue\n3.  Any non-saturated model for the variances must be shown to fit the data before being used for interpretation\n    -   \"fit the data\" has differing standards depending on software type used\n\n## Today's Example Data\n\n-   Data are simulated based on the results reported in:\n\n-   Sample of 350 undergraduates (229 women, 121 men)\n\n    -   In simulation, 10% of variables were missing (using missing completely at random mechanism)\n\n-   Dictionary:\n\n    1.  Prior Experience at High School Level (HSL)\n    2.  Prior Experience at College Level (CC)\n    3.  Perceived Usefulness of Mathematics (USE)\n    4.  Math Self-Concept (MSC)\n    5.  Math Anxiety (MAS)\n    6.  Math Self-Efficacy (MSE)\n    7.  Math Performance (PERF)\n    8.  Female (sex variable: 0 = male; 1 = female)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ESRM64503)\nlibrary(tidyverse)\nlibrary(DescTools)\nhead(dataMath)\ndim(dataMath)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  id hsl cc use msc mas mse perf female\n1  1  NA  9  44  55  39  NA   14      1\n2  2   3  2  77  70  42  71   12      0\n3  3  NA 12  64  52  31  NA   NA      1\n4  4   6 20  71  65  39  84   19      0\n5  5   2 15  48  19   2  60   12      0\n6  6  NA 15  61  62  42  87   18      0\n[1] 350   9\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nDesc(dataMath[,2:8], plotit = FALSE, conf.level = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n────────────────────────────────────────────────────────────────────────────── \nDescribe dataMath[, 2:8] (data.frame):\n\ndata frame:\t350 obs. of  7 variables\n\t\t145 complete cases (41.4%)\n\n  Nr  Class  ColName  NAs         Levels\n  1   int    hsl      36 (10.3%)        \n  2   int    cc       37 (10.6%)        \n  3   int    use      24 (6.9%)         \n  4   int    msc      39 (11.1%)        \n  5   int    mas      46 (13.1%)        \n  6   int    mse      34 (9.7%)         \n  7   int    perf     60 (17.1%)        \n\n\n────────────────────────────────────────────────────────────────────────────── \n1 - hsl (integer)\n\n  length      n    NAs  unique    0s   mean  meanCI'\n     350    314     36       8     0   4.92    4.92\n          89.7%  10.3%          0.0%           4.92\n                                                   \n     .05    .10    .25  median   .75    .90     .95\n    3.00   3.00   4.00    5.00  6.00   6.00    7.00\n                                                   \n   range     sd  vcoef     mad   IQR   skew    kurt\n    7.00   1.32   0.27    1.48  2.00  -0.26   -0.41\n                                                   \n\n   value  freq   perc  cumfreq  cumperc\n1      1     1   0.3%        1     0.3%\n2      2    11   3.5%       12     3.8%\n3      3    34  10.8%       46    14.6%\n4      4    71  22.6%      117    37.3%\n5      5    79  25.2%      196    62.4%\n6      6    88  28.0%      284    90.4%\n7      7    27   8.6%      311    99.0%\n8      8     3   1.0%      314   100.0%\n\n' 0%-CI (classic)\n\n────────────────────────────────────────────────────────────────────────────── \n2 - cc (integer)\n\n  length      n    NAs  unique     0s   mean  meanCI'\n     350    313     37      28     21  10.31   10.31\n          89.4%  10.6%           6.0%          10.31\n                                                    \n     .05    .10    .25  median    .75    .90     .95\n    0.00   2.00   6.00   10.00  14.00  19.00   20.00\n                                                    \n   range     sd  vcoef     mad    IQR   skew    kurt\n   27.00   5.89   0.57    5.93   8.00   0.17   -0.43\n                                                    \nlowest : 0 (21), 1 (5), 2 (9), 3 (9), 4 (12)\nhighest: 23, 24, 25, 26, 27\n\nheap(?): remarkable frequency (8.6%) for the mode(s) (= 10, 13)\n\n' 0%-CI (classic)\n\n────────────────────────────────────────────────────────────────────────────── \n3 - use (integer)\n\n  length      n    NAs  unique     0s   mean  meanCI'\n     350    326     24      71      1  52.50   52.50\n          93.1%   6.9%           0.3%          52.50\n                                                    \n     .05    .10    .25  median    .75    .90     .95\n   25.50  31.00  42.25   52.00  64.00  71.50   77.75\n                                                    \n   range     sd  vcoef     mad    IQR   skew    kurt\n  100.00  15.81   0.30   16.31  21.75  -0.11   -0.08\n                                                    \nlowest : 0, 13, 15, 16, 19 (2)\nhighest: 84 (2), 86, 92, 95, 100\n\n' 0%-CI (classic)\n\n────────────────────────────────────────────────────────────────────────────── \n4 - msc (integer)\n\n  length      n    NAs  unique     0s   mean  meanCI'\n     350    311     39      76      0  49.79   49.79\n          88.9%  11.1%           0.0%          49.79\n                                                    \n     .05    .10    .25  median    .75    .90     .95\n   24.00  29.00  38.00   49.00  61.00  72.00   80.50\n                                                    \n   range     sd  vcoef     mad    IQR   skew    kurt\n   98.00  16.96   0.34   16.31  23.00   0.23   -0.09\n                                                    \nlowest : 5, 9, 12, 15, 16 (2)\nhighest: 87 (3), 89, 91, 94, 103\n\n' 0%-CI (classic)\n\n────────────────────────────────────────────────────────────────────────────── \n5 - mas (integer)\n\n  length      n    NAs  unique     0s   mean  meanCI'\n     350    304     46      57      1  31.50   31.50\n          86.9%  13.1%           0.3%          31.50\n                                                    \n     .05    .10    .25  median    .75    .90     .95\n   13.00  17.00  24.75   32.00  39.00  45.70   50.00\n                                                    \n   range     sd  vcoef     mad    IQR   skew    kurt\n   62.00  11.32   0.36   10.38  14.25  -0.13   -0.17\n                                                    \nlowest : 0, 2, 3 (2), 5, 6\nhighest: 54 (2), 55 (2), 56, 58, 62\n\n' 0%-CI (classic)\n\n────────────────────────────────────────────────────────────────────────────── \n6 - mse (integer)\n\n  length      n    NAs  unique     0s   mean  meanCI'\n     350    316     34      56      0  73.41   73.41\n          90.3%   9.7%           0.0%          73.41\n                                                    \n     .05    .10    .25  median    .75    .90     .95\n   54.00  58.00  65.00   73.00  81.00  88.50   92.25\n                                                    \n   range     sd  vcoef     mad    IQR   skew    kurt\n   60.00  11.89   0.16   11.86  16.00   0.06   -0.26\n                                                    \nlowest : 45 (2), 46, 47, 49 (2), 50 (4)\nhighest: 98, 100, 101 (2), 103, 105 (2)\n\n' 0%-CI (classic)\n\n────────────────────────────────────────────────────────────────────────────── \n7 - perf (integer)\n\n  length      n    NAs  unique     0s   mean  meanCI'\n     350    290     60      19      0  13.97   13.97\n          82.9%  17.1%           0.0%          13.97\n                                                    \n     .05    .10    .25  median    .75    .90     .95\n    9.45  10.00  12.00   14.00  16.00  18.00   19.00\n                                                    \n   range     sd  vcoef     mad    IQR   skew    kurt\n   18.00   2.96   0.21    2.97   4.00   0.16    0.14\n                                                    \nlowest : 5, 6, 7 (2), 8 (3), 9 (8)\nhighest: 19 (10), 20 (4), 21 (3), 22 (2), 23\n\nheap(?): remarkable frequency (13.8%) for the mode(s) (= 13)\n\n' 0%-CI (classic)\n```\n\n\n:::\n:::\n\n\n\n\n## Using MVN Likelihoods in `lavaan`\n\n> [The lavaan package](https://www.lavaan.ugent.be/) is developed by Dr. [Yves Rosseel](https://research.ugent.be/web/person/yves-rosseel-0/en) to provide useRs, researchers and teachers a free open-source, but commercial-quality package for latent variable modeling. You can use lavaan to estimate a large variety of multivariate statistical models, including **path analysis**, **confirmatory factor analysis**, **structural equation modeling** and **growth curve models**.\n\n-   `lavaan`’s default model is a linear (mixed) model that uses ML with the multivariate normal distribution\n\n-   ML is sometimes called a full information method (FIML)\n\n    -   Full information is the term used when each observation gets used in a likelihood function\n    -   The contrast is limited information (not all observations used; typically summary statistics are used)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lavaan)\n```\n:::\n\n\n\n\n## Revisiting Univariate Linear Regression\n\n-   We will begin our discussion by starting with perhaps the simplest model we will see: a univariate empty model\n    -   We will use the PERF variable from our example data: Performance on a mathematics assessment\n-   The empty model for PERF is:\n    -   $e_{i, PERF} \\sim N(0, \\sigma^2_{e,PERF})$\n    -   Two parameters are estimated: [$\\beta_{0,PERF}$ and $\\sigma^2_{e,PERF}$]{.mohu}\n\n$$\n\\text{PERF}_i = \\beta_{0,\\color{tomato}{PERF}} + e_{i, \\color{tomato}{PERF}}\n$$\n\n-   Here, the additional subscript is added to denote these terms are part of the model for the PERF variable\n    -   We will need these when we get to multivariate models and path analysis\n\n## `lavaan` Syntax\n\n-   The `lavaan` package works by taking the typical R model syntax (as from `lm()`) and putting it into a quoted character variable\n    -   `lavaan` model syntax also includes other commands used to access other parts of the model (really, parts of the MVN distribution)\n-   Here:\n    -   `~~` indicate variance or covariance between variables on either side (`perf ~~ perf`) estimates variance\\\n    -   `~1` indicate intercept for one variable (`perf~1`)\n\n\n\n\n::: {.cell output-location='default'}\n\n```{.r .cell-code}\n## Syntax for model01\nmodel01.syntax <- \" #<1>\n## Variances:\nperf ~~ perf\n\n## Means:\nperf ~ 1\n\"\n## Estimation for model01\nmodel01.fit <- cfa(model01.syntax, data=dataMath, mimic=\"MPLUS\", fixed.x = TRUE, estimator = \"MLR\") #<2>\n\n## Print output\nsummary(model01.fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlavaan 0.6-19 ended normally after 8 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         2\n\n                                                  Used       Total\n  Number of observations                           290         350\n  Number of missing patterns                         1            \n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                                 0.000       0.000\n  Degrees of freedom                                 0           0\n\nParameter Estimates:\n\n  Standard errors                             Sandwich\n  Information bread                           Observed\n  Observed information based on                Hessian\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)\n    perf             13.966    0.174   80.397    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n    perf              8.751    0.756   11.581    0.000\n```\n\n\n:::\n:::\n\n\n\n\n1.  model syntax is a string object containing our model specification\n2.  We use the `cfa()` function to run the model based on the syntax\n\n## Model Parameter Estimates and Assumptions\n\n\n\n\n::: {.cell filename='Summary of lavaan\\'s cfa()'}\n\n```{.r .cell-code}\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)\n    perf             13.966    0.174   80.397    0.000\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n    perf              8.751    0.756   11.581    0.000\n```\n:::\n\n::: {.cell filename='Summary of lm()'}\n\n```{.r .cell-code}\nsummary(lm(perf ~ 1, data = dataMath))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = perf ~ 1, data = dataMath)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.9655 -1.9655  0.0345  2.0345  9.0345 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   13.966      0.174   80.26   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.963 on 289 degrees of freedom\n  (60 observations deleted due to missingness)\n```\n\n\n:::\n:::\n\n\n\n\n-   Parameter Estimates:\n    -   $\\beta_{0,PERF} = 13.966$\n    -   $\\sigma^2_{e,PERF} = 8.751$\n-   Using the model estimates, we known that:\n\n$$\n\\text{PERF}_i \\sim N(13.966, 8.751)\n$$\n\n# Multivariate Empty Models\n\n## Adding One More Variable: Multivariate Regression\n\n-   We already know how to use `lavaan` to estimate univariate model, let's move on to model two variables as outcomes\n\n    -   **Mathematics performance (perf)**\n    -   **Perceived Usefulness of Mathematics (use)**\n\n-   Assumption: We will assume these to be continuous variables (conditionally MVN)\n\n-   Initially, we will only look at an empty model with these two variables:\n\n    -   Empty models are baseline models\n    -   We will use these to show how such models look based on the characteristics of the multivariate normal distribution\n    -   We will also show the bigger picture when modeling multivariate data: how we must be sure to model the covariance matrix correctly\n\n## Multivariate Empty Model: The Notation\n\n-   The multivariate model for `perf` and `use` is given by two regression models, which are estimated **simultaneously**:\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}