{
  "hash": "cc4ef06e8e8c9c7e22c268e5cec85e49",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lecture 08: Multivariate Analysis\"\nsubtitle: \"Model Setup and Assumptions\"\nauthor: \"Jihong Zhang*, Ph.D\"\ninstitute: | \n  Educational Statistics and Research Methods (ESRM) Program*\n  \n  University of Arkansas\ndate: \"2024-10-09\"\ndate-modified: \"2024-10-11\"\nsidebar: false\nexecute: \n  echo: true\n  warning: false\noutput-location: column\ncode-annotations: below\nhighlight-style: \"nord\"\nformat: \n  uark-revealjs:\n    scrollable: true\n    chalkboard: true\n    embed-resources: false\n    code-fold: false\n    number-sections: false\n    footer: \"ESRM 64503 - Lecture 08: Multivariate Analysis\"\n    slide-number: c/t\n    tbl-colwidths: auto\n    output-file: slides-index.html\n  html: \n    page-layout: full\n    toc: true\n    toc-depth: 2\n    toc-expand: true\n    lightbox: true\n    code-fold: false\n    fig-align: center\nfilters:\n  - quarto\n  - line-highlight\n---\n\n```{=html}\n<div class=\"card shadow\">\n    <div class=\"ml-3 mt-2\">\n        <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"54\" height=\"14\" viewBox=\"0 0 54 14\">\n            <g fill=\"none\" fill-rule=\"evenodd\" transform=\"translate(1 1)\">\n                <circle cx=\"6\" cy=\"6\" r=\"6\" fill=\"#FF5F56\" stroke=\"#E0443E\" stroke-width=\".5\"></circle>\n                <circle cx=\"26\" cy=\"6\" r=\"6\" fill=\"#FFBD2E\" stroke=\"#DEA123\" stroke-width=\".5\"></circle>\n                <circle cx=\"46\" cy=\"6\" r=\"6\" fill=\"#27C93F\" stroke=\"#1AAB29\" stroke-width=\".5\"></circle>\n            </g>\n        </svg>\n    </div>\n    <div class=\"card-body\">\n        <h5 class=\"card-title\">Today's Class</h5>\n        <ul>\n          <li>Multivariate linear models: an introduction</li>\n          <li>How to form multivariate models in lavaan</li>\n          <li>What parameters mean</li>\n          <li>How they relate to the multivariate normal distribution</li>\n        </ul>\n    </div>\n</div>\n```\n\n::: {.cell output-location='default'}\n\n```{.r .cell-code}\nlibrary(ESRM64503)\nlibrary(kableExtra)\nlibrary(tidyverse)\nlibrary(DescTools) # Desc() allows you to quick screen data\nlibrary(lavaan) # Desc() allows you to quick screen data\nhead(dataMath)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  id hsl cc use msc mas mse perf female\n1  1  NA  9  44  55  39  NA   14      1\n2  2   3  2  77  70  42  71   12      0\n3  3  NA 12  64  52  31  NA   NA      1\n4  4   6 20  71  65  39  84   19      0\n5  5   2 15  48  19   2  60   12      0\n6  6  NA 15  61  62  42  87   18      0\n```\n\n\n:::\n\n```{.r .cell-code}\ndim(dataMath)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 350   9\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## Homework 2\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel04.syntax = \"\n# Variances:\nperf ~~ perf \nuse ~~ use   \nmas ~~ mas\n\n# Covariance:\nperf ~~ use\nperf ~~ mas\nuse ~~ mas\n\n# Means:\nperf ~ 1  \nuse ~ 1   \nmas ~ 1   \n\"\n```\n:::\n\n::: {.cell output-location='default'}\n\n```{.r .cell-code}\n## Estimation for model01\nmodel04.fit <- cfa(model04.syntax, data=dataMath, mimic=\"MPLUS\", fixed.x = TRUE, estimator = \"MLR\") \n\n## Print output\nparameterestimates(model04.fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   lhs op  rhs     est     se      z pvalue ci.lower ci.upper\n1 perf ~~ perf   8.712  0.744 11.706  0.000    7.253   10.171\n2  use ~~  use 249.388 19.238 12.963  0.000  211.682  287.094\n3  mas ~~  mas 127.648  9.895 12.901  0.000  108.255  147.041\n4 perf ~~  use   7.358  2.788  2.639  0.008    1.894   12.822\n5 perf ~~  mas  17.555  2.194  8.002  0.000   13.255   21.855\n6  use ~~  mas  53.390  9.587  5.569  0.000   34.600   72.180\n7 perf ~1       13.929  0.169 82.263  0.000   13.597   14.261\n8  use ~1       52.594  0.875 60.139  0.000   50.880   54.308\n9  mas ~1       31.601  0.634 49.851  0.000   30.358   32.843\n```\n\n\n:::\n\n```{.r .cell-code}\nstandardizedsolution(model04.fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   lhs op  rhs est.std    se      z pvalue ci.lower ci.upper\n1 perf ~~ perf   1.000 0.000     NA     NA    1.000    1.000\n2  use ~~  use   1.000 0.000     NA     NA    1.000    1.000\n3  mas ~~  mas   1.000 0.000     NA     NA    1.000    1.000\n4 perf ~~  use   0.158 0.059  2.685  0.007    0.043    0.273\n5 perf ~~  mas   0.526 0.043 12.372  0.000    0.443    0.610\n6  use ~~  mas   0.299 0.049  6.109  0.000    0.203    0.395\n7 perf ~1        4.719 0.204 23.106  0.000    4.319    5.119\n8  use ~1        3.330 0.143 23.257  0.000    3.050    3.611\n9  mas ~1        2.797 0.126 22.151  0.000    2.550    3.044\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel04b.syntax = \"\n# Variances:\nperf ~~ perf \nuse ~~ use   \nmas ~~ mas\n\n# Covariance:\nperf ~~ use\nperf ~~ mas\nuse ~~ 0*mas\n\n# Means:\nperf ~ 1  \nuse ~ 1   \nmas ~ 1   \n\"\nmodel04b.fit <- cfa(model04b.syntax, data=dataMath, mimic=\"MPLUS\", fixed.x = TRUE, estimator = \"MLR\") \n\n## Print output\nparameterestimates(model04b.fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   lhs op  rhs     est     se      z pvalue ci.lower ci.upper\n1 perf ~~ perf   8.675  0.748 11.593  0.000    7.208   10.141\n2  use ~~  use 249.202 19.211 12.972  0.000  211.550  286.854\n3  mas ~~  mas 127.708  9.916 12.879  0.000  108.272  147.143\n4 perf ~~  use   0.772  2.578  0.299  0.765   -4.281    5.825\n5 perf ~~  mas  17.417  2.232  7.804  0.000   13.043   21.792\n6  use ~~  mas   0.000  0.000     NA     NA    0.000    0.000\n7 perf ~1       13.932  0.169 82.274  0.000   13.601   14.264\n8  use ~1       52.488  0.874 60.033  0.000   50.774   54.201\n9  mas ~1       31.531  0.638 49.421  0.000   30.280   32.781\n```\n\n\n:::\n\n```{.r .cell-code}\nstandardizedsolution(model04b.fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   lhs op  rhs est.std    se      z pvalue ci.lower ci.upper\n1 perf ~~ perf   1.000 0.000     NA     NA    1.000    1.000\n2  use ~~  use   1.000 0.000     NA     NA    1.000    1.000\n3  mas ~~  mas   1.000 0.000     NA     NA    1.000    1.000\n4 perf ~~  use   0.017 0.056  0.298  0.765   -0.092    0.126\n5 perf ~~  mas   0.523 0.044 11.790  0.000    0.436    0.610\n6  use ~~  mas   0.000 0.000     NA     NA    0.000    0.000\n7 perf ~1        4.730 0.206 22.993  0.000    4.327    5.134\n8  use ~1        3.325 0.143 23.212  0.000    3.044    3.606\n9  mas ~1        2.790 0.127 22.056  0.000    2.542    3.038\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(model04.fit, model04b.fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nScaled Chi-Squared Difference Test (method = \"satorra.bentler.2001\")\n\nlavaan->lavTestLRT():  \n   lavaan NOTE: The \"Chisq\" column contains standard test statistics, not the \n   robust test that should be reported per model. A robust difference test is \n   a function of two standard (not robust) statistics.\n             Df    AIC    BIC  Chisq Chisq diff Df diff Pr(>Chisq)    \nmodel04.fit   0 6421.3 6456.0  0.000                                  \nmodel04b.fit  1 6446.5 6477.4 27.234     29.031       1  7.123e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## Wrapping Up\n\n1.  This lecture was an introduction to the estimation of multivariate linear models for multivariate outcomes the using path analysis/SEM package `lavaan`\n\n2.  We saw that the model for continuous data uses the multivariate normal distribution in its likelihood function\n\n### Next Class\n\n1.  Does each model fit the data well (absolute model fit)?\n2.  If not, how can we improve model fit?\n3.  Which model fits better (relative model fit)?\n4.  Answers are given in the following lectures...\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}