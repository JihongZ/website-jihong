{
  "hash": "24fe992534fc15c62b9171dee0164f7f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lecture 05: ANOVA Comparisons\"\nsubtitle: \"Experimental Design in Education\"\nauthor: \"Jihong Zhang*, Ph.D\"\ninstitute: | \n  Educational Statistics and Research Methods (ESRM) Program*\n  \n  University of Arkansas\ndate: \"2025-02-10\"\nsidebar: false\nexecute: \n  eval: true\n  echo: true\nformat: \n  # html: \n  #   page-layout: full\n  #   toc: true\n  #   toc-depth: 2\n  #   lightbox: true\n  uark-revealjs:\n    chalkboard: true\n    embed-resources: false\n    code-fold: false\n    number-sections: true\n    number-depth: 1\n    footer: \"ESRM 64503: Lecture 05\"\n    slide-number: c/t\n    tbl-colwidths: auto\n    scrollable: true\n    mermaid:\n      theme: forest\nfilters:\n  - output-line-highlight.lua\n---\n\n\n\n[Class Outline]{.redcolor .bigger}\n\n-   Go through three assumptions of ANOVA and their checking statistics\n-   Post-hoc test for more group comparisons.\n-   Example: Intervention and Verbal Acquisition\n-   After-class Exercise: Effect of Sleep Duration on Cognitive Performance\n\n# Planned Contrasts and Effect Sizes\n\n## Planned Contrasts\n\n-   Pre-defined:\n\n    -   Unlike post-hoc tests, planned contrasts are determined before looking at the data, meaning the researcher has a specific hypothesis about which groups to compare.\n    -   Definition: Planned contrasts are hypothesis-driven comparisons made before data collection.\n\n-   Weights assigned:\n\n    -   To perform a planned contrast, each group is assigned a numerical \"weight\" which reflects its role in the comparison, with the weights usually summing to zero.\n\n-   Less stringent correction:\n\n    -   Because planned contrasts are based on specific hypotheses, they typically require less stringent multiple comparison corrections compared to post-hoc tests.\n\n## Example of Planned Contrasts\n\n-   Imagine a study comparing the effects of three different study methods (A, B, C) on test scores. A planned contrast might be to compare the average score of method A (considered the \"experimental\" method) against the combined average of methods B and C (considered the \"control\" conditions), testing the hypothesis that method A leads to significantly higher scores than the traditional methods.\n\n-   When to use planned contrasts:\n\n    -   When you have a clear theoretical basis for predicting specific differences between groups in your study.\n    -   When you are only interested in a few specific comparisons, not all possible pairwise comparisons.\n\n## What Does Each Contrast Tell Us?\n\n-   Each contrast is a mean comparison (via t-test).\n-   Simple contrast (pairwise) compares two individual means.\n-   Complex contrast compares a combination of group means.\n-   Must be theoretically justified for meaningful interpretation.\n\n## Simple vs. Complex Comparisons\n\n-   **Simple Comparison:** Two groups directly compared.\n    -   Example: $H_0: \\mu_2 = \\mu_3$\n-   **Complex Comparison:** Combines means of multiple groups.\n    -   Example: $H_0: (\\mu_1 + \\mu_2)/2 = \\mu_3$\n    -   Example: $H_0: (\\mu_1 + \\mu_2 + \\mu_3)/3 = (\\mu_4 + \\mu_5)/2$\n\n## Examples of Complex Comparisons\n\n-   Helmert contrast: Compares each mean to the mean of subsequent groups.\n-   Deviation contrast: Compares each mean to the grand mean.\n-   Polynomial contrast: Tests for trends in ordered data.\n\n## Planned Contrast: Orthogonal vs. Non-Orthogonal Contrasts\n\n-   **Orthogonal Contrasts:** Independent from each other, sum of product of weights equals zero.\n-   **Non-Orthogonal Contrasts:** Not independent, lead to inflated Type I error rates.\n-   Orthogonal contrasts allow clear interpretation without redundancy.\n\n## Orthogonal Planned Contrasts\n\n-   If the same exact combination of means is not found in more than one contrast, the contrasts are independent (orthogonal)\n    -   Check this by ensuring that the product of the weights across all contrasts sum to zero\n-   Why does independence matter?\n    -   Type I error rate is unaffected by independent (orthogonal) contrasts\n    -   Interpretation of contrasts is cleaner because contrasts aren’t related (you’ve isolated effects)\n\n| Group | Contrast 1 | Contrast 2 | Product |\n|-------|------------|------------|---------|\n| G1    | -2         | 0          | 0       |\n| G2    | +1         | +1         | +1      |\n| G3    | +1         | -1         | -1      |\n| Sum   | 0          | 0          | 0       |\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontras <- matrix(\n  c(-2, 1, 1,\n    0, 1, -1), ncol = 2\n)\ncontras\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1] [,2]\n[1,]   -2    0\n[2,]    1    1\n[3,]    1   -1\n```\n\n\n:::\n\n```{.r .cell-code}\ncrossprod(contras) ## if diagnonal matix = orthogonal\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1] [,2]\n[1,]    6    0\n[2,]    0    2\n```\n\n\n:::\n:::\n\n\n\n## Computing Planned Contrasts\n\n-   Formula for contrast value: $C = c_1\\mu_1 + c_2\\mu_2 + \\dots + c_k\\mu_k$\n-   Test statistic: $t = \\frac{C}{\\sqrt{MSE \\sum \\frac{c_i^2}{n_i}}}$\n    -   $MSE$: Mean Square Error from ANOVA\n    -   $c_i$: Contrast coefficients\n    -   $n_i$: Sample size per group\n\n# Example - STEM vs. Non-STEM Groups\n\n## Example data background\n\n-   Hypothesis: STEM students have different growth mindset scores than non-STEM students.\n-   Weights assigned:\n    -   STEM (Engineering, Chemistry): $+\\frac{1}{2}$\n    -   Non-STEM (Education, Political Sci, Psychology): $-\\frac{1}{3}$\n-   Compute contrast value and test using t-statistic.\n\n## Set Contrasts in R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(kableExtra)\n# Set seed for reproducibility\nset.seed(42)\ndt <- read.csv(\"week5_example.csv\")\noptions(digits = 5)\nsummary_tbl <- dt |> \n  group_by(group) |> \n  summarise(\n    N = n(),\n    Mean = mean(score),\n    SD = sd(score)\n  )\nkable(summary_tbl)\n```\n\n::: {.cell-output-display}\n\n\n|group |  N|   Mean|      SD|\n|:-----|--:|------:|-------:|\n|g1    | 28| 4.2500| 3.15054|\n|g2    | 28| 2.7589| 2.19478|\n|g3    | 28| 3.5446| 2.86506|\n|g4    | 28| 3.8568| 0.58325|\n|g5    | 28| 2.0243| 1.30911|\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n### Contrast Matrix\n\n[For example, Helmert Four contrasts:]{.redcolor}\n\n1.  g1 vs. g2: $\\mu_{Engineering} = \\mu_{Education}$\n2.  $\\frac{g1+g2}{2}$ vs. g3: $\\mu_{non-Chemistry} = \\mu_{Chemistry}$\n3.  $\\frac{g1+g2+g3}{3}$ vs. g4: $\\mu_{non-Political} = \\mu_{Political}$\n4.  $\\frac{g1+g2+g3+g4}{4}$ vs. g5: $\\mu_{non-Psychology} = \\mu_{Psychology}$\n\nSummary Statistics:\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndt$group <- factor(dt$group, levels = c(\"g1\", \"g2\", \"g3\", \"g4\", \"g5\"))\ngroups <- levels(dt$group)\ncH <- contr.helmert(groups) # pre-defined four contrasts\ncolnames(cH) <- paste0(\"Ctras\", 1:4)\nsummary_ctras_tbl <- cbind(summary_tbl, cH)\nkable(summary_ctras_tbl)\n```\n\n::: {.cell-output-display}\n\n\n|   |group |  N|   Mean|      SD| Ctras1| Ctras2| Ctras3| Ctras4|\n|:--|:-----|--:|------:|-------:|------:|------:|------:|------:|\n|g1 |g1    | 28| 4.2500| 3.15054|     -1|     -1|     -1|     -1|\n|g2 |g2    | 28| 2.7589| 2.19478|      1|     -1|     -1|     -1|\n|g3 |g3    | 28| 3.5446| 2.86506|      0|      2|     -1|     -1|\n|g4 |g4    | 28| 3.8568| 0.58325|      0|      0|      3|     -1|\n|g5 |g5    | 28| 2.0243| 1.30911|      0|      0|      0|      4|\n\n\n:::\n:::\n\n\n\n[Features of contrast matrix]{.redcolor}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\napply(cH, 2, sum)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCtras1 Ctras2 Ctras3 Ctras4 \n     0      0      0      0 \n```\n\n\n:::\n\n```{.r .cell-code}\ncrossprod(cH) # diagonal -- columns are orthogonal\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       Ctras1 Ctras2 Ctras3 Ctras4\nCtras1      2      0      0      0\nCtras2      0      6      0      0\nCtras3      0      0     12      0\nCtras4      0      0      0     20\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(aov(score ~ group, dt))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             Df Sum Sq Mean Sq F value Pr(>F)   \ngroup         4     89    22.3    4.47  0.002 **\nResiduals   135    675     5.0                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n### t-value formula for defined contrast matrix\n\n$t = \\frac{C}{\\sqrt{MSE \\sum \\frac{c_i^2}{n_i}}}$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSum_C2_n <- colSums(cH^2 / summary_tbl$N)\nC <- crossprod(summary_tbl$Mean, cH)\nMSE <- 5.0\nt <- as.numeric(C / sqrt(MSE * Sum_C2_n))\nt\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -2.495040  0.077632  0.694597 -3.340639\n```\n\n\n:::\n\n```{.r .cell-code}\ntibble(\n  t_value = t,\n  p_value = pt(t, df = 135) ## p-values\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 2\n  t_value  p_value\n    <dbl>    <dbl>\n1 -2.50   0.00690 \n2  0.0776 0.531   \n3  0.695  0.756   \n4 -3.34   0.000541\n```\n\n\n:::\n:::\n\n\n\n-   g1 vs. g2: We reject the null and determine that the mean of the Education is different from the mean of Engineering in their growth mindset scores (p = 0.531).\n\n-   $\\frac{g1+g2}{2}$ vs. g3: We retain the null and determine that the mean of the Chemistry is not significant different from the mean of Education and Engineering in their growth mindset scores (p = 0.531).\n\n------------------------------------------------------------------------\n\n### Helmert Contrast\n\nRemember that Planned Contrast: g1 vs. g2 from Helmert Contrast:\n\n-   t-value: -2.495\n-   p-value: 0.0069\n-   df: 134\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrasts(dt$group) <- \"contr.helmert\"\nfit_helmert <- lm(score ~ group, dt)\ncontr.helmert(levels(dt$group))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   [,1] [,2] [,3] [,4]\ng1   -1   -1   -1   -1\ng2    1   -1   -1   -1\ng3    0    2   -1   -1\ng4    0    0    3   -1\ng5    0    0    0    4\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fit_helmert)$coefficients |> round(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)    3.287      0.189  17.391    0.000\ngroup1        -0.746      0.299  -2.495    0.014\ngroup2         0.013      0.173   0.078    0.938\ngroup3         0.085      0.122   0.695    0.489\ngroup4        -0.316      0.095  -3.340    0.001\n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n### Planned Contrast Connected to Linear Regression\n\n-   Planned contrast can be done using `linear regression` + `contrasts`\n\n-   Let's look at the default contrasts plan: treatment contrasts == dummy coding\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nattributes(C(dt$group, treatment, 4))$contrasts\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   g2 g3 g4 g5\ng1  0  0  0  0\ng2  1  0  0  0\ng3  0  1  0  0\ng4  0  0  1  0\ng5  0  0  0  1\n```\n\n\n:::\n\n```{.r .cell-code}\nattributes(C(dt$group, sum, 4))$contrasts\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   [,1] [,2] [,3] [,4]\ng1    1    0    0    0\ng2    0    1    0    0\ng3    0    0    1    0\ng4    0    0    0    1\ng5   -1   -1   -1   -1\n```\n\n\n:::\n\n```{.r .cell-code}\nattributes(C(dt$group, helmert, 4))$contrasts\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   [,1] [,2] [,3] [,4]\ng1   -1   -1   -1   -1\ng2    1   -1   -1   -1\ng3    0    2   -1   -1\ng4    0    0    3   -1\ng5    0    0    0    4\n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n### Treatment Contrasts\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nlibrary(multcomp)\noptions(contrasts = c(\"contr.treatment\", \"contrasts\"))\nfit <- lm(score ~ group, dt)\nunique(cbind(model.matrix(fit), group = dt$group))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    (Intercept) group1 group2 group3 group4 group\n1             1     -1     -1     -1     -1     1\n29            1      1     -1     -1     -1     2\n57            1      0      2     -1     -1     3\n85            1      0      0      3     -1     4\n113           1      0      0      0      4     5\n```\n\n\n:::\n:::\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = score ~ group, data = dt)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-4.250 -1.500 -0.269  1.214  5.991 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   3.2869     0.1890   17.39   <2e-16 ***\ngroup1       -0.7455     0.2988   -2.49   0.0138 *  \ngroup2        0.0134     0.1725    0.08   0.9382    \ngroup3        0.0847     0.1220    0.69   0.4885    \ngroup4       -0.3157     0.0945   -3.34   0.0011 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.24 on 135 degrees of freedom\nMultiple R-squared:  0.117,\tAdjusted R-squared:  0.0907 \nF-statistic: 4.47 on 4 and 135 DF,  p-value: 0.00202\n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n### Sum Contrasts\n\n-   Another type of coding is **effect coding**. In R, the corresponding contrast type are the so-called **sum contrasts**.\n\n-   A detailed post about sum contrasts can be found [here](https://learnb4ss.github.io/learnB4SS/articles/contrasts.html)\n\n-   With sum contrasts the reference level is in fact the grand mean.\n\n    -   $\\frac{g1+g2+g3+g4+g5}{5}$ vs. g1/g2/g3/g4: the difference between mean score of g1 with grand mean across all five groups\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\ncontrasts(dt$group) <- \"contr.sum\"\nfit2 <- lm(score ~ group, dt)\ncontr.sum(levels(dt$group))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   [,1] [,2] [,3] [,4]\ng1    1    0    0    0\ng2    0    1    0    0\ng3    0    0    1    0\ng4    0    0    0    1\ng5   -1   -1   -1   -1\n```\n\n\n:::\n:::\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nsummary(fit2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = score ~ group, data = dt)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-4.250 -1.500 -0.269  1.214  5.991 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    3.287      0.189   17.39   <2e-16 ***\ngroup1         0.963      0.378    2.55    0.012 *  \ngroup2        -0.528      0.378   -1.40    0.165    \ngroup3         0.258      0.378    0.68    0.497    \ngroup4         0.570      0.378    1.51    0.134    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.24 on 135 degrees of freedom\nMultiple R-squared:  0.117,\tAdjusted R-squared:  0.0907 \nF-statistic: 4.47 on 4 and 135 DF,  p-value: 0.00202\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(dt$score)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.2869\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary_tbl$Mean[1:4] - mean(dt$score)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  0.96307 -0.52800  0.25771  0.56986\n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n## Self-defined Contrast\n\n-   Extended Example 2 : Assume now that I think the average of the STEM groups is different than the average of the non-STEM groups\n\n### Method 1: Calculation by Hand\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n  group  N   Mean      SD Contrasts\n1    g1 28 4.2500 3.15054   0.50000\n2    g2 28 2.7589 2.19478  -0.33333\n3    g3 28 3.5446 2.86506   0.50000\n4    g4 28 3.8568 0.58325  -0.33333\n5    g5 28 2.0243 1.30911  -0.33333\n```\n\n\n:::\n:::\n\n\n\n$$\nH_0: \\frac{\\mu_{Engineering}+\\mu_{Chemistry}}{2} = \\frac{\\mu_{Education}+\\mu_{PoliSci}+\\mu_{Psychology}}{3}\n$$\n\nweighted mean difference:\n\n$$\nC = c_1\\mu_{Eng}+c_2\\mu_{Edu}+c_3\\mu_{Chem}+c_4\\mu_{PoliSci}+c_5\\mu_{Psych}\\\\\n= \\frac{1}{2}*4.25+(-\\frac13)*2.75+(\\frac12)*3.54+(-\\frac13)*3.85+(-\\frac13)*2.02\\\\\n= 1.0173\n$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(C <- sum(summary_tbl_ext$Contrasts*summary_tbl_ext$Mean))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.0173\n```\n\n\n:::\n:::\n\n\n\n$$\n\\sum\\frac{c^2}{n} = \\frac{(\\frac12)^2}{28}+\\frac{(-\\frac13)^2}{28}+\\frac{(\\frac12)^2}{28}+\\frac{(-\\frac13)^2}{28}+\\frac{(-\\frac13)^2}{28}\n$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(Sum_C2_n <- sum(summary_tbl_ext$Contrasts^2 / summary_tbl$N))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.029762\n```\n\n\n:::\n\n```{.r .cell-code}\n(MSE = sum((residuals(aov(score ~ group, dt)))^2) / (nrow(dt) - 5))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5.0011\n```\n\n\n:::\n\n```{.r .cell-code}\n(t = as.numeric(C / sqrt(MSE * Sum_C2_n)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.6369\n```\n\n\n:::\n:::\n\n\n\n$$\nt = \\frac{C}{\\sqrt{MSE*\\sum\\frac{c^2}{n} }} = \\frac{1.0173}{\\sqrt{5.0011*0.029762}}=2.6368\n$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npt(t, df = 135, lower.tail = FALSE) * 2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.0093476\n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n### Method 2: Linear Regression Contrasts by R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# set first contrast\ncontrasts(dt$group) <- matrix(\n  c(1/2, -1/3, 1/2, -1/3, -1/3)\n)\nfit_extended <- lm(score ~ group, dt)\nunique(model.matrix(fit_extended))[, 1:2]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    (Intercept)   group1\n1             1  0.50000\n29            1 -0.33333\n57            1  0.50000\n85            1 -0.33333\n113           1 -0.33333\n```\n\n\n:::\n:::\n\n::: {.cell output-line-numbers='3'}\n\n```{.r .cell-code}\nsummary(fit_extended)$coefficient |> round(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n``` highlight\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)    3.287      0.189  17.391    0.000\ngroup1         1.221      0.463   2.637    0.009\ngroup2        -0.518      0.423  -1.227    0.222\ngroup3         0.948      0.423   2.243    0.027\ngroup4        -0.885      0.423  -2.093    0.038\n```\n\n\n:::\n:::\n\n\n\n# Effect Sizes\n\n## Effect Sizes\n\n-   Effect size measures the magnitude of an effect beyond statistical significance.\n-   Provides context for interpreting practical significance.\n-   Common measures: Eta squared ($\\eta^2$), Omega squared ($\\omega^2$), Cohen’s d.\n\n## Eta Squared ($\\eta^2$)\n\n-   Proportion of total variance explained by the independent variable.\n-   Formula: $\\eta^2 = \\frac{SS_{Model}}{SS_{Total}}$\n-   Interpretation:\n    -   Small: 0.01, Medium: 0.06, Large: 0.14\n\n## Omega Squared ($\\omega^2$)\n\n-   Unbiased estimate of effect size, preferred for small samples.\n-   Formula: $\\omega^2 = \\frac{SS_{Model} - df_{Model} \\cdot MSE}{SS_{Total} + MSE}$\n-   Interpretation follows $\\eta^2$ scale but slightly smaller values.\n\n## Effect Size for Planned Contrasts\n\n-   Correlation-based effect size: $r = \\sqrt{\\frac{t^2}{t^2 + df}}$\n-   Example: For $t = 2.49, df = 135$: $r = \\sqrt{\\frac{2.49^2}{2.49^2 + 135}} = 0.21$\n    -   Small to moderate effect.\n\n## Cohen’s d and Hedges’ g\n\n-   Used for simple mean comparisons.\n-   Cohen’s d formula: $d = \\frac{M_1 - M_2}{SD_{pooled}}$\n-   Hedges’ g corrects for small sample bias.\n-   Guidelines:\n    -   Small: 0.2, Medium: 0.5, Large: 0.8\n\n## Summary\n\n-   Planned contrasts allow hypothesis-driven mean comparisons.\n-   Orthogonal contrasts maintain Type I error control.\n-   Effect sizes help interpret the importance of results.\n-   Combining planned contrasts with effect size measures enhances statistical analysis.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}