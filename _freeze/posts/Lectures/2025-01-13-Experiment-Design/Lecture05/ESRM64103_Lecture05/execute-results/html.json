{
  "hash": "441995faa1ab21e4f06b5f5eae6d0c02",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lecture 05: ANOVA Comparisons and Contrasts\"\nsubtitle: \"Experimental Design in Education\"\nauthor: \"Jihong Zhang*, Ph.D\"\ninstitute: | \n  Educational Statistics and Research Methods (ESRM) Program*\n  \n  University of Arkansas\ndate: \"2025-02-10\"\nsidebar: false\nexecute: \n  eval: true\n  echo: true\nformat: \n  # html: \n  #   page-layout: full\n  #   toc: true\n  #   toc-depth: 2\n  #   lightbox: true\n  uark-revealjs:\n    chalkboard: true\n    embed-resources: false\n    code-fold: false\n    number-sections: true\n    number-depth: 1\n    footer: \"ESRM 64503: Lecture 05\"\n    slide-number: c/t\n    tbl-colwidths: auto\n    scrollable: true\n    mermaid:\n      theme: forest\nfilters:\n  - output-line-highlight.lua\n---\n\n\n\n[Class Outline]{.redcolor .bigger}\n\n-   Planned Contrast\n-   Example: Group Comparison - STEM vs. Non-STEM Groups\n    -   ANOVA-style t-statistics and Regression-style Coding Schema in R\n-   Effect sizes.\n\n# Planned Contrasts\n\n## Definition: Planned Contrasts\n\n-   Pre-defined:\n\n    -   Unlike post-hoc tests, planned contrasts are determined **before** looking at the data, meaning the researcher has a specific [hypothesis about which groups to compare]{.underline .bigger}.\n    -   **Definition**: Planned contrasts are hypothesis-driven comparisons made before data collection.\n\n-   Weights assigned:\n\n    -   To perform a planned contrast, each group is assigned a numerical \"weight\" which reflects its role in the comparison, with the [weights usually summing to zero]{.underline}.\n    \n    $$\n    \\text{unscaled_group_differences} = weights * means\n    $$\n\n## Example of Planned Contrasts\n\n-   **Imagine** a study comparing the effects of three different study methods (**A, B, C**) on test scores.\n\n    -   One planned contrast might be to compare the average score of method A (considered the \"experimental\" method) against the combined average of methods B and C (considered the \"control\" conditions),\n\n    -   Testing the hypothesis that method A leads to significantly higher scores than the traditional methods.\n\n    -   $H_0: \\mu_{A} = \\frac{\\mu_B+\\mu_C}{2}$, we also call this **complex contrast**\n\n-   **When** to use planned contrasts:\n\n    -   When you have a clear theoretical basis for predicting specific differences between groups in your study.\n    -   When you are only interested in a few specific comparisons, not all possible pairwise comparisons.\n\n## What Does Each Contrast Tell Us?\n\n-   Each contrast is a mean comparison (via t-test).\n-   **Simple** contrast (pairwise) compares two individual group means.\n-   **Complex** contrast compares a combination of group means.\n-   Must be theoretically justified for meaningful interpretation.\n\n## Simple vs. Complex Comparisons\n\n-   **Simple Comparison:** Two groups directly compared.\n    -   Example: $H_0: \\mu_2 = \\mu_3$\n-   **Complex Comparison:** Combines means of multiple groups.\n    -   Example: $H_0: \\frac{(\\mu_1 + \\mu_2)}{2} = \\mu_3$\n    -   Example: $H_0: \\frac{(\\mu_1 + \\mu_2 + \\mu_3)}{3} = \\frac{(\\mu_4 + \\mu_5)}{2}$\n    \n::: callout-note\nWe should not test all possible combinations of groups. Instead, justify your comparison plan before performing statistic analysis. \n:::\n\n## Today's focus: Complex Comparisons\n\n-   We perform ominous test in last lecture, which gives us simple contrasts\n    -  which provides all pairwise group comparisons (simple contrasts) \n-   Today we focus more on **complex contrasts**.\n    -   **Helmert** contrast: Compares each mean to the mean of subsequent groups.\n    -   **Sum (Deviation)** contrast: each group compared to grand mean\n    -   **Polynomial** contrast: Tests for trends in ordered data.\n-   By default, R uses **Treatment** contrasts: each group compared to the reference group\n    -   Question: is \"Treatment constrast\" simple or complex constrast\n    -   G1 vs. Treatment (reference)\n    -   G2 vs. Treatment (reference)\n    -   ....\n\n## Orthogonal vs. Non-Orthogonal Contrasts\n\n-   **Orthogonal Contrasts:** Independent from each other, sum of product of weights equals zero.\n\n-   **Non-Orthogonal Contrasts:** Not independent, lead to inflated Type I error rates.\n\n    ::: callout-note\n    Orthogonal contrasts allow clear interpretation without **redundancy**.\n    :::\n\n-   Orthogonal contrasts follows a series of group comparisons that does not overlap variances.\n\n## Orthogonal contrasts from variances: no redundency \n\n[Hermert contrast for example]{.redcolor}\n\n-   With a logical control group, a good first contrast compares all treatment groups to the one control group.\n-   To get each level of IV alone you should have one less contrast than your number of IV levels (3 levels = 2 contrasts)\n-   Once an IV level appears by itself, it shouldn’t reappear in subsequent contrasts\n\n\n\n```{dot}\n//| echo: FALSE\n//| fig-width: 15\ndigraph VarianceDiagram {\n    rankdir=LR;\n    \n    A [label=\"Total Variance Explained\", shape=box, style=filled, fillcolor=tomato, fontcolor=blue, fontsize=20, width=2.5, height=1.5];\n    B [label=\"Variance for G1 and G2\", shape=box, style=filled, fillcolor=lightgrey, fontcolor=red, fontsize=16, width=2.0, height=1];\n    C [label=\"Variance for G1\", shape=box, style=filled, fillcolor=lightblue, fontcolor=red];\n    D [label=\"Variance for G2\", shape=box, style=filled, fillcolor=lightblue, fontcolor=red];\n    E [label=\"Variance for G3\", shape=box, style=filled, fillcolor=lightgrey, fontcolor=red];\n\n    A -> B;\n    B -> C;\n    B -> D;\n    A -> E;\n}\n```\n\n\n\n## Example of Orthogonal Contrasts\n\n:::: columns\n\n::: {.column width=\"50%\"}\n\n-   Contrast 1: g3 vs. (g1, g2)\n![](image/g3vsg12.jpg){width=\"90%\"}\n:::\n\n::: {.column width=\"50%\"}\n\n-   Contrast 2: g1 vs. g2\n![](image/g1vsg2.jpg){width=\"90%\"}\n:::\n::::\n\n## Orthogonal Planned Contrasts\n\n-   If the same exact combination of means is not found in more than one contrast, the contrasts are independent (orthogonal)\n    -   Check this by ensuring that the product of the weights across all contrasts sum to zero\n-   For a orthogonal comparison, **contrasts are independent with each other:**\n    -   We weight the means included on each side of the contrast\n    -   Each contrast has a sum of weights as 0\n    -   Groups not in the contrast get a weight of 0\n-   Why does independence matter?\n    -   [Type I error rate is unaffected by independent (orthogonal) contrasts]{.underline}\n    -   Interpretation of contrasts is cleaner because contrasts aren’t related (you’ve isolated effects)\n\n| Group | Contrast 1 | Contrast 2 | Product |\n|-------|------------|------------|---------|\n| G1    | +1         | -1         | -1      |\n| G2    | +1         | +1         | +1      |\n| G3    | -2         | 0          | 0       |\n| Sum   | 0          | 0          | 0       |\n\n## Contrasts' Independence checking in R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontras <- matrix(\n  c(1, 1, -2,\n    -1, 1, 0), ncol = 2\n)\ncontras\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1] [,2]\n[1,]    1   -1\n[2,]    1    1\n[3,]   -2    0\n```\n\n\n:::\n\n```{.r .cell-code}\nt(contras[,1]) %*% contras[,2] ## the cross-product of two constrasts should be zero\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1]\n[1,]    0\n```\n\n\n:::\n\n```{.r .cell-code}\ncrossprod(contras) ## if non-diagnonal elements are zero = orthogonal\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1] [,2]\n[1,]    6    0\n[2,]    0    2\n```\n\n\n:::\n\n```{.r .cell-code}\ncor(contras) ## or correlation matrix is identity matrix\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1] [,2]\n[1,]    1    0\n[2,]    0    1\n```\n\n\n:::\n:::\n\n\n\n## Computing Planned Contrasts\n\n-   Formula for contrast value: $C = c_1\\mu_1 + c_2\\mu_2 + \\dots + c_k\\mu_k$\n-   Test statistic: $t = \\frac{C}{\\sqrt{MSE \\sum \\frac{c_i^2}{n_i}}}$\n    -   $MSE$: Mean Square Error from ANOVA\n    -   $c_i$: Contrast coefficients\n    -   $n_i$: Sample size per group\n\n# Example - STEM vs. Non-STEM Groups\n\n## Background\n\n-   Hypothesis: STEM students have different **growth mindset scores**(score) than non-STEM students.\n-   Weights assigned:\n    -   STEM (Engineering, Chemistry): $+\\frac{1}{2}$\n    -   Non-STEM (Education, Political Sci, Psychology): $-\\frac{1}{3}$\n-   Compute contrast value and test using t-statistic.\n\n## Set Contrasts in R\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(tidyverse)\nlibrary(kableExtra)\nlibrary(here)\n# Set seed for reproducibility\nset.seed(42)\ndt <- read.csv(here(\"posts/Lectures/2025-01-13-Experiment-Design/Lecture05\",\"week5_example.csv\"))\noptions(digits = 5)\nsummary_tbl <- dt |> \n  group_by(group) |> \n  summarise(\n    N = n(),\n    Mean = mean(score),\n    SD = sd(score),\n    shapiro.test.p.values = shapiro.test(score)$p.value\n  )\nkable(summary_tbl)\n```\n\n::: {.cell-output-display}\n\n\n|group |  N|   Mean|      SD| shapiro.test.p.values|\n|:-----|--:|------:|-------:|---------------------:|\n|g1    | 28| 4.2500| 3.15054|               0.07759|\n|g2    | 28| 2.7589| 2.19478|               0.07605|\n|g3    | 28| 3.5446| 2.86506|               0.00623|\n|g4    | 28| 3.8568| 0.58325|               0.03023|\n|g5    | 28| 2.0243| 1.30911|               0.06147|\n\n\n:::\n:::\n\n\n\n- HOV Assumption: Levene's Test\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naov_fit <- aov(score ~ group, data = dt)\ncar::leveneTest(aov_fit) |> as.data.frame() |> kable()\n```\n\n::: {.cell-output-display}\n\n\n|      |  Df| F value| Pr(>F)|\n|:-----|---:|-------:|------:|\n|group |   4|  12.966|      0|\n|      | 135|      NA|     NA|\n\n\n:::\n:::\n\n\n\nEven though assumption checkings did not pass using original categorical levels, we may be still interested in different group contrasts.\n\n------------------------------------------------------------------------\n\n### Complex Contrast Matrix\n\n- There are multiple \"canned\" contrasts: Helmert, Sum (Effective Coding), Treatment\n\n[For example, Helmert Four contrasts:]{.redcolor}\n\n1.  g1 vs. g2: $\\mu_{Engineering} = \\mu_{Education}$\n2.  $\\frac{g1+g2}{2}$ vs. g3: $\\mu_{non-Chemistry} = \\mu_{Chemistry}$\n3.  $\\frac{g1+g2+g3}{3}$ vs. g4: $\\mu_{non-Political} = \\mu_{Political}$\n4.  $\\frac{g1+g2+g3+g4}{4}$ vs. g5: $\\mu_{non-Psychology} = \\mu_{Psychology}$\n\nSummary Statistics:\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndt$group <- factor(dt$group, levels = c(\"g1\", \"g2\", \"g3\", \"g4\", \"g5\"))\ngroups <- levels(dt$group)\ncH <- contr.helmert(groups) # pre-defined four contrasts\ncolnames(cH) <- paste0(\"Ctras\", 1:4)\nsummary_ctras_tbl <- cbind(summary_tbl, cH)\nkable(summary_ctras_tbl)\n```\n\n::: {.cell-output-display}\n\n\n|   |group |  N|   Mean|      SD| shapiro.test.p.values| Ctras1| Ctras2| Ctras3| Ctras4|\n|:--|:-----|--:|------:|-------:|---------------------:|------:|------:|------:|------:|\n|g1 |g1    | 28| 4.2500| 3.15054|               0.07759|     -1|     -1|     -1|     -1|\n|g2 |g2    | 28| 2.7589| 2.19478|               0.07605|      1|     -1|     -1|     -1|\n|g3 |g3    | 28| 3.5446| 2.86506|               0.00623|      0|      2|     -1|     -1|\n|g4 |g4    | 28| 3.8568| 0.58325|               0.03023|      0|      0|      3|     -1|\n|g5 |g5    | 28| 2.0243| 1.30911|               0.06147|      0|      0|      0|      4|\n\n\n:::\n:::\n\n\n\n---\n\n[Orthogonal contrast matrix]{.redcolor}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\napply(cH, 2, sum)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCtras1 Ctras2 Ctras3 Ctras4 \n     0      0      0      0 \n```\n\n\n:::\n\n```{.r .cell-code}\ncrossprod(cH) # diagonal -- columns are orthogonal\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       Ctras1 Ctras2 Ctras3 Ctras4\nCtras1      2      0      0      0\nCtras2      0      6      0      0\nCtras3      0      0     12      0\nCtras4      0      0      0     20\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(aov(score ~ group, dt))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             Df Sum Sq Mean Sq F value Pr(>F)   \ngroup         4     89    22.3    4.47  0.002 **\nResiduals   135    675     5.0                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n## Planed Contrasts and Coding Schema\n\n- The relationship between planned contrasts in ANOVA and coding in regression lies in how categorical variables are represented and interpreted in statistical models.\n\n- Both approaches aim to test specific hypotheses about group differences, but their implementation varies based on the framework\n  - ANOVA focuses on partitioning variance, \n  - while regression interprets categorical predictors through coding schemes.\n\n------------------------------------------------------------------------\n\n## Effect Coding (Deviation Coding)\n\n- In modern statistics, Regression-style coding is statistically equivalent as ANOVA-style contrast matrix. \n  - Equivalent to ANOVA-style contrasts. ([we will use this in R to reproduce ANOVA-style contrast matrix]{.redcolor})\n- Compares each level to the grand mean.\n\n::: callout-note\nEffect coding is a method of encoding categorical variables in regression models, similar to dummy coding, but with a different interpretation of the resulting coefficients. It is particularly useful when researchers want to compare each level of a categorical variable to the overall mean rather than to a specific reference category.\n:::\n\n---\n\n### **1. Definition and Representation**\nIn effect coding, categorical variables are transformed into numerical variables, typically using values of -1, 0, and 1. The key difference from dummy coding is that the reference category is represented by -1 instead of 0, and the coefficients indicate deviations from the grand mean.\n\nFor a categorical variable with `k` levels, effect coding requires `k-1` coded variables. If we have a categorical variable X with three levels: $A, B, C$, the effect coding scheme could be:\n\n| Category | $X_1$ | $X_2$ |\n|----------|--------|--------|\n| A        | 1      | 0      |\n| B        | 0      | 1      |\n| C (reference) | -1     | -1     |\n\nThe last category ($C$) is the reference group, coded as -1 for all indicator variables.\n\n---\n\n### **2. Interpretation of Coefficients**\n\n:::: columns\n::: {.column width=\"40%\"}\nWhen effect coding is used in a regression model:\n\n$$\nY = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\epsilon\n$$\n\n- $X_1$ and $X_2$ are coded varaibles. They have no much meaning, but their coefficients are **important** \n- $\\beta_0$ represents the **grand mean** of $Y$ across all categories.\n- $\\beta_1$ and $\\beta_2$ represent the **deviation** of categories $A$ and $B$ from the grand mean.\n- The reference group ($C$) does not have a separate coefficient; instead, its deviation can be inferred as $-(\\beta_1 + \\beta_2)$.\n\n:::\n\n::: {.column width=\"60%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(ggplot2)\n# Create a data frame for text labels\ntext_data <- data.frame(\n  x = rep(0.25, 3),  # Repeating the same x-coordinate\n  y = c(0.3, 0.7, 0.9),  # Different y-coordinates\n  label = c(\"C: beta[0] - beta[1] - beta[2]\", \n            \"A: beta[0] + 1*'×'*beta[1] + 0*'×'*beta[2]\", \n            \"B: beta[0] + 0*'×'*beta[1] + 1*'×'*beta[2]\")  # Labels\n)\n\n# Create an empty ggplot with defined limits\nggplot() +\n  geom_text(data = text_data, aes(x = x, y = y, label = label), parse = TRUE, size = 11) +\n  # Add a vertical line at x = 0.5\n  # geom_vline(xintercept = 0.5, color = \"blue\", linetype = \"dashed\", linewidth = 1) +\n  # Add two horizontal lines at y = 0.3 and y = 0.7\n  geom_hline(yintercept = c(0.35, 0.75, 0.95), color = \"red\", linetype = \"solid\", linewidth = 1) +\n  geom_hline(yintercept = 0.5, color = \"grey\", linetype = \"solid\", linewidth = 1) +\n  geom_text(aes(x = .25, y = .45, label = \"grand mean of Y\"), color = \"grey\", size = 11) +\n  # Set axis limits\n  xlim(0, 1) + ylim(0, 1) +\n  labs(y = \"Y\", x = \"\") +\n  # Theme adjustments\n  theme_minimal() +\n  theme(text = element_text(size = 20))\n```\n\n::: {.cell-output-display}\n![](ESRM64103_Lecture05_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\n:::\n::::\n\n\n\n---\n\n### **3. Comparison to Dummy Coding**\n\n- **Dummy Coding**: Compares each category to a **specific reference category** (e.g., comparing A and B to C).\n\n| Category | $X_1$ | $X_2$ |\n|----------|--------|--------|\n| A        | 1      | 0      |\n| B        | 0      | 1      |\n| C (reference) | 0     | 0     |\n\n- **Effect Coding**: Compares each category to the **grand mean** rather than a single reference category.\n\n---\n\n### **4. Use Cases**\n\nEffect coding is beneficial when:\n\n- There is no natural baseline category, and comparisons to the **overall mean** are more meaningful.\n- Researchers want to maintain **sum-to-zero constraints** for categorical variables in linear models.\n- In ANOVA-style analyses, where main effects and interaction effects are tested under an equal-weight assumption.\n\n---\n\n### **5. Implementation in R**\nEffect coding can be set in R using the `contr.sum` function:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nX <- factor(c(\"A\", \"B\", \"C\"))\ncontrasts(X) <- contr.sum(3) # set up effect coding in R\nmodel <- lm(Y ~ X, data = mydata) # use linear regression to mimic ANOVA-style results\nsummary(model)\n```\n:::\n\n\n\n\n------------------------------------------------------------------------\n\n## ANOVA: t-value formula for Defined Contrast Matrix\n\n$t = \\frac{C}{\\sqrt{MSE \\sum \\frac{c_i^2}{n_i}}}$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSum_C2_n <- colSums(cH^2 / summary_tbl$N)\nC <- crossprod(summary_tbl$Mean, cH)\nMSE <- 5.0\nt <- as.numeric(C / sqrt(MSE * Sum_C2_n))\nt\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -2.495040  0.077632  0.694597 -3.340639\n```\n\n\n:::\n\n```{.r .cell-code}\ntibble(\n  t_value = t,\n  p_value = pt(t, df = 135) ## p-values\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 2\n  t_value  p_value\n    <dbl>    <dbl>\n1 -2.50   0.00690 \n2  0.0776 0.531   \n3  0.695  0.756   \n4 -3.34   0.000541\n```\n\n\n:::\n:::\n\n\n\n-   g1 vs. g2: We reject the null and determine that the mean of the Education is different from the mean of Engineering in their growth mindset scores (p = 0.531).\n\n-   $\\frac{g1+g2}{2}$ vs. g3: We retain the null and determine that the mean of the Chemistry is not significant different from the mean of Education and Engineering in their growth mindset scores (p = 0.531).\n\n------------------------------------------------------------------------\n\n### Helmert Contrast\n\nRemember that Planned Contrast: g1 vs. g2 from Helmert Contrast:\n\n-   t-value: -2.495\n-   p-value: 0.0069\n-   df: 134\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrasts(dt$group) <- \"contr.helmert\"\nfit_helmert <- lm(score ~ group, dt)\ncontr.helmert(levels(dt$group))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   [,1] [,2] [,3] [,4]\ng1   -1   -1   -1   -1\ng2    1   -1   -1   -1\ng3    0    2   -1   -1\ng4    0    0    3   -1\ng5    0    0    0    4\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fit_helmert)$coefficients |> round(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)    3.287      0.189  17.391    0.000\ngroup1        -0.746      0.299  -2.495    0.014\ngroup2         0.013      0.173   0.078    0.938\ngroup3         0.085      0.122   0.695    0.489\ngroup4        -0.316      0.095  -3.340    0.001\n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n### Planned Contrast Connected to Linear Regression\n\n-   Planned contrast can be done using `linear regression` + `contrasts`\n\n-   Let's look at the default contrasts plan: treatment contrasts == dummy coding\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\n## treatment contrast matrix \nattributes(C(dt$group, treatment, 4))$contrasts\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   g2 g3 g4 g5\ng1  0  0  0  0\ng2  1  0  0  0\ng3  0  1  0  0\ng4  0  0  1  0\ng5  0  0  0  1\n```\n\n\n:::\n:::\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\n## sum contrast matrix \nattributes(C(dt$group, sum, 4))$contrasts\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   [,1] [,2] [,3] [,4]\ng1    1    0    0    0\ng2    0    1    0    0\ng3    0    0    1    0\ng4    0    0    0    1\ng5   -1   -1   -1   -1\n```\n\n\n:::\n:::\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nattributes(C(dt$group, helmert, 4))$contrasts\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   [,1] [,2] [,3] [,4]\ng1   -1   -1   -1   -1\ng2    1   -1   -1   -1\ng3    0    2   -1   -1\ng4    0    0    3   -1\ng5    0    0    0    4\n```\n\n\n:::\n:::\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\ncrossprod(attributes(C(dt$group, treatment, 4))$contrasts)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   g2 g3 g4 g5\ng2  1  0  0  0\ng3  0  1  0  0\ng4  0  0  1  0\ng5  0  0  0  1\n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n### Treatment Contrasts\n\n::::: columns\n::: {.column width=\"50%}\n- For treatment contrasts, four dummy variables are created to compared:\n\n  - G1 (ref) vs. G2\n  - G1 (ref) vs. G3\n  - G1 (ref) vs. G4\n  - G1 (ref) vs. G5\n:::\n\n::: {.column width=\"50%}\n- `Intercept`: G1's mean\n- `group2`: G2 vs. G1\n- `group3`: G3 vs. G1\n- `group4`: G4 vs. G1\n- `group5`: G5 vs. G1\n:::  \n::::: \n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nlibrary(multcomp)\ncontrasts(dt$group) <- \"contr.treatment\"\nfit <- lm(score ~ group, dt)\nunique(cbind(model.matrix(fit), group = dt$group))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    (Intercept) groupg2 groupg3 groupg4 groupg5 group\n1             1       0       0       0       0     1\n29            1       1       0       0       0     2\n57            1       0       1       0       0     3\n85            1       0       0       1       0     4\n113           1       0       0       0       1     5\n```\n\n\n:::\n:::\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nsummary(fit)$coefficients\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Estimate Std. Error t value   Pr(>|t|)\n(Intercept)  4.25000    0.42262 10.0562 4.2275e-18\ngroupg2     -1.49107    0.59768 -2.4948 1.3810e-02\ngroupg3     -0.70536    0.59768 -1.1802 2.4001e-01\ngroupg4     -0.39321    0.59768 -0.6579 5.1172e-01\ngroupg5     -2.22571    0.59768 -3.7239 2.8718e-04\n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n### Sum Contrasts\n\n-   Another type of coding is **effect coding**. In R, the corresponding contrast type are the so-called **sum contrasts**.\n\n-   A detailed post about sum contrasts can be found [here](https://learnb4ss.github.io/learnB4SS/articles/contrasts.html)\n\n-   With sum contrasts the reference level is in fact the grand mean.\n\n    -   $\\frac{g1+g2+g3+g4+g5}{5}$ vs. g1/g2/g3/g4: the difference between mean score of g1 with grand mean across all five groups\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\ncontrasts(dt$group) <- \"contr.sum\"\nfit2 <- lm(score ~ group, dt)\ncontr.sum(levels(dt$group))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   [,1] [,2] [,3] [,4]\ng1    1    0    0    0\ng2    0    1    0    0\ng3    0    0    1    0\ng4    0    0    0    1\ng5   -1   -1   -1   -1\n```\n\n\n:::\n:::\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nsummary(fit2)$coefficients\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Estimate Std. Error  t value   Pr(>|t|)\n(Intercept)  3.28693    0.18900 17.39087 2.8188e-36\ngroup1       0.96307    0.37801  2.54777 1.1962e-02\ngroup2      -0.52800    0.37801 -1.39680 1.6476e-01\ngroup3       0.25771    0.37801  0.68177 4.9655e-01\ngroup4       0.56986    0.37801  1.50753 1.3401e-01\n```\n\n\n:::\n:::\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nmean(dt$score) # (Intercept) grand mean\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.2869\n```\n\n\n:::\n:::\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\ntibble(\n  Label = paste0(\"group\", 1:4),\n  Estimate = summary_tbl$Mean[1:4] - mean(dt$score) \n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 2\n  Label  Estimate\n  <chr>     <dbl>\n1 group1    0.963\n2 group2   -0.528\n3 group3    0.258\n4 group4    0.570\n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n## Self-defined Contrast\n\n-   Extended Example 2 : Assume now that I think the average of the STEM groups is different than the average of the non-STEM groups\n\n### Method 1: Calculation by Hand\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n  group  N   Mean      SD shapiro.test.p.values Contrasts\n1    g1 28 4.2500 3.15054             0.0775874   0.50000\n2    g2 28 2.7589 2.19478             0.0760542  -0.33333\n3    g3 28 3.5446 2.86506             0.0062253   0.50000\n4    g4 28 3.8568 0.58325             0.0302312  -0.33333\n5    g5 28 2.0243 1.30911             0.0614743  -0.33333\n```\n\n\n:::\n:::\n\n\n\n$$\nH_0: \\frac{\\mu_{Engineering}+\\mu_{Chemistry}}{2} = \\frac{\\mu_{Education}+\\mu_{PoliSci}+\\mu_{Psychology}}{3}\n$$\n\nweighted mean difference:\n\n$$\nC = c_1\\mu_{Eng}+c_2\\mu_{Edu}+c_3\\mu_{Chem}+c_4\\mu_{PoliSci}+c_5\\mu_{Psych}\\\\\n= \\frac{1}{2}*4.25+(-\\frac13)*2.75+(\\frac12)*3.54+(-\\frac13)*3.85+(-\\frac13)*2.02\\\\\n= 1.0173\n$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(C <- sum(summary_tbl_ext$Contrasts*summary_tbl_ext$Mean))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.0173\n```\n\n\n:::\n:::\n\n\n\n$$\n\\sum\\frac{c^2}{n} = \\frac{(\\frac12)^2}{28}+\\frac{(-\\frac13)^2}{28}+\\frac{(\\frac12)^2}{28}+\\frac{(-\\frac13)^2}{28}+\\frac{(-\\frac13)^2}{28}\n$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(Sum_C2_n <- sum(summary_tbl_ext$Contrasts^2 / summary_tbl$N))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.029762\n```\n\n\n:::\n\n```{.r .cell-code}\n(MSE = sum((residuals(aov(score ~ group, dt)))^2) / (nrow(dt) - 5))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5.0011\n```\n\n\n:::\n\n```{.r .cell-code}\n(t = as.numeric(C / sqrt(MSE * Sum_C2_n)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.6369\n```\n\n\n:::\n:::\n\n\n\n$$\nt = \\frac{C}{\\sqrt{MSE*\\sum\\frac{c^2}{n} }} = \\frac{1.0173}{\\sqrt{5.0011*0.029762}}=2.6368\n$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npt(t, df = 135, lower.tail = FALSE) * 2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.0093476\n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n### Method 2: Linear Regression Contrasts by R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# set first contrast\ncontrasts(dt$group) <- matrix(\n  c(1/2, -1/3, 1/2, -1/3, -1/3)\n)\nfit_extended <- lm(score ~ group, dt)\nunique(model.matrix(fit_extended))[, 1:2]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    (Intercept)   group1\n1             1  0.50000\n29            1 -0.33333\n57            1  0.50000\n85            1 -0.33333\n113           1 -0.33333\n```\n\n\n:::\n:::\n\n::: {.cell output-line-numbers='3'}\n\n```{.r .cell-code}\nsummary(fit_extended)$coefficient |> round(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n``` highlight\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)    3.287      0.189  17.391    0.000\ngroup1         1.221      0.463   2.637    0.009\ngroup2        -0.518      0.423  -1.227    0.222\ngroup3         0.948      0.423   2.243    0.027\ngroup4        -0.885      0.423  -2.093    0.038\n```\n\n\n:::\n:::\n\n\n\n# Effect Sizes\n\n## What is Effect Sizes\n\n-   Effect size measures the magnitude of an effect beyond statistical significance.\n    -   Put simply: a p-value is partially dependent on sample size and does not give us any insight into the strength of the relationship\n    -   Lower p-value → just increase sample size\n-   Provides context for interpreting practical significance.\n    -   In scientific experiments, it is often useful to know not only whether an experiment has a statistically significant effect, but also the size (magnitude) of any observed effects.\n-   Common measures: Eta squared ($\\eta^2$), Omega squared ($\\omega^2$), Cohen’s d.\n\n::: callout-note\nMany psychology journals require the reporting of effect sizes\n:::\n\n## Eta Squared\n\n-   $\\eta^2$: Proportion of total variance explained by the independent variable.\n-   Formula: $\\eta^2 = \\frac{SS_{Model}}{SS_{Total}}$\n-   Interpretation:\n    -   Small: 0.01, Medium: 0.06, Large: 0.14\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(F_table <- as.data.frame(anova(fit)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           Df  Sum Sq Mean Sq F value    Pr(>F)\ngroup       4  89.368 22.3420  4.4674 0.0020173\nResiduals 135 675.149  5.0011      NA        NA\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n(eta_2 <- F_table$`Sum Sq`[1] / sum(F_table$`Sum Sq`))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.11689\n```\n\n\n:::\n:::\n\n\n\n[Interpretation: 11.69% of variance in the DV is due to group differences.]{.redcolor}\n\n## Drawbacks of Eta Squared\n\n1.  **As you add more variables to the model, the proportion explained by any one variable will automatically decrease.**\n    -   This makes it hard to compare the effect of a single variable in different studies.\n    -   Partial Eta Squared solves this problem. There, the denominator is not the total variation in Y, but the unexplained variation in Y plus the variation explained just by that IV.\n        -   Any variation explained by other IVs is removed from the denominator.\n    -   In a one-way ANOVA, Eta Squared and Partial Eta Squared will be equal, but this isn’t true in models with more than one independent variable (factorial ANOVA).\n2.  **Eta Squared is a biased measure of population variance explained (although it is accurate for the sample).**\n    -   It always overestimates it. This bias gets very small as sample size increases, but for small samples an unbiased effect size measure is Omega Squared.\n\n## Omega Square\n\n-   Omega Squared ($\\omega^2$) has the same basic interpretation but uses unbiased measures of the variance components.\n    -   Because it is an unbiased estimate of population variances, Omega Squared is always smaller than Eta Squared. \\## Omega Squared ($\\omega^2$)\n-   Unbiased estimate of effect size, preferred for small samples.\n-   Formula: $\\omega^2 = \\frac{SS_{Model} - df_{Model} \\cdot MSE}{SS_{Total} + MSE}$\n-   Interpretation follows $\\eta^2$ scale but slightly smaller values.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nF_table\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           Df  Sum Sq Mean Sq F value    Pr(>F)\ngroup       4  89.368 22.3420  4.4674 0.0020173\nResiduals 135 675.149  5.0011      NA        NA\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nattach(F_table) #<1>\n(Omega_2 <- (`Sum Sq`[1] - Df[1] * MSE) / (sum(`Sum Sq`) + MSE)) #<2>\ndetach(F_table)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.090139\n```\n\n\n:::\n:::\n\n\n\n1.  Attach data set so that you can directly call the columns without \"\\$\"\n2.  The formula of Omega square\n\n## Effect Size for Planned Contrasts\n\n-   Correlation-based effect size: $r = \\sqrt{\\frac{t^2}{t^2 + df}} = \\sqrt{\\frac{F}{F + df}}$\n-   Example: For $t = 2.49, df = 135$: $r = \\sqrt{\\frac{2.49^2}{2.49^2 + 135}} = 0.21$\n    -   Small to moderate effect.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(coef_tbl <- as.data.frame(summary(fit)$coefficients))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Estimate Std. Error t value   Pr(>|t|)\n(Intercept)  4.25000    0.42262 10.0562 4.2275e-18\ngroupg2     -1.49107    0.59768 -2.4948 1.3810e-02\ngroupg3     -0.70536    0.59768 -1.1802 2.4001e-01\ngroupg4     -0.39321    0.59768 -0.6579 5.1172e-01\ngroupg5     -2.22571    0.59768 -3.7239 2.8718e-04\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nattach(coef_tbl)\nround(sqrt(`t value`^2 / (`t value`^2 + 135)), 3)\ndetach(coef_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.654 0.210 0.101 0.057 0.305\n```\n\n\n:::\n:::\n\n\n- Shows a small to moderate positive relationship between g1 with g5.\n\n## Cohen’s d and Hedges’ g\n\n-   Used for simple mean comparisons.\n-   Cohen’s d formula: $d = \\frac{M_1 - M_2}{SD_{pooled}}$\n-   Hedges’ g corrects for small sample bias.\n-   Guidelines:\n    -   Small: 0.2, Medium: 0.5, Large: 0.8\n\n## Guideline of Effect Size\n\n![](images/clipboard-1482285190.png)\n\n- For our example: there is a significant effect of academic program on growth mindset scores (F(4,135)=4.47).\n- Academic program explains 11.69% of variance in growth mindset scores. This is a\nlarge medium to large effect ($\\eta^1$ = 0.1169).\n\n## Summary\n\n-   Planned contrasts allow hypothesis-driven mean comparisons.\n-   Orthogonal contrasts maintain Type I error control.\n-   Effect sizes help interpret the importance of results.\n-   Combining planned contrasts with effect size measures enhances statistical analysis.\n",
    "supporting": [
      "ESRM64103_Lecture05_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}