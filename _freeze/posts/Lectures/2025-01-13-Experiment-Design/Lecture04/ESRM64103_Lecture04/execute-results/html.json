{
  "hash": "e5946092b3d8c1df89d30e950dce715d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lecture 04: ANOVA Assumptions\"\nsubtitle: \"Experimental Design in Education\"\nauthor: \"Jihong Zhang*, Ph.D\"\ninstitute: | \n  Educational Statistics and Research Methods (ESRM) Program*\n  \n  University of Arkansas\ndate: \"2025-08-18\"\nsidebar: false\nexecute: \n  eval: true\n  echo: true\nformat: \n  #html: \n  #  page-layout: full\n  #  toc: true\n  #  toc-depth: 2\n  #  lightbox: true\n  uark-revealjs:\n    chalkboard: true\n    embed-resources: false\n    code-fold: false\n    number-sections: true\n    number-depth: 1\n    footer: \"ESRM 64503: Lecture 04\"\n    slide-number: c/t\n    tbl-colwidths: auto\n    scrollable: true\n#jupyter: python3\n---\n\n\n\n## Class Outline\n\n-  Go through three assumptions of ANOVA and their checking statistics\n-  Omnibus test for more group comparisons.\n-  Example: Intervention and Verbal Acquisition\n-  Exercise: Effect of Sleep Duration on Cognitive Performance\n\n\n## ANOVA Procedure\n\n1.  **Set hypotheses**:\n    -   **Null hypothesis** ($H_0$): All group means are equal.\n    -   **Alternative hypothesis** ($H_A$): At least one group mean differs.\n2.  **Determine statistical parameters**:\n    -   Significance level $\\alpha$\n    -   Degrees of freedom for between-group ($df_b$) and within-group ($df_w$)\n    -   Find the critical F-value.\n3.  **Compute test statistic**:\n    -   Calculate **F-ratio** based on between-group and within-group variance.\n4.  **Compare results**:\n    -   Either compare $F_{\\text{obs}}$ with $F_{\\text{crit}}$ or $p$-value with $\\alpha$.\n    -   If $p < \\alpha$, reject $H_0$.\n\n# ANOVA Assumptions\n\n## Overview\n\n-   Like all statistical tests, ANOVA requires certain assumptions to be met for valid conclusions:\n    -   **Independence**: Observations are independent of each other.\n    -   **Normality**: The residuals (errors) follow a normal distribution.\n    -   **Homogeneity of variance (HOV)**: The variance within each group is approximately equal.\n\n## Importance of Assumptions\n\n-   **If assumptions are violated**, the results of ANOVA may not be reliable.\n-   **Robustness**:\n    -   ANOVA is **robust** to minor violations of normality, especially for large sample sizes (Central Limit Theorem).\n    -   **Not robust** to violations of independence—if independence is violated, ANOVA is inappropriate.\n    -   **Moderately robust** to HOV violations if sample sizes are equal.\n\n## Assumption 1: Independence\n\n-   **Definition**: Each observation should be independent of others.\n-   **Violations**:\n    -   Clustering of data (e.g., repeated measures).\n    -   Participants influencing each other (e.g., classroom discussions).\n-   **Check**: Use the **Durbin-Watson test**.\n-   **Consequences**: If independence is violated, **ANOVA results are not valid**.\n\n------------------------------------------------------------------------\n\n### Durbin-Watson Statistic (DW)\n\n::: callout-note\n-   The Durbin-Watson test is primarily used for detecting **autocorrelation** in time-series data.\n\n-   In the context of ANOVA with independent groups, residuals are generally assumed to be independent. However, it's still good practice to check this assumption, especially if there's a reason to suspect potential autocorrelation.\n:::\n\n-   Properties of DW Statistic:\n    -   Ranges from 0 to 4.\n        -   A value around 2 suggests no autocorrelation.\n        -   Values approaching 0 indicate positive autocorrelation.\n        -   Values toward 4 suggest negative autocorrelation.\n    -   P-value\n        -   P-Value: A small p-value (typically \\< 0.05) indicates significant autocorrelation in the residuals. A larger p-value suggests no evidence of autocorrelation.\n\n## Assumption 2: Normality\n\n-   The **dependent variable (DV)** should be normally distributed within each group.\n-   **Assessments**:\n    -   **Graphical methods**: Histograms, Q-Q plots.\n    -   **Statistical tests**:\n        -   **Shapiro-Wilk test** (common)\n        -   **Kolmogorov-Smirnov (KS) test** (for large samples)\n        -   **Anderson-Darling test** (detects kurtosis issues).\n-   **Robustness**:\n    -   ANOVA is **robust** to normality violations for **large samples**.\n    -   **If normality is violated**, consider transformations or non-parametric tests.\n\n## Assumption 3: Homogeneity of Variance (HOV)\n\n-   Variance across groups should be equal.\n-   **Assessments**:\n    -   **Levene’s test**: Tests equality of variances.\n    -   **Brown-Forsythe test**: More robust to non-normality.\n    -   **Boxplots**: Visual inspection.\n-   **What if violated?**\n    -   Use **Welch’s ANOVA**, which corrects for variance differences.\n\n## ANOVA Robustness\n\n-   **Robust to**:\n    -   Minor normality violations (for large samples).\n    -   Small HOV violations if group sizes are **equal**.\n-   **Not robust to**:\n    -   **Independence violations**—ANOVA is invalid if data points are dependent.\n    -   **Severe HOV violations**—Type I error rates become unreliable.\n\n## Homogeneity of Variance Violation\n\n-   If HOV is **violated**, options include:\n    -   **Welch’s ANOVA** (adjusted for variance differences).\n    -   **Transforming** the dependent variable.\n    -   **Using non-parametric tests** (e.g., Kruskal-Wallis).\n\n# Omnibus ANOVA Test\n\n## Overview\n\n-   **What does it test?**\n    -   Whether there is **at least one** significant difference among means.\n-   **Limitation**:\n    -   Does **not** tell **which** groups are different.\n-   **Solution**:\n    -   Conduct **post-hoc tests**.\n\n## Individual Comparisons of Means\n\n-   If ANOVA is **significant**, follow-up tests identify **where** differences occur.\n-   **Types**:\n    -   **Planned comparisons**: Defined **before** data collection.\n    -   **Unplanned (post-hoc) comparisons**: Conducted **after** ANOVA.\n\n## Planned vs. Unplanned Comparisons\n\n-   **Planned**:\n    -   Based on **theory**.\n    -   Can be done **even if ANOVA is not significant**.\n-   **Unplanned (post-hoc)**:\n    -   **Data-driven**.\n    -   Only performed **if ANOVA is significant**.\n\n## Types of Unplanned Comparisons\n\n-   **Common post-hoc tests**:\n    1.  **Fisher’s LSD**\n    2.  **Bonferroni correction**\n    3.  **Sidák correction**\n    4.  **Tukey’s HSD**\n\n## Fisher’s LSD\n\n-   **Least Significant Difference test**.\n-   **Problem**: Does not control for **multiple comparisons** (inflated Type I error).\n\n## Bonferroni Correction\n\n-   Adjusts **alpha** to reduce **Type I error**.\n-   New alpha: $\\alpha / c$ (where $c$ is the number of comparisons).\n-   **Conservative**: Less power, avoids false positives.\n\n## Sidák Correction\n\n-   Similar to Bonferroni but slightly more powerful.\n-   New alpha: $1 - (1 - \\alpha)^{1/c}$.\n\n## Tukey’s HSD\n\n-   Controls for **Type I error** across multiple comparisons.\n-   Uses a **q-statistic** from a Tukey table.\n-   Preferred when **all pairs** need comparison.\n\n## ANOVA Example: Intervention and Verbal Acquisition\n\n### Background\n\n-   Research Question: Does an intensive intervention improve students’ verbal acquisition scores?\n-   Study Design:\n    -   4 groups: Control, G1, G2, G3 (treatment levels).\n    -   Outcome variable: Verbal acquisition score (average of three assessments).\n-   Hypotheses:\n    -   $H_0$: No difference in verbal acquisition scores across groups.\n    -   $H_A$: At least one group has a significantly different mean.\n\n## Step 1: Generate Simulated Data in R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load necessary libraries\nlibrary(tidyverse)\n\n# Set seed for reproducibility\nset.seed(123)\n\n# Generate synthetic data for 4 groups\ndata <- tibble(\n  group = rep(c(\"Control\", \"G1\", \"G2\", \"G3\"), each = 30),\n  verbal_score = c(\n    rnorm(30, mean = 70, sd = 10),  # Control group\n    rnorm(30, mean = 75, sd = 12),  # G1\n    rnorm(30, mean = 80, sd = 10),  # G2\n    rnorm(30, mean = 85, sd = 8)    # G3\n  )\n)\n\n# View first few rows\nhead(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n  group   verbal_score\n  <chr>          <dbl>\n1 Control         64.4\n2 Control         67.7\n3 Control         85.6\n4 Control         70.7\n5 Control         71.3\n6 Control         87.2\n```\n\n\n:::\n:::\n\n\n\n## Step 2: Summary Statistics\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Summary statistics by group\ndata %>%\n  group_by(group) %>%\n  summarise(\n    mean_score = mean(verbal_score),\n    sd_score = sd(verbal_score),\n    n = n()\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 4\n  group   mean_score sd_score     n\n  <chr>        <dbl>    <dbl> <int>\n1 Control       69.5     9.81    30\n2 G1            77.1    10.0     30\n3 G2            80.2     8.70    30\n4 G3            84.2     7.25    30\n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Boxplot visualization\nggplot(data, aes(x = group, y = verbal_score, fill = group)) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(title = \"Verbal Acquisition Scores Across Groups\", y = \"Score\", x = \"Group\")\n```\n\n::: {.cell-output-display}\n![](ESRM64103_Lecture04_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n\n## Step 3: Check ANOVA Assumptions\n\n### Assumption Check 1: Independence of residuals Check\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit the ANOVA model\nanova_model <- lm(verbal_score ~ group, data = data)\n\n# Install lmtest package if not already installed\n# install.packages(\"lmtest\")\n\n# Load the lmtest package\nlibrary(lmtest)\n\n# Perform the Durbin-Watson test\ndw_test_result <- dwtest(anova_model)\n\n# View the test results\nprint(dw_test_result)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tDurbin-Watson test\n\ndata:  anova_model\nDW = 2.0519, p-value = 0.5042\nalternative hypothesis: true autocorrelation is greater than 0\n```\n\n\n:::\n:::\n\n\n\n-   Interpretation:\n    -   In this example, the `DW` value is close to 2, and the p-value is greater than 0.05, indicating no significant autocorrelation in the residuals.\n\n------------------------------------------------------------------------\n\n### Assumption Check 2: Normality Check\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Shapiro-Wilk normality test for each group\ndata %>%\n  group_by(group) %>%\n  summarise(\n    shapiro_p = shapiro.test(verbal_score)$p.value\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 2\n  group   shapiro_p\n  <chr>       <dbl>\n1 Control     0.797\n2 G1          0.961\n3 G2          0.848\n4 G3          0.568\n```\n\n\n:::\n:::\n\n\n\n-   Interpretation:\n    -   If $p>0.05$, normality assumption is not violated.\n    -   If $p<0.05$, data deviates from normal distribution.\n\n------------------------------------------------------------------------\n\n-   Alternative Check: Q-Q Plot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data, aes(sample = verbal_score)) +\n  geom_qq() + geom_qq_line() +\n  facet_wrap(~group) +\n  theme_minimal() +\n  labs(title = \"Q-Q Plot for Normality Check\")\n```\n\n::: {.cell-output-display}\n![](ESRM64103_Lecture04_files/figure-revealjs/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n### Assumption Check 3: Homogeneity of Variance (HOV) Check\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Levene's Test for homogeneity of variance\nlibrary(car)\nleveneTest(verbal_score ~ group, data = data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value Pr(>F)\ngroup   3  1.1718 0.3236\n      116               \n```\n\n\n:::\n:::\n\n\n\n-   Interpretation:\n    -   If $p>0.05$, variance is homogeneous (ANOVA assumption met).\n    -   If $p<0.05$, variance differs across groups (consider Welch’s ANOVA).\n\n## Step 4: Perform One-Way ANOVA\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova_model <- aov(verbal_score ~ group, data = data)\nsummary(anova_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             Df Sum Sq Mean Sq F value   Pr(>F)    \ngroup         3   3492  1164.1   14.33 5.28e-08 ***\nResiduals   116   9424    81.2                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n-   Interpretation:\n    -   If $p<0.05$, at least one group mean is significantly different.\n    -   If $p>0.05$, fail to reject $H0$ (no significant differences).\n\n## Step 5: Post-Hoc Tests (Tukey’s HSD)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Tukey HSD post-hoc test\ntukey_results <- TukeyHSD(anova_model)\ntukey_results\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = verbal_score ~ group, data = data)\n\n$group\n                diff       lwr       upr     p adj\nG1-Control  7.611098  1.544769 13.677427 0.0076195\nG2-Control 10.715241  4.648912 16.781571 0.0000625\nG3-Control 14.719926  8.653597 20.786255 0.0000000\nG2-G1       3.104144 -2.962185  9.170473 0.5434070\nG3-G1       7.108829  1.042499 13.175158 0.0146493\nG3-G2       4.004685 -2.061644 10.071014 0.3176380\n```\n\n\n:::\n:::\n\n\n\n-   Interpretation:\n    -   Identifies which groups differ.\n    -   If $p<0.05$, the groups significantly differ.\n        -   G1-Control\n        -   G2-Control\n        -   G3-Control\n        -   G3-G1\n\n## Step 6: Reporting ANOVA Results\n\nA one-way ANOVA was conducted to examine the effect of an intensive intervention on verbal acquisition scores. There was a statistically significant difference between groups, $F(3,116)=14.33$, $p<.001$. Tukey's post-hoc comparisons revealed that the G3 intervention group (M=84.2, SD=7.25) had significantly higher scores than the Control (M=69.5,SD=9.81) and G1 (M=77.1,SD=10.0) groups (all p\\<.05). However, no significant difference was found between G2 and G3 (p=.31). These findings suggest that higher intervention intensity improves verbal acquisition performance.\n\n# Exercise: Effect of Sleep Duration on Cognitive Performance\n\n## Background\n\n-   Research Question:\n\n    -   Does the amount of sleep affect cognitive performance on a standardized test?\n\n-   Study Design\n\n    -   Independent variable: Sleep duration (3 groups: Short (≤5 hrs), Moderate (6-7 hrs), Long (≥8 hrs)).\n    -   Dependent variable: Cognitive performance scores (measured as test scores out of 100).\n\n## Data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set seed for reproducibility\nset.seed(42)\n\n# Generate synthetic data for sleep study\nsleep_data <- tibble(\n  sleep_group = rep(c(\"Short\", \"Moderate\", \"Long\"), each = 30),\n  cognitive_score = c(\n    rnorm(30, mean = 65, sd = 10),  # Short sleep group (≤5 hrs)\n    rnorm(30, mean = 75, sd = 12),  # Moderate sleep group (6-7 hrs)\n    rnorm(30, mean = 80, sd = 8)    # Long sleep group (≥8 hrs)\n  )\n)\n\n# View first few rows\nhead(sleep_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n  sleep_group cognitive_score\n  <chr>                 <dbl>\n1 Short                  78.7\n2 Short                  59.4\n3 Short                  68.6\n4 Short                  71.3\n5 Short                  69.0\n6 Short                  63.9\n```\n\n\n:::\n:::\n\n\n\nGo through all six steps.\n\n## Answer:\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Step 5: Perform One-Way ANOVA\nanova_sleep <- aov(cognitive_score ~ sleep_group, data = sleep_data)\nsummary(anova_sleep)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nsleep_group  2   3764  1881.9   15.88 1.32e-06 ***\nResiduals   87  10311   118.5                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\n:::{.heimu}\n- A one-way ANOVA was conducted to examine the effect of sleep duration on cognitive performance.\n\n- There was a statistically significant difference in cognitive test scores across sleep groups, $F(2,87)=15.88$,$p<.001$.\n\n- Tukey's post-hoc test revealed that participants in the Long sleep group (M=81.52,SD=6.27) performed significantly better than those in the Short sleep group (M=65.68,SD=12.55), p<.01.\n\n\n- These results suggest that inadequate sleep is associated with lower cognitive performance.\n:::\n\n",
    "supporting": [
      "ESRM64103_Lecture04_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}