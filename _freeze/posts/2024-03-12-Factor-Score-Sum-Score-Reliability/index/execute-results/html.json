{
  "hash": "f0c2b3a73b684cbf253f593c1c9eb92d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: 'Sum Score, Factor Score, and Reliability'\nauthor: 'Jihong Zhang'\ndate: 'Mar 12 2024'\ncategories:\n  - Scoring\n  - Reliability\n  - CTT\n  - Factor Analysis\nexecute: \n  warning: false\n  message: false\ncitation: true\nformat: \n  html:\n    code-fold: false\n    code-line-numbers: false\nbibliography: references.bib\n---\n\n\n\nNetwork psychometrics has become an alternative approach to factor analysis and item response theory in multiple fields of psychology and education, such as psychopathology, personality, measurement validation, and dimensionality determancy. However, individual scoring differences between psychometric network analysis and traditional psychometric modeling has not been well investigated. Some questions arise regarding individual scoring:\n\n1.  What will be individual scores in psychometric network analysis? Or, how can we evaluate the average level of each individuals?\n2.  If we can build individual scoring in psychometric network, what is the relationship between this scoring with factor scores.\n3.  How can we use this scoring method to evaluate measurement quality, such as reliability or validity?\n\nTo answer these questions, we first need to review how individuals are scored in factor analysis method and classical test theory. Borrowing the theoretical framework and purpose of factor scoring, we can construct the scoring method for psychometric network. Then, we can show that there are statistical relationship between network scores with factor scores. Thus, depending on the psychometric methods researchers use, they can be free to use either factor score or network score to report. They can also compute the other without constructing the other model.\n\nOverall, the purpose of this post is to illustrate the definition, assumption, psychometric properties, usage, and interpretation of factor scores in Structural Equation Models (SEM), and how those features of factor scores compare to sum scores in Classical Test Theory (CTT). This post is inspired by Dr. Templin's [2022 presentation](https://jonathantemplin.com/wp-content/uploads/2022/10/sem15pre906_lecture11.pdf).\n\n## Definition of Test Score\n\nIn CTT, the test score is unit of analysis of the whole test, which can be statistically expressed as:\n\n$$\nY_{total} = T+e\n$$\n\nWhere $Y_{total}$ denotes test scores, $T$ denotes true score, and $e$ denotes error. There are some assumptions:\n\n1.  Items are assumed exchangeable;\n2.  Expected value of $e$ is 0;\n3.  Error $e$ is expected to be uncorrelated with true score $T$\n\n## Scoring of Classical test theory\n\nIn classical test theory (CTT), the test score is construct as sum of item scores. CTT assumes that there is a true score exists that reflect the true ability of test takers and the observed sum scores of each individual is a combination of true score and random error.\n\n$$\nY_{total} = T + e\n$$\n\nWhere $Y_{total}$ denotes a vector of observed sum scores of respondents, $T$ denotes a vector of true scores of respondents, and $e$ denotes the random error for respondents. True scores and random errors are independent.\n\n### CTT-based reliability\n\nMultiple reliability coefficients have been proposed in previous literature. Each reliability has their advantages and disadvantages. Let's take the average iter-item correlation as one example. Average iter-item correlation is computed as the proportion of variance in the sum score that is due to variation in the latent trait or true score.\n\nWe can derive the reliability as following:\n\n$$\n\\text{Var}(Y_{total}) = \\text{Var}(T+e) = \\text{Var}(T)+\\text{Var}(e)+2\\text{Cov}(T,e)\n$$\n\nBut, since T and e are assumed independent $\\text{Cov}(T, e) = 0$, so,\n\n$$\n\\text{Var}(Y_{total}) = \\text{Var}(T)+\\text{Var}(e)\n$$\n\nThen, reliability can be computed as:\n\n$$\n\\rho = \\frac{\\text{Var}(T)}{\\text{Var}(Y)} = \\frac{\\text{Var}(T)}{\\text{Var}(T)+\\text{Var}(e)} \n$$\n\nWhere,\n\n-   $\\text{Var}(T)$ is variance of true score and could be interpreted as variability in the latent trait in the context of factor analysis.\n\n-   $\\text{Var}(e)$ is variance of error, and could be interpreted as measurement error\n\n#### Mini example\n\nUsing a 10-item example with each having 1-5 scale.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(tidyverse)\nlibrary(here)\nlibrary(kableExtra)\nlibrary(psych)\ndat_path <- 'posts/2024-01-12-syllabus-adv-multivariate-esrm-6553/Lecture07/Code'\nconspiracy <- read.csv(here(dat_path, 'conspiracies.csv'))\nitemResp <- conspiracy |> select(starts_with('PolConsp'))\nconspiracy |> \n  mutate(ID = 1:177) |> \n  pivot_longer(starts_with('PolConsp'), names_to = 'Item', values_to = 'Resp') |> \n  mutate(Item = factor(Item, paste0('PolConsp', 1:10))) |> \n  group_by(Item) |> \n  summarise(\n    Mean = mean(Resp),\n    SD = sd(Resp),\n    Min = min(Resp),\n    Max = max(Resp),\n    Skew = psych::skew(Resp)\n  ) |> \n  kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|Item       |  Mean|    SD| Min| Max|  Skew|\n|:----------|-----:|-----:|---:|---:|-----:|\n|PolConsp1  | 2.367| 1.136|   1|   5| 0.432|\n|PolConsp2  | 1.955| 1.112|   1|   5| 1.050|\n|PolConsp3  | 1.876| 1.096|   1|   5| 1.019|\n|PolConsp4  | 2.011| 1.108|   1|   5| 0.925|\n|PolConsp5  | 1.983| 1.105|   1|   5| 0.962|\n|PolConsp6  | 1.893| 1.003|   1|   5| 0.887|\n|PolConsp7  | 1.723| 1.004|   1|   5| 1.340|\n|PolConsp8  | 1.842| 0.952|   1|   5| 0.788|\n|PolConsp9  | 1.808| 1.137|   1|   5| 1.324|\n|PolConsp10 | 1.520| 1.056|   1|   5| 2.224|\n\n\n:::\n:::\n\n\n\nOne estimate of the internal consistency reliability of a test is <mark>Cronbach's $\\alpha$</mark>, which summarizes the average item-test correlation.\n\nThe standard Cronbach's $\\alpha$ is .93. The average Iter-Item Correlation is .564. Ideally, the average inter-item correlation for a set of items should be between .20 and .40, suggesting that while the items are reasonably homogenous, they do contain sufficiently unique variance so as to not be isomorphic with each other [@piedmont2014].\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkable(alpha(itemResp)$total, digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|   | raw_alpha| std.alpha| G6(smc)| average_r|    S/N|   ase|  mean|    sd| median_r|\n|:--|---------:|---------:|-------:|---------:|------:|-----:|-----:|-----:|--------:|\n|   |     0.927|     0.928|   0.935|     0.564| 12.937| 0.008| 1.898| 0.833|    0.582|\n\n\n:::\n:::\n\n\n\nUsing factor analysis and `lavaan`, we can reproduce average inter-item correlations assuming items are tau-equavalent:\n\n-   Item responses are standardized (mean as 0, variance as 1)\n\n-   Factor loadings are constrained to be equal as 1\n\n-   Residual variances of items are constrained to be equal\n\nThen, iter-item correlation and Cronbach's alpha can be computed as:\n\n$$\n\\rho = \\frac{\\text{Var}(\\theta)}{\\text{Var}(\\theta)+\\text{Var}(\\psi)}\n$$\n\n$$\n\\alpha = \\frac{N\\rho}{\\sigma^2 +(N-1)\\rho}\n$$\n\nwhere N is sample size, $\\rho$ is average iter-item correlation, and $\\sigma^2$ are average item variances and equal to 1 if items are standardized.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lavaan)\nitemResp_std <- itemResp |> \n  mutate(across(everything(), scale))\nunifac_model <- '\nF1 =~ 1*PolConsp1+1*PolConsp2+1*PolConsp3+1*PolConsp4+1*PolConsp5+1*PolConsp6+1*PolConsp7+1*PolConsp8+1*PolConsp9+1*PolConsp10\nPolConsp1 ~~equal(\"e1\")*PolConsp1\nPolConsp2 ~~equal(\"e1\")*PolConsp2\nPolConsp3 ~~equal(\"e1\")*PolConsp3\nPolConsp4 ~~equal(\"e1\")*PolConsp4\nPolConsp5 ~~equal(\"e1\")*PolConsp5\nPolConsp6 ~~equal(\"e1\")*PolConsp6\nPolConsp7 ~~equal(\"e1\")*PolConsp7\nPolConsp8 ~~equal(\"e1\")*PolConsp8\nPolConsp9 ~~equal(\"e1\")*PolConsp9\nPolConsp10~~equal(\"e1\")*PolConsp10\n'\nfit = cfa(model = unifac_model, data = itemResp_std, std.lv = FALSE)\n# summary(fit)\nVar_F1 = as.numeric(coef(fit)['F1~~F1'])\nVar_errors= as.numeric(coef(fit)[1])\nrho = Var_F1 / (Var_F1 + Var_errors) # reliability \nrho # average iter-item correlation\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.5640165\n```\n\n\n:::\n\n```{.r .cell-code}\nCron_alpha = 10*rho / (1 + (10-1)*rho )\nCron_alpha # Cronbach's alpha\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9282467\n```\n\n\n:::\n:::\n\n\n\nCronbach's alpha is related to number of items:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(greekLetters)  \ntibble(nItems = 2:20, alpha = nItems*rho / (1 + (nItems-1)*rho )) |> \n  ggplot() +\n  aes(x = nItems, y = alpha) +\n  geom_point(size = 3, shape = 1) +\n  geom_path(group = 1) +\n  scale_x_continuous(breaks = 2:20) +\n  scale_y_continuous(breaks = seq(0.7, 1, .025), limits = c(0.7, 1)) +\n  labs(x = 'Retrospective Number of items', y = paste0(\"Cronbach's \", greeks('alpha')),\n       title = 'Relationship between number of items with alpha')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n## Scoring of Factor Analysis\n\nIn factor analysis, factor scores are computed by using factor loadings and factor correlations. In most modern statistical software (i.e., lavaan, Mplus etc), factor scores are estimated by multivariate methods that use various aspects of the reduced or unreduced correlation matrix and factor analysis coefficients [@timothy2015]. A frequently used method of estimating factor scores is Thurstone's (1935) least squared regression approach, although several other strategies have been developed (e.g., Bartlett, 1937; Harman, 1976; McDonald, 1982).\n\nFor confirmatory factor analysis that is identified, the scoring method discussed by Thurston (1935) and Thomson (1934) has the closed form[@ferrando2018]:\n\n$$\nEAP(\\theta_i) = \\Phi\\Lambda'R^{-1}X_i=S'R^{-1}X_i\n$$\n\nWhere $\\theta_i$ is the factor score estimate for individual $i$, and $\\Phi$ is the factor correlation matrix (for example, for single factor model, $\\Phi$ is 1 $\\times$ 1 matrix ), $\\Lambda$ is the pattern loading matrix, and $R$ is the structural correlation matrix between items.\n\nUsing the previous consipiracy theory data, we can calculate the factor scores directly using Thurston's method and compare to factor score by `lavaan`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2 <- '\n    F1 =~ PolConsp1+PolConsp2+PolConsp3+PolConsp4+PolConsp5+PolConsp6+PolConsp7+PolConsp8+PolConsp9+PolConsp10\n'\nfit2 = cfa(model = model2, data = itemResp_std, std.lv = TRUE)\nsummary(fit2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlavaan 0.6.17 ended normally after 20 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        20\n\n  Number of observations                           177\n\nModel Test User Model:\n                                                      \n  Test statistic                               120.975\n  Degrees of freedom                                35\n  P-value (Chi-square)                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  F1 =~                                               \n    PolConsp1         0.627    0.069    9.127    0.000\n    PolConsp2         0.755    0.065   11.677    0.000\n    PolConsp3         0.706    0.066   10.647    0.000\n    PolConsp4         0.734    0.065   11.234    0.000\n    PolConsp5         0.871    0.060   14.528    0.000\n    PolConsp6         0.865    0.060   14.367    0.000\n    PolConsp7         0.735    0.065   11.244    0.000\n    PolConsp8         0.865    0.060   14.361    0.000\n    PolConsp9         0.730    0.065   11.154    0.000\n    PolConsp10        0.615    0.069    8.893    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .PolConsp1         0.601    0.067    9.030    0.000\n   .PolConsp2         0.425    0.049    8.634    0.000\n   .PolConsp3         0.496    0.056    8.828    0.000\n   .PolConsp4         0.455    0.052    8.724    0.000\n   .PolConsp5         0.236    0.031    7.540    0.000\n   .PolConsp6         0.246    0.032    7.643    0.000\n   .PolConsp7         0.455    0.052    8.723    0.000\n   .PolConsp8         0.247    0.032    7.646    0.000\n   .PolConsp9         0.461    0.053    8.740    0.000\n   .PolConsp10        0.617    0.068    9.055    0.000\n    F1                1.000                           \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n## extract factor loadings and unique variances\nlambdas = as.numeric(coef(fit2)[paste0(\"F1=~PolConsp\", 1:10)])\nLambda = matrix(lambdas, ncol = 1)\npsis = as.numeric(coef(fit2)[paste0(\"PolConsp\", 1:10, \"~~PolConsp\", 1:10)])\nPsi = diag(psis)\n\n## Estimated Structural correlation matrix\nR = Lambda %*% t(Lambda) + Psi\nTheta = as.numeric(diag(1) %*% t(Lambda) %*% solve(R) %*% t(itemResp_std))\nTheta_lav = as.numeric(predict(fit2))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfs = tibble(\n   Theta = Theta,\n   Theta_lav =  Theta_lav\n)\nfs\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 177 × 2\n     Theta Theta_lav\n     <dbl>     <dbl>\n 1  0.0199    0.0199\n 2  1.58      1.58  \n 3  1.76      1.76  \n 4 -0.962    -0.962 \n 5  0.0437    0.0437\n 6 -1.01     -1.01  \n 7 -0.353    -0.353 \n 8 -0.0569   -0.0569\n 9 -0.817    -0.817 \n10  0.0437    0.0437\n# ℹ 167 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\nggplot(fs) +\n  geom_point(aes(x = Theta, y = Theta_lav)) +\n  labs(x = \"Factor score by Thurston's method\", y = \"Factor score by `lavaan`\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n::: callout-note\n## Relationship between factor score and network score\n\nThe official paper will show network score is a special case of factor score.\n:::",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}