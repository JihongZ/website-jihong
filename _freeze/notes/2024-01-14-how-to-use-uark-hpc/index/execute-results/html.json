{
  "hash": "f9f0a1e4992cf573e503072a017a23df",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Use High Performance Computing UArk\"\nsubtitle: \"AHPCC from University of Arkansas\"\nauthor: Jihong Zhang\ndate: 2024-01-14\ncategories: \n  - Tutorial\n  - AHPCC\n  - HPC\n  - Parallelization\nformat: \n  html: \n    code-annotations: hover\n    code-line-numbers: false\n    toc: true\n    toc-depth: 3\n    number-sections: true\ncitation:\n  type: webpage\n  issued: 2024-01-14\n---\n\n\n\n::: callout-important\n## 2025-03-20 Update\nMy student Nicole recently had a excellent workshop on how to use HPC interactively at UArk. Please refer to her website  [here](https://nbonge.quarto.pub/r-in-ahpc/).\n:::\n\n::: objectives\n## General Information {.unnumbered}\nArkansas High Performance Computing Center (AHPCC, [official website](https://hpc.uark.edu/)) is available for research and instructional use to faculty and students of any Arkansas university and their research collaborators. There is no charge for use of our computing resources.\n\nTo use the HPC, an AHPCC account must be requested through [Internal Account Request Form](http://hpc.uark.edu/hpc-support/user-account-requests/internal.php). Please see [here](https://dartproject.org/hpc/) for more information about AHPPC inventory.\n:::\n\n## Connect to HPC\n\n-   You can use online [dashboard](https://hpc-portal2.hpc.uark.edu/pun/sys/dashboard) or terminal to have access to AHPCC nodes.\n\n### For terminal\n\nAs long as you have an AHPCC account, you can connect to HPC through SSH. For Windows users, you can use [PuTTY](http://www.putty.org/) or Powershell to connect to HPC. For Mac and Linux users, you can use the terminal to connect to HPC. The command is:\n\n``` bash\nssh [username]@hpc-portal2.hpc.uark.edu\n```\n\nReplace \\[username\\] with your username of AHPCC account. Passwords will be required. After you enter your password, you will be connected to HPC and your terminal/Powershell will look like this.\n\n![Login Screenshot](login.png)\n\nNote: Pinnacle is a new resource at the University of Arkansas in 2019. It consists of 100 Intel based nodes with 20 NVIDIA V100 GPU nodes enabling data science and machine learning and 8 big memory nodes with 768 Gb ram/each for projects requiring a large memory footprint.\n\n### SSH login without password\n\n1.  Generate a pair of authentication keys in your local machine and do not enter a passphrase using the following codes:\n\n``` bash\nssh-keygen -t rsa   \n```\n\nPlease note that make the passphrase empty:\n\n```         \nGenerating public/private rsa key pair.\nEnter file in which to save the key (/Users/[username]/.ssh/id_rsa): \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in /Users/[username]/.ssh/id_rsa\nYour public key has been saved in /Users/[username]/.ssh/id_rsa.pub\n```\n\n2.  In your local machine, type in following commands to copy local public key to the hpc server.\n\n``` bash\nscp ~/.ssh/id_rsa.pub [loginname]@hpc-portal2.hpc.uark.edu:/home/[loginname]/.ssh/authorized_keys\n```\n\n3.  Now you should be able to login the hpc login node without password:\n\n``` bash\nssh [loginname]@hpc-portal2.hpc.uark.edu\n```\n\n## Upload or Download Data\n\nThere are two ways to download data: (1) dashboard (2) terminal\n\n### Dashboard\n\nOne the dashboard page, find `Files` tag on the navigation bar:\n\n**Files \\> /karpinski/\\[username\\]**\n\nYou then should be able to upload or download your files from local to server or form server to local.\n\n### Terminal\n\n-   To **upload** data files from local machine to HPC, type in following codes on your local machine:\n\n``` bash\nscp program.c [username]@hpc-portal2.hpc.uark.edu:/home/username/\n```\n\nwhere `program.c` is one example file you want to upload. If you target file is located in **Downloads** folder, use `~/Downloads/program.c` instead.\n\nTo copy an entire **folder and its subfolds** using SCP, add parameter `-r` following `scp` for recursive operations (`src` is a folder for example):\n\n``` bash\nscp -r src [username]@hpc-portal2.hpc.uark.edu:/home/username/\n```\n\n-   To **download** data files from HPC to local machine, type in following codes on your local machine:\n\n``` bash\nscp -r [username]@hpc-portal2.hpc.uark.edu:/home/username/src ./\n```\n\n## Frequent-use SLURM Commands\n\n| slurm commands | compatibility commands | Meaning |\n|-------------------|-----------------------|------------------------------|\n| `sbatch` | `qsub` | submit \\<job file\\> |\n| `srun` | `qsub -I` | submit interactive job |\n| `squeue` | `qstat` | list all queued jobs |\n| `squeue -u [username]` | `qstat -u [username]` | list queued jobs for user rfeynman |\n| `scancel` | `qdel` | cancel \\<job#\\> |\n| `sinfo` | `shownodes -l -n;qstat -q` | node status;list of queues |\n\n::: callout-note\n## Note\n\nFor slurm, please use the commands in the 1st column. Then you should be able to start R in an interactive job and install required packages. If you load `R/4.2.2` module, those packages installed via an interactive job will be stored at `$HOME$/R/x86_64-pc-linux-gnu/4.2/`. See [here](https://hpcwiki.uark.edu/doku.php?id=pinnacle_usage) for more details about interactive job.\n:::\n\n\n## Jobs submission\n\n### Workflow\n\nThere are multiple steps to submit the R file to cluster to run.\n\n1.  Before we submit the job file, we need to determine the computing nodes we want to use. Please refer to this [link](#0) for detailed information about HPC equipment. A general '*job submit*' command is like this:\n\n    ``` bash\n    sbatch -q q06h32c -l walltime=1:00 -l nodes=1:ppn=32 example.sh\n    ```\n\n    ::: {.callout-note appearance=\"simple\"}\n## Note\nThe `sbatch` command (a slurm command) aims to submit a job that is saved to the job file `example.sh` or `example.slurm`. The command above submitted the job to the q06h32c queue with a wall-time of 1 minute requesting all 32 cores on 1 node.\n    :::\n\n2.  Then, we need to create a job file with `.sh` or `.slurm` extension to automatically run the job submission commands on the HPC. \n\n    Here's a simple example of a job file `example.sh` that can tell HPC **how** to run your R code (`#SBATCH` represents all parameters we feed to job submission):\n\n    ``` bash\n    #!/bin/bash\n    #SBATCH --job-name=mpi\n    #SBATCH --output=zzz.slurm\n    #SBATCH --partition comp06\n    #SBATCH --nodes=2\n    #SBATCH --tasks-per-node=32\n    #SBATCH --time=6:00:00\n    module load gcc/11.2.1 mkl/19.0.5 R/4.2.2\n    # module load gcc/11.2.1 intel/21.2.0 mkl/21.3.0 R/4.3.0\n\n    Rscript HelloWorld/example.R\n    ```\n\n    ::::{.callout-note collapse=\"true\"}\n    ## Click to Learn Which Modules Needed for R Language\n    -   Where <mark>Line 8</mark> loaded all required modules:\n        -   `gcc` and `mkl` are required for R package installation (Note: To the date, `gcc/11.2.1` is the latest version of `gcc` than can compile the `cmdstanr` successfully). Please see [here](https://hpcwiki.uark.edu/doku.php?id=r) for more details.\n        -   `Rscript` is the bash command to execute R file on HPC. `HelloWorld/example.R` is the path of your R script.\n        -   Anything behind the `#SBATCH` are options for the SLURM scheduler. Please see following summary or view [it](https://slurm.schedmd.com/pdfs/summary.pdf) online.\n    \n    ::::\n\n3.  **Last but not least**, we may want to use R interactively to test your R code is running well. Use the following bash command to start a new R session in terminal:\n\n    ::: {.callout-note}\n    ## New Interactive Node for Testing\n    ```bash \n    srun -N1 -n1 -c1 -p cloud72 -q cloud -t 2:00:00 --pty /bin/bash\n    ```\n    \n    This command will redirect to `cloud72` queue, which includes virtual machines and containers, usually single processor, 72 hour limit, 3 nodes.\n    :::\n\n4.  To show the whole picture, the whole workflow of one job submission is as follows. `$` represents the bash command line.\n\n    ``` bash\n    $ cat exampleJob.sh\n    #!/bin/bash\n    #SBATCH --nodes=1\n    #SBATCH --tasks-per-node=2\n    #SBATCH --job-name=Exp0\n    module purge\n    module load os/el7 gcc/9.3.1 mkl/19.0.5 R/4.2.2\n    cd $SLURM_SUBMIT_DIR\n    Rscript example.R\n    $ rm slurm-334001.out\n    $ sbatch exampleJob.sh\n    Submitted batch job 334002\n    $ ls\n    exampleJob.sh  example.R  gene_up.txt  MS_entrez_id_alldata.txt  slurm-334002.out\n    ```\n\n\n\n### Multiple Job Submission for R\n\n-   For R programming, if we want to submit multiple jobs iterating over data files (**each job runs a data analysis using one data file**). Then, one easiest way is to create a `masterJob.R` file that can\n\n    -   create multiple bash job submission file with filenames containing their job ID (`.sh` or `.slurm`)\n\n    -   submit those job files iteratively using `for` loop and `sbatch`.\n\n-   Following is one example of how to submit and run multiple data analysis jobs on HPC using `162`th to `240`th data files. Note that `#SBATCH --output=/home/jzhang/BSEM/OutputFiles/himem72-%j.out` redirect output files (`.out`) to the user-specified directory (which is BSEM/OutputFiles in this case). `%j` will append Job ID to the filenames of output files.\n\n\n\n::: {.cell filename='masterjob.R'}\n\n```{.r .cell-code  code-fold=\"false\"}\nlibrary(tidyverse)\nroot_path = \"/home/jzhang/\"\nfor (i in 162:240) { # <1>\n  jobfile <- paste0(\"Analysis_ModelA_DivergentSV\", i, \".sh\") # change file for specific model\n  ## --ntasks-per-node=6 : there are 6 R files to be running parallels.\n  ## --cpus-per-task=3: for each R files, there are 3 chains\n  initial <- \"#!/bin/bash\n#SBATCH --job-name=himem72\n#SBATCH --output=/home/jzhang/BSEM/OutputFiles/himem72-%j.out\n#SBATCH --partition himem72\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1     # adjust this if you want to use multiple threads\n#SBATCH --cpus-per-task=3       # adjust this if you are using parallel commands\n#SBATCH --time=72:00:00         # adjust this if you want to request more running time\n#SBATCH --mem=1000              # adjust this according to the memory requirement per node you need\n#SBATCH --mail-user=YOUR-EMAIL  # adjust this to match your email address\n#SBATCH --mail-type=ALL\n  \nsource /etc/profile.d/modules.sh\nmodule purge\nmodule load intel/21.2.0 mkl/21.3.0 R/4.2.2 gcc/11.2.1\ncd $SLURM_SUBMIT_DIR\n  \"\n  ## adding all R files simultaneously\n  jobfile_content <- paste0(initial,\n                            paste0(\"\\nRscript \", root_path,\"BSEM/Rcode/Analysis_ModelA_DivergentSV.R \"),\n                            i, \" '\" , root_path, \"'\")\n  write_lines(jobfile_content, file = paste0(root_path, \"BSEM/JobFiles/\", jobfile))\n  # message(commd)\n  system(paste0(\"sbatch \", paste0(root_path, \"BSEM/JobFiles/\", jobfile)))\n}\n```\n:::\n\n\n\nAlternatively, you can use array jobs for similar jobs submission. See more details in [slurm wiki](https://slurm.schedmd.com/job_array.html).\n\n``` bash\n# Submit a job array with index values between 0 and 31\n$ sbatch --array=0-31    -N1 tmp\n\n# Submit a job array with index values of 1, 3, 5 and 7\n$ sbatch --array=1,3,5,7 -N1 tmp\n\n# Submit a job array with index values between 1 and 7\n# with a step size of 2 (i.e. 1, 3, 5 and 7)\n$ sbatch --array=1-7:2   -N1 tmp\n```\n\nJob arrays will have additional environment variables set.\n\n-   **SLURM_ARRAY_JOB_ID** will be set to the first job ID of the array.\n-   **SLURM_ARRAY_TASK_ID** will be set to the job array index value.\n-   **SLURM_ARRAY_TASK_COUNT** will be set to the number of tasks in the job array.\n-   **SLURM_ARRAY_TASK_MAX** will be set to the highest job array index value.\n-   **SLURM_ARRAY_TASK_MIN** will be set to the lowest job array index value.\n\n## Cancel job\n\nUse `scancle [jobID]` to cancel one running job or `scancle jobID1,jobID2` to cancel multiple running jobs.\n\n## Checking job\n\n### `sinfo` command: Look up available resources\n\n-   When logged in the **computing node** or **login node**, type in `hostname` will output your computational node's name.\n\n-   One node has 32 cores, use `sinfo` to check:\n\n    -   `alloc` means it has been occupied; `idle` means it is available.\n\n### `squeue` command: Check running jobs\n\n`squeue` can check jobs that are running or pending. Below shows the information of all running/down task for the queue `comp06` (there are 9 Jobs but only 7 are running). Note that comp06 and comp72 queues share the same nodes, both belonging to pinnacle cluster. There are 49 public standard compute nodes. Thus, if there are 49 running jobs in both queues, then your job has to be waitting until some jobs finished.\n\nFor example, below shows all 47 running jobs in comp06/comp72 queues. Some have been running like 2 days. There are 72 hours limit though for all computation nodes.\n\n``` bash\n$ squeue -p comp06,comp72 -t R -u jzhang\n JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n 362406    comp06    measr   jzhang  R    1:04:24      1 c1501\n 362385    comp06 sys/dash ashmitau  R    2:07:25      1 c1402\n 362309    comp06 sys/dash    igorf  R    4:14:32      1 c1402\n 362361    comp06 03a_iqtr amatthew  R      55:02      1 c1420\n 362311    comp06  mystery cdgoolsb  R    4:09:10      1 c1410\n 362310    comp06  mystery cdgoolsb  R    4:09:40      1 c1410\n 362308    comp06  mystery cdgoolsb  R    4:14:41      1 c1410\n 362454    comp72 test_str pradeepk  R      11:03      1 c1512\n 362150    comp72   cv0_rf    igorf  R 1-00:43:47      1 c1410\n 362151    comp72   cv1_rf    igorf  R 1-00:43:47      1 c1410\n 362152    comp72   cv2_rf    igorf  R 1-00:43:47      1 c1410\n 362137    comp72 sys/dash maghamoh  R 1-03:12:27      1 c1410\n 362340    comp72  cv1_pls    igorf  R    1:00:24      1 c1512\n 362341    comp72  cv2_pls    igorf  R    1:00:24      1 c1512\n 362339    comp72  cv0_pls    igorf  R    1:04:24      1 c1501\n 360997    comp72  TiS2-ph bothinah  R 2-04:46:42      1 c1609\n 360877    comp72 Temp_230 sppoudel  R      54:55      1 c1419\n 360875    comp72 Temp_220 sppoudel  R    6:19:42      1 c1415\n 360876    comp72 Temp_225 sppoudel  R    6:19:42      1 c1509\n 354260    comp72 peep19-0   djo001  R   11:27:37      1 c1506\n 354262    comp72 peep20-0   djo001  R   11:27:37      1 c1514\n 354263    comp72 peep21-0   djo001  R   11:27:37      1 c1515\n 351991    comp72 peep16-0   djo001  R   12:31:45      1 c1507\n 351988    comp72 peep18-2   djo001  R   14:00:48      1 c1603\n 351987    comp72 peep17-2   djo001  R   14:07:24      1 c1519\n 360873    comp72 Temp_210 sppoudel  R   14:49:25      1 c1408\n 360874    comp72 Temp_215 sppoudel  R   14:49:25      1 c1418\n 351989    comp72 peep18-0   djo001  R   14:49:55      1 c1516\n 351990    comp72 peep17-0   djo001  R   14:49:55      1 c1518\n 351986    comp72 peep16-2   djo001  R   15:36:01      1 c1605\n 360824    comp72 SmNiO3-2 paillard  R   16:23:51      4 c[1405-1406,1503,1508]\n 360871    comp72 Temp_205 sppoudel  R   16:23:51      1 c1511\n 360821    comp72 SmNiO3-2 paillard  R 1-01:41:15      4 c[1412-1413,1513,1517]\n 360869    comp72 Temp_200 sppoudel  R 1-01:41:15      1 c1606\n 360868    comp72 Temp_195 sppoudel  R 1-14:30:28      1 c1504\n 349719    comp72  peep8-2   djo001  R 1-16:02:28      1 c1608\n 360867    comp72 Temp_190 sppoudel  R 1-20:18:00      1 c1610\n 360818    comp72 SmNiO3-2 paillard  R 1-20:18:01      4 c[1404,1409,1502,1505]\n 360866    comp72 Temp_180 sppoudel  R 2-04:52:43      1 c1411\n 349718    comp72  peep9-2   djo001  R 2-05:37:18      1 c1604\n 349717    comp72 peep10-2   djo001  R 2-05:51:48      1 c1520\n 349715    comp72 peep12-2   djo001  R 2-09:11:29      1 c1417\n 349716    comp72 peep11-2   djo001  R 2-09:11:29      1 c1607\n 349714    comp72 peep13-2   djo001  R 2-09:30:18      1 c1510\n 338160    comp72 INT3-WT- dgirodat  R 2-10:20:18      1 c1407\n 338164    comp72 C1069T-p dgirodat  R 2-10:20:18      1 c1414\n```\n\nWhen you want to get the worst case scenario estimate of when your waiting jobs will start, you can always run following command,\n\n``` bash\nsqueue -u [loginname] --start\n```\n\n::: callout-note\n## More advanced filtering\n\nUse `squeue -u [username] | awk '{print $1}' | grep -v JOBID` to list all jobs Then, use `scancel 'squeue -u [username] | awk '{print $1}' | grep -v JOBID'` to cancel multiple running jobs with given JobIDs\n:::\n\n### `sacct` command: Check job history\n\n`sacct` can check your job history\n\n``` bash\n$ sacct --format Jobid,ReqMem,MaxRSS,TimeLimit,AllocCPUS,CPUTIME,TotalCPU\nJobID            ReqMem     MaxRSS  Timelimit  AllocCPUS    CPUTime   TotalCPU\n------------ ---------- ---------- ---------- ---------- ---------- ----------\n466693             192M              02:00:00          1   02:00:25  08:17.128\n466693.0                  7018740K                     1   02:00:55  08:17.128\n466694              64M            12-00:00:+          3   00:00:15  00:03.511\n466694.batch                                           3   00:00:15  00:03.511\n466752              64M            12-00:00:+          3   00:07:15  05:11.966\n466752.batch              1720012K                     3   00:07:15  05:11.966\n466756              64M            12-00:00:+          3   14:57:42   05:26:19\n466756.batch              2230252K                     3   14:57:42   05:26:19\n466758              64M            12-00:00:+          3   15:35:27   00:00:00\n```\n\n1.  JobID - Job ID . Step ID of the job step\n2.  ReqMem - Requested memory (Gc: GigaByte per core)\n3.  MaxRSS - Actually-used memory (Resident Set Size)\n4.  Timelimit - Time limit requested for the job with `--time`\n5.  Elapsed - Actual time used by the job\n6.  AllocCPUs - Number of allocated CPUs to the job\n7.  CPUTime - CPUtime allocated to the job (Elapsed \\* AllocCPUs)\n8.  TotalCPU - Actual CPU time consumed by the job\n\nMost frequently used queues are from `pinnacle` cluster.\n\nBelow is a list of queues in the `pinnacle` cluster. The number after the queue is the time limit for a running job. For example, `comp72` has 72 hour limits while `comp06` has only 6 hour limit, but they share same nodes. Thus, for efficiency, maybe use `comp01` for quick examination of coding and use `comp72` for time consuming jobs.\n\n``` bash\ncomp72/06/01: standard compute nodes, 72/6/1 hour limit, 42/46/48 nodes\ngpu72/06:     gpu nodes: 72/6 hour limit, 19 nodes\nagpu72/06:    a100 gpu nodes: 72/6 hour limit\nhimem72/06:   768 GB nodes, 72/6 hour limit, 6 nodes\npubcondo06:   condo nodes all-user use, 6 hour limit, various constraints required, 25 nodes\npcon06:       same as pubcondo06, shortened name for easier printout, use this going forward\ncloud72:      virtual machines and containers, usually single processor, 72 hour limit, 3 nodes\ncondo:        condo nodes, no time limit, authorization required, various constraints required, 25 nodes\ntres72/06:    reimaged trestles nodes, 72/06 hour limit, 126 nodes\nrazr72/06:    reimaged razor nodes, 72 hour limit, in progress\n```\n\nHere's some useful information regarding selecting queue from [hpcwiki](https://hpcwiki.uark.edu/doku.php?id=pinnacle_usage).\n\n> Generally the nodes are reserved for the most efficient use, especially for expensive features such as GPU and extra memory. Pinnacle compute nodes are very busy (comp.. and himem.. partitions) are reserved for scalable programs that can use all 32/24 cores (except for the cloud partition, and condo usage by the owner). Cores are allocated by the product of ntasks-per-node x cpus-per-task. Exceptions: (1) serial/single core jobs that use more memory than available on Razor/Trestles (64 to 192 GB) (2) multiple jobs submitted together that use a whole node, such as 4 x 8 cores (3) two jobs on one high-memory node (2 x 12 cores) that each use more than 192 GB (and less than 384 GB so that they can run on the himem node)\n\n### Count running jobs\n\nFollowing bash command is a general command to cound running jobs on himem72 queue. `-p himem72` filters jobs running on the partition `himem72`. `-t R` filters the \"running\" status (other status include 'PD' which means pending). `wc` is a bash command to count number of lines/bytes.\n\nYou can check running jobs for multiple users. For example, `squeue -t R -u user1,user2 | wc` counts user1's and user2's running jobs.\n\n``` bash\nsqueue -u jzhang -t R -p himem72 | wc\n```\n\n## Troubleshooting\n\n1.  Revise `.bashrc` so that the ssh cannot login?\n\n    You potential can try `ctrl+c` to avoid the ssh to execute bashrc. Try multiple time if not succeed. See [here](https://serverfault.com/questions/206544/i-screwed-up-exit-in-bashrc) for reference.\n\n## Example 1: parallelization of Stan\n\nLet's assume we have a job task to run multiple Bayesian models with ***K*** Markov Chains. For each Bayesian model, we have an independent R file. In total, we have ***J*** .R modeling files. For each independent R file, we input one data set. There are ***N*** data sets in total with multiple simulation conditions.\n\nThe workflow for this job task is like this:\n\n![Workflow for HPC Job](Workflow.png){.preview-image fig-align=\"center\"}\n\n### Overall Procedure\n\nFirst of all, we need to create a `masterJob.R` file[^1] with two main aims: (1) to create multiple bash job files with each corresponds to run one or multiple analysis models; (2) to submit the data analysis job to the computing server. In `masterJob.R`, there may exist nested \"[*for loop*]{.underline}\" with datasets/design factors as iterators.\n\n[^1]: which could be replaced as bash file if you are more familiar with bash language\n\nFor example, below is an example `masterJob.R` file. Iterator `i` represents the index of data set.\n\n\n\n::: {.cell filename='masterjob_All.R'}\n\n```{.r .cell-code  code-fold=\"false\" code-line-numbers=\"true\"}\nlibrary(tidyverse)\nroot_path = \"~/Downloads/JZ/\" # change to folder in your HPC\nfor (i in 1:10) {\n  jobfile <- paste0(\"AllModelRunning_data\", i, \".sh\")\n  ## --ntasks-per-node=6 : there are 6 R files to be running parallels.\n  ## --cpus-per-task=3: for each R files, there are 3 chains\n  initial <- \"#!/bin/bash\n#SBATCH --partition tres288\n#SBATCH --qos tres\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=6\n#SBATCH --cpus-per-task=4\n#SBATCH --time=288:00:00\n\nsource /etc/profile.d/modules.sh\nmodule purge\nmodule load intel/21.2.0 mkl/21.3.0 R/4.2.2 gcc/11.2.1\ncd $SLURM_SUBMIT_DIR\n  \"\n  ## adding all R files simultaneously\n  jobfile_content <- paste0(initial,         paste0(\"\\nRscript \", root_path,\"RcodeJZ2/Analysis_ModelA_AlignedSV_asym1000.R \"), i, \" '\" , root_path, \"' | at now &\")\n  jobfile_content <- paste0(jobfile_content, paste0(\"\\nRscript \", root_path,\"RcodeJZ2/Analysis_ModelA_AlignedSV_sym1000.R \"), i, \" '\" , root_path, \"' | at now &\")\n  jobfile_content <- paste0(jobfile_content, paste0(\"\\nRscript \", root_path,\"RcodeJZ2/Analysis_ModelA_Diffuse_asym500.R \"), i, \" '\", root_path, \"' | at now &\")\n  jobfile_content <- paste0(jobfile_content, paste0(\"\\nRscript \", root_path,\"RcodeJZ2/Analysis_ModelA_Diffuse_sym500.R \"), i, \" '\", root_path, \"' | at now &\")\n  jobfile_content <- paste0(jobfile_content, paste0(\"\\nRscript \", root_path,\"RcodeJZ2/Analysis_ModelA_DivergentSV_asym100.R \"), i, \" '\", root_path, \"' | at now &\")\n  jobfile_content <- paste0(jobfile_content, paste0(\"\\nRscript \", root_path,\"RcodeJZ2/Analysis_ModelA_DivergentSV_sym100.R \"), i, \" '\", root_path, \"' | at now & wait\")\n  write_lines(jobfile_content, file = paste0(root_path, \"JobFiles/\", jobfile))\n  # message(commd)\n  system(paste0(\"sbatch \", paste0(root_path, \"JobFiles/\", jobfile)))\n}\n```\n:::\n\n\n\nIf we want to iterate over all N data sets, we can set `for (i in 1:N)`. The `initial` partical contains the settings of HPC jobs: 1 node, each node run 6 tasks, and each task uses 4 cpus. If we run a Bayesian model with 3 chains, we can set `--cpus-per-task=3` instead. Each modeling file (for example, *Analysis_ModelA_AlignedSV_asym1000.R*) will be subjected to run using `Rscript` with two arguments: (1) data set index (i); (2) root directory containing all codes and data sets (root_path). The first argument make sure each file will be fed to modeling file. The second argument makes the masterJob file more generic to run on varied HPC accounts.\n\n`write_lines` function saves the text of job file into a local directory in root direcotry â€“ JobFile. `system` is a R function that can run bash code in R. Here we echo `sbatch [OneJobFile].R` to make R automatically submit the JobFile for specific data set.\n\nAlternatively, we can set up the masterJob file to run one model only:\n\n\n\n::: {.cell filename='masterJob_AlignsedSV_asym100.R'}\n\n```{.r .cell-code  code-fold=\"false\" code-line-numbers=\"true\"}\nlibrary(tidyverse)\nroot_path = \"~/Downloads/JZ/\"\nfor (i in 1:10) {\n  jobfile <- paste0(\"AlignsedSV_asym100_ModelRunning_data\", i, \".sh\") # change file for specific model\n  ## --ntasks-per-node=6 : there are 6 R files to be running parallels.\n  ## --cpus-per-task=3: for each R files, there are 3 chains\n  initial <- \"#!/bin/bash\n#SBATCH --partition tres288\n#SBATCH --qos tres\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=6\n#SBATCH --cpus-per-task=4\n#SBATCH --time=288:00:00\n\nsource /etc/profile.d/modules.sh\nmodule purge\nmodule load intel/21.2.0 mkl/21.3.0 R/4.2.2 gcc/11.2.1\ncd $SLURM_SUBMIT_DIR\n  \"\n  ## adding all R files simultaneously\n  jobfile_content <- paste0(initial,  \n                            paste0(\"\\nRscript \", root_path,\"RcodeJZ2/Analysis_ModelA_AlignedSV_asym1000.R \"), \n                            i, \" '\" , root_path, \"'\")\n  write_lines(jobfile_content, file = paste0(root_path, \"JobFiles/\", jobfile))\n  # message(commd)\n  system(paste0(\"sbatch \", paste0(root_path, \"JobFiles/\", jobfile)))\n}\n```\n:::\n\n\n\nTo make sure it running without error, we need to check each modeling file carefully.\n\nFor example, below is one of six modeling files: *Analysis_ModelA_AlignedSV_sym1000.R.*\n\nPart I of this modeling file is to read in two arguments of `Rscript` specified in *masterJob_All.R*. Part II contains all functions needed for Bayesian models running. Part III screens all data sets saved in the folder `dataJZ` and creates a vector of paths of the data set `dataset_fullpaths`. It also creates a list of unique identifiers for each result of model `datset_prefix`. Finally, it run the Bayesian model with 3 Markov chains.\n\n\n\n::: {.cell filename='Analysis_ModelA_AlignedSV_sym1000.R'}\n\n```{.r .cell-code  code-fold=\"false\" code-line-numbers=\"true\"}\n#########################################\n###### Part I \n#########################################\nargs <- commandArgs(trailingOnly = TRUE)\nwhich_dat <- as.numeric(args[1])\nroot_path = as.character(args[2]) # root directory\n\n#########################################\n###### Part II \n#########################################\n## function 1: for one Bayesian model running\nBayAna <- function(mod, dat, ncores) {...}\n## function 2: run four Bayesian models with different model structure and save results\nBayFit_new <- function(dname, ncores, outputpath, prefix){...}\n\n#########################################\n###### Part III \n#########################################\ndatset_paths <- list.files(paste0(root_path, \"dataJZ/\"), pattern = '.dat',recursive = TRUE)\ndatset_fullpaths <- paste0(paste0(root_path, \"dataJZ/\"), datset_paths)\ndatset_prefix <- stringr::str_replace_all(datset_paths, \"/\", \"_\")\n\nBayFit_new(dname = datset_fullpaths[which_dat],\n           outputpath = paste0(root_path, \"ResultJZ/\"),\n           prefix = datset_prefix[which_dat],\n           ncores = 3)\n```\n:::\n\n\n\nFor better illustration, below is the top 10 elements of `datset_fullpaths` :\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroot_path = \"~/Library/CloudStorage/OneDrive-Personal/2024 Spring/Ejike Bayesian Modeling on HPC/JZ/\"\ndatset_paths <- list.files(paste0(root_path, \"dataJZ/\"), pattern = '.dat',recursive = TRUE)\ndatset_fullpaths <- paste0(paste0(root_path, \"dataJZ/\"), datset_paths)\nhead(datset_fullpaths)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"~/Library/CloudStorage/OneDrive-Personal/2024 Spring/Ejike Bayesian Modeling on HPC/JZ/dataJZ/\"\n```\n\n\n:::\n:::\n\n\n\n### Brief Workflow\n\n[Procedure of Data Analysis on HPC.pdf](Procedure%20of%20Data%20Analysis%20on%20HPC.pdf)\n\n## Resources\n\n1.  `rslurm` package: [Parallelize R code on a Slurm cluster](https://cran.r-project.org/web/packages/rslurm/vignettes/rslurm.html#how-it-works-advanced-customization)\n2.  [CRAN Task View: High-Performance and Parallel Computing with R](https://cran.r-project.org/web/views/HighPerformanceComputing.html)\n3.  Linux 101: <https://github.com/erolrecep/GettingStartedwithAHPCC>\n4.  [New Mexico State University HPC Wiki](https://hpc.nmsu.edu/discovery/slurm/)\n5.  [Slurm Official Documentation](https://slurm.schedmd.com/documentation.html)\n6.  [University of Arkansas HPC Center Wiki](https://hpcwiki.uark.edu/doku.php?id=pinnacle_usage) (not very useful and outdated)\n7.  [Slides fo Jobs Submission in Slurms by Damien Francios](https://indico.cism.ucl.ac.be/event/121/contributions/60/attachments/130/287/slurm2022.pdf)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}