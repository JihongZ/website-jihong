{
  "hash": "25d050d498bfa195c27f2cca442ea007",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: 'Network analysis estimation for application research'\nsubtitle: 'Compare multiple R packages for psychological network analysis'\ndate: 'April 4 2024'\ncategories:\n  - R\n  - Bayesian\n  - Tutorial\n  - Network Analysis\nexecute: \n  eval: true\n  echo: true\n  warning: false\nformat: \n  html: \n    code-fold: true\n    code-summary: 'Click to see the code'\n    toc-location: left\nbibliography: references.bib\ncsl: apa.csl\n---\n\n\n\n\n# Background\n\nMultiple estimation methods for network analysis have been proposed, from regularized to unregularized, from frequentist to Bayesian approach, from one-step to multiple steps.\n@isvoranuWhichEstimationMethod2023a provides an throughout illustration of current network estimation methods and simulation study.\nThis post tries to reproduce the procedures and coding illustrated by the paper and compare the results for packages with up-to-date version.\nFive packages will be used for network modeling: (1) `qgraph`, (2)`psychonetrics`, (3)`MGM`, (4)`BGGM`, (5)`GGMnonreg`.\nNote that the tutorial of each R package is not the scope of this post.\nThe specific variants of estimation is described in @fig-usedestimation.\nPlease see [here](../2024-03-05-Bayesian-GGM/index.qmd) for `BGGM` R package for more detailed example.\n\n![Estimation methods used in Isvoranu and Epskamp (2023)](estimation_methods_table.png){#fig-usedestimation fig-align=\"center\"}\n\n# Simulation Study 1\n## Data Generation\n\nFor the sake of simplicity, I will only pick one condition from the simulation settings.\nTo simulate data, I used the same code from the paper.\nThe function is a wrapper of `bootnet::ggmGenerator` function\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"dataGenerator() function\"}\nlibrary(\"bootnet\")\ndataGenerator <- function(\n  trueNet,  # true network models: DASS21, PTSD, BFI\n  sampleSize, # sample size\n  data = c(\"normal\",\"skewed\",\"uniform ordered\",\"skewed ordered\"), # type of data\n  nLevels = 4,\n  missing = 0\n){\n  data <- match.arg(data)\n  nNode <- ncol(trueNet)\n  \n  if (data == \"normal\" || data == \"skewed\"){\n    # Generator function:\n    gen <- ggmGenerator()\n    \n    # Generate data:\n    Data <- gen(sampleSize,trueNet)\n    \n    # Generate replication data:\n    Data2 <- gen(sampleSize,trueNet)\n    \n    if (data == \"skewed\"){ ## exponential transformation to make data skewed\n      for (i in 1:ncol(trueNet)){\n        Data[,i] <- exp(Data[,i])\n        Data2[,i] <- exp(Data2[,i])\n      }\n    }\n  \n  } else {\n    # Skew factor:\n    skewFactor <- switch(data,\n                         \"uniform ordered\" = 1,\n                         \"skewed ordered\" = 2,\n                         \"very skewed ordered\" = 4)\n    \n    # Generator function:\n    gen <- ggmGenerator(ordinal = TRUE, nLevels = nLevels)\n    \n    # Make thresholds:\n    thresholds <- lapply(seq_len(nNode),function(x)qnorm(seq(0,1,length=nLevels + 1)[-c(1,nLevels+1)]^(1/skewFactor)))\n    \n    # Generate data:\n    Data <- gen(sampleSize, list(\n      graph = trueNet,\n      thresholds = thresholds\n    ))\n    \n    # Generate replication data:\n    Data2 <- gen(sampleSize, list(\n      graph = trueNet,\n      thresholds = thresholds\n    ))\n  }\n  \n  # Add missings:\n  if (missing > 0){\n    for (i in 1:ncol(Data)){\n      Data[runif(sampleSize) < missing,i] <- NA\n      Data2[runif(sampleSize) < missing,i] <- NA\n    }\n  }\n  \n  return(list(\n    data1 = Data,\n    data2 = Data2\n  ))\n}\n```\n:::\n\n\n\n\nBFI contains 26 columns: first columns are the precision matrix with 25 $\\times$ 25 and second columns as clusters.\nWe will use the structure of BFI for the simulation.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(here)\nbfi_truenetwork <- read.csv(here(\"notes\", \"2024\", \"2024-04-04-Network-Estimation-Methods\", \n                                 \"weights matrices\", \"BFI.csv\"))\nbfi_truenetwork <- bfi_truenetwork[,1:25]\nhead(psychTools::bfi)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      A1 A2 A3 A4 A5 C1 C2 C3 C4 C5 E1 E2 E3 E4 E5 N1 N2 N3 N4 N5 O1 O2 O3 O4\n61617  2  4  3  4  4  2  3  3  4  4  3  3  3  4  4  3  4  2  2  3  3  6  3  4\n61618  2  4  5  2  5  5  4  4  3  4  1  1  6  4  3  3  3  3  5  5  4  2  4  3\n61620  5  4  5  4  4  4  5  4  2  5  2  4  4  4  5  4  5  4  2  3  4  2  5  5\n61621  4  4  6  5  5  4  4  3  5  5  5  3  4  4  4  2  5  2  4  1  3  3  4  3\n61622  2  3  3  4  5  4  4  5  3  2  2  2  5  4  5  2  3  4  4  3  3  3  4  3\n61623  6  6  5  6  5  6  6  6  1  3  2  1  6  5  6  3  5  2  2  3  4  3  5  6\n      O5 gender education age\n61617  3      1        NA  16\n61618  3      2        NA  18\n61620  2      2        NA  17\n61621  5      2        NA  17\n61622  3      1        NA  17\n61623  1      2         3  21\n```\n\n\n:::\n:::\n\n\n\n\nTo generate data from `bootnet::ggmGenerator()`, we can generate a function `gen` from it with first argument as sample size and second argument as partial correlation matrix.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\ngen <- bootnet::ggmGenerator()\ndata <- gen(2800, as.matrix(bfi_truenetwork))\n```\n:::\n\n\n\n\n## Measures\n\n### Overview of Centrality Measures\n\nCentrality measures are used as one characteristic of network model to summarize the importance of nodes/items given a network.\nSome ideas of centrality measures come from social network.\nSome may not make much sense in psychometric network.\nI also listed the centrality measures that have been used in literatures of psychological or psychometric modeling.\nFollowing the terminology of @christensen2018, centrality measures include: (1) betweenness centrality (BC); (2) the randomized shortest paths betweeness centrality (RSPBC); (3) closeness centrality (CC); (4)node degree (ND); (5) node strength (NS); (6) expected influence (EI); (7) engenvector centrality (EC); (8) Eccentricity (*k;* @hage1995); (9) hybrid centrality (HC; @christensen2018a).\n\nThey can be grouped into three categories:\n\n[*Type 1*]{.underline}—Number of path relevant metrics: BC measures how often a node is on the shortest path from one node to another.\nRSPBC is a adjusted BC measure which measures how oftern a node is on the random shortest path from one to another; CC measures the average number of paths from one node to all other nodes in the network.\nND measures how many connections are connected to each node.\nEccentricity (*k*) measures the maximum \"distance\" between one node with other nodes with lower values suggests higher centrality, where one node's distance is the length of a shortest path between this node to other nodes.\n\n[*Type 2*]{.underline}—Path strength relevant metrics: **NS** measures the sum of the absolute values of edge weights connected to a single node.\n**EI** measures the sum of the positive or negative values of edge weights connected to a single node.\n\n[*Type 3*]{.underline}—Composite of multiple centrality measures: **HC** measures nodes on the basis of their centrality values across multiple measures of centrality (BC, LC, *k*, EC, and NS) which describes highly central nodes with large values and highly peripheral nodes with small values [@christensen2018b].\n\nSome literature of network psychometrics criticized the use of Type 1 centrality measures and some Type II centrality measures [@hallquist2021; @neal2022].\nFor example, @hallquist2021 argued that some Type I centrality measures such as BC and CC derive from the concept of distance, which builds on the physical nature of many traditional graph theory applications, including railways and compute networks.\nIn association networks, the idea of network distance does not have physical reference.\n@bringmann2019 also think distance-based centrality like closeness centrality (CC) and betweenness centrality (BC) do not have \"shortest path\", or \"node exchangeability\" assumptions in psychological networks so they are not suitable in the context of psychological network.\nIn addition, ND (degree), CC (closeness), and BC (betweenness) do not take negative values of edge weights into account that may lose important information in the context of psychology.\n\n### Network level accuracy metrics\n\nStructure accuracy measures such as *sensitivity*, specificity, and precision investigate if an true edge is include or not or an false edge is include or not.\nSeveral edge weight accuracy measures include: (1) correlation between absolute values of estimated edge weights and true edge weights, (2) average absolute bias between estimated edge weights and true weights, (3) average absolute bias for true edges.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor0 <- function(x,y,...){\n  if (sum(!is.na(x)) < 2 || sum(!is.na(y)) < 2 || sd(x,na.rm=TRUE)==0 | sd(y,na.rm=TRUE) == 0){\n    return(0)\n  } else {\n    return(cor(x,y,...))\n  }\n}\n\nbias <- function(x,y) mean(abs(x-y),na.rm=TRUE)\n\n\n### Inner function:\ncomparison_metrics <- function(real, est, name = \"full\"){\n  \n  # Output list:\n  out <- list()\n  \n  # True positives:\n  TruePos <- sum(est != 0 &  real != 0)\n  \n  # False pos:\n  FalsePos <- sum(est != 0 & real == 0)\n  \n  # True Neg:\n  TrueNeg <- sum(est == 0 & real == 0)\n  \n  # False Neg:\n  FalseNeg <- sum(est == 0 & real != 0)\n  \n  # Sensitivity:\n  out$sensitivity <- TruePos / (TruePos + FalseNeg)\n  \n  # Sensitivity top 50%:\n  top50 <- which(abs(real) > median(abs(real[real!=0])))\n  out[[\"sensitivity_top50\"]] <- sum(est[top50]!=0 & real[top50] != 0) / sum(real[top50] != 0)\n  \n  # Sensitivity top 25%:\n  top25 <- which(abs(real) > quantile(abs(real[real!=0]), 0.75))\n  out[[\"sensitivity_top25\"]] <- sum(est[top25]!=0 & real[top25] != 0) / sum(real[top25] != 0)\n  \n  # Sensitivity top 10%:\n  top10 <- which(abs(real) > quantile(abs(real[real!=0]), 0.90))\n  out[[\"sensitivity_top10\"]] <- sum(est[top10]!=0 & real[top10] != 0) / sum(real[top10] != 0)\n  \n  # Specificity:\n  out$specificity <- TrueNeg / (TrueNeg + FalsePos)\n  \n  # Precision (1 - FDR):\n  out$precision <- TruePos / (FalsePos + TruePos)\n  \n  # precision top 50% (of estimated edges):\n  top50 <- which(abs(est) > median(abs(est[est!=0])))\n  out[[\"precision_top50\"]] <- sum(est[top50]!=0 & real[top50] != 0) / sum(est[top50] != 0)\n  \n  # precision top 25%:\n  top25 <- which(abs(est) > quantile(abs(est[est!=0]), 0.75))\n  out[[\"precision_top25\"]] <- sum(est[top25]!=0 & real[top25] != 0) / sum(est[top25] != 0)\n  \n  # precision top 10%:\n  top10 <- which(abs(est) > quantile(abs(est[est!=0]), 0.90))\n  out[[\"precision_top10\"]] <- sum(est[top10]!=0 & real[top10] != 0) / sum(est[top10] != 0)\n  \n  # Signed sensitivity:\n  TruePos_signed <- sum(est != 0 &  real != 0 & sign(est) == sign(real))\n  out$sensitivity_signed <- TruePos_signed / (TruePos + FalseNeg)\n  \n  # Correlation:\n  out$correlation <- cor0(est,real)\n  \n  # Correlation between absolute edges:\n  out$abs_cor <- cor0(abs(est),abs(real))\n  \n  #\n  out$bias <- bias(est,real)\n  \n  ## Some measures for true edges only:\n  if (TruePos > 0){\n    \n    trueEdges <- est != 0 & real != 0\n    \n    out$bias_true_edges <- bias(est[trueEdges],real[trueEdges])\n    out$abs_cor_true_edges <- cor0(abs(est[trueEdges]),abs(real[trueEdges]))\n  } else {\n    out$bias_true_edges <- NA\n    out$abs_cor_true_edges <- NA\n  }\n  \n  out$truePos <- TruePos\n  out$falsePos <- FalsePos\n  out$trueNeg <- TrueNeg\n  out$falseNeg <- FalseNeg\n  \n  # Mean absolute weight false positives:\n  false_edges <- (est != 0 &  real == 0) | (est != 0 & real != 0 & sign(est) != sign(real) )\n  out$mean_false_edge_weight <- mean(abs(est[false_edges]))\n  out$SD_false_edge_weight <- sd(abs(est[false_edges]))\n  \n  # Fading:\n  out$maxfade_false_edge <- max(abs(est[false_edges])) / max(abs(est))\n  out$meanfade_false_edge <- mean(abs(est[false_edges])) / max(abs(est))\n  \n  \n  # Set naname\n  if (name != \"\"){\n    names(out) <- paste0(names(out),\"_\",name)  \n  }\n  out\n}\n```\n:::\n\n\n\n\n## Estimation\n \n::: {.panel-tabset}\n### Method 1 - EBICglasso in bootnet\n\nThis method uses the `bootnet::estimateNetwork` function.\n\n`EBICtuning <- 0.5` sets up the hyperparameter ($\\gamma$) as .5 that controls how much the EBIC prefers simpler models (fewer edges), which by default is .5.\n\n$$\n\\text{EBIC} =-2L+\\log(N)+4\\gamma \\log(P)\n$$\n\n$$\n\\text{AIC} = -2L + 2P\n$$\n\n$$\n\\text{BIC} = -2L + P\\log(N) \n$$\n\nAnother important setting is the tuning parameter ($\\lambda$) of EBICglasso that controls the sparsity level in the penalized likelihood function as:\n\n$$\n\\log \\det(\\boldsymbol{K}) - \\text{trace}(\\boldsymbol{SK})-\\lambda \\Sigma|\\kappa_{ij}|\n$$\n\nwhere $\\boldsymbol{S}$ represents the sample variance-covariance matrix and $\\boldsymbol{K}$ represents the precision matrix that *lasso* aims to estimate.\nOverall, the regularization limits the sum of absolute partial correlation coefficients.\n\n`sampleSize=\"pairwise_average\"` will set the sample size to the average of sample sizes used for each individual correlation in `EBICglasso`.\n\n@fig-bfi is the estimated network structure with BFI-25 data.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"Method 1: EBICglasso\"}\nlibrary(\"qgraph\")\nlibrary(\"bootnet\")\nsampleAdjust  <-  \"pairwise_average\"\nEBICtuning <- 0.5\ntransformation <- \"polychoric/categorical\" # EBICglasso use cor_auto\nres_m1 <- estimateNetwork(data, # input as polychoric correlation\n                          default = \"EBICglasso\",\n                          sampleSize = sampleAdjust,\n                          tuning = EBICtuning,\n                          corMethod = ifelse(transformation == \"polychoric/categorical\",\n                                             \"cor_auto\",\n                                             \"cor\"))\n    \nestnet_m1 <- res_m1$graph\nsummary(res_m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n=== Estimated network ===\nNumber of nodes: 25 \nNumber of non-zero edges: 154 / 300 \nMean weight: 0.02061227 \nNetwork stored in object$graph \n \nDefault set used: EBICglasso \n \nUse plot(object) to plot estimated network \nUse bootnet(object) to bootstrap edge weights and centrality indices \n\nRelevant references:\n\n \tFriedman, J. H., Hastie, T., & Tibshirani, R. (2008). Sparse inverse covariance estimation with the graphical lasso. Biostatistics, 9 (3), 432-441.\n\tFoygel, R., & Drton, M. (2010). Extended Bayesian information criteria for Gaussian graphical models. \n\tFriedman, J. H., Hastie, T., & Tibshirani, R. (2014). glasso: Graphical lasso estimation of gaussian graphical models. Retrieved from https://CRAN.R-project.org/package=glasso\n\tEpskamp, S., Cramer, A., Waldorp, L., Schmittmann, V. D., & Borsboom, D. (2012). qgraph: Network visualizations of relationships in psychometric data. Journal of Statistical Software, 48 (1), 1-18.\n\tEpskamp, S., Borsboom, D., & Fried, E. I. (2016). Estimating psychological networks and their accuracy: a tutorial paper. arXiv preprint, arXiv:1604.08462.\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"Method 1: EBICglasso\"}\nstr(res_m1$results)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nList of 5\n $ results:List of 5\n  ..$ w      : num [1:25, 1:25, 1:100] 1 -0.336 -0.239 -0.117 -0.166 ...\n  ..$ wi     : num [1:25, 1:25, 1:100] 1.20036 0.36019 0.12108 0 -0.00751 ...\n  ..$ approx : logi FALSE\n  ..$ rholist: num [1:100] 0.007 0.00733 0.00768 0.00805 0.00843 ...\n  ..$ errflag: int [1:100] 0 0 0 0 0 0 0 0 0 0 ...\n $ ebic   : num [1:100] 53796 53759 53736 53728 53677 ...\n $ optnet : num [1:25, 1:25] 0 -0.2471 -0.0836 0 0 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:25] \"V1\" \"V2\" \"V3\" \"V4\" ...\n  .. ..$ : chr [1:25] \"V1\" \"V2\" \"V3\" \"V4\" ...\n $ lambda : num [1:100] 0.007 0.00733 0.00768 0.00805 0.00843 ...\n $ optwi  : num [1:25, 1:25] 1.154 0.325 0.112 0 0 ...\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"Method 1: EBICglasso\"}\nEBIC = mean(res_m1$results$ebic) # EBIC of the final model\n(AIC = EBIC - 2 * log(nrow(data))) # AIC =  52287.32\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 56907.61\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"Method 1: EBICglasso\"}\nqgraph(estnet_m1)\n```\n\n::: {.cell-output-display}\n![Method 1: Network Plot for BFI-25 with EBICglasso](index_files/figure-html/fig-bfi-1.png){#fig-bfi width=288}\n:::\n:::\n\n\n\n\n\n### Method 2 - ggmModSelect in bootnet\n\nThe *ggmModSelect* algorithm is a non-regularized method.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"Method 2: ggmModSelect\"}\n# With stepwise\nres_m2_1 <- estimateNetwork(data, default = \"ggmModSelect\",\n                           sampleSize = sampleAdjust, stepwise = TRUE,\n                           tuning = EBICtuning,\n                           corMethod = ifelse(transformation == \"polychoric/categorical\",\n                                              \"cor_auto\",\n                                              \"cor\"))\n\nestnet_m2_1 <- res_m2_1$graph\nqgraph(estnet_m2_1)\n```\n\n::: {.cell-output-display}\n![Method 2.1: Network Plot for BFI-25 with ggmModSelect and Stepwise](index_files/figure-html/fig-m2_1-1.png){#fig-m2_1 width=288}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"Method 2: ggmModSelect\"}\n# Without stepwise\nres_m2_2 <- estimateNetwork(data, default = \"ggmModSelect\",\n                           sampleSize = sampleAdjust, stepwise = FALSE,\n                           tuning = EBICtuning,\n                           corMethod = ifelse(transformation == \"polychoric/categorical\",\n                                              \"cor_auto\",\n                                              \"cor\"))\nestnet_m2_2 <- res_m2_2$graph\nqgraph(estnet_m2_2)\n```\n\n::: {.cell-output-display}\n![Method 2.1: Network Plot for BFI-25 with ggmModSelect and No Stepwise](index_files/figure-html/fig-m2_2-1.png){#fig-m2_2 width=288}\n:::\n:::\n\n\n\n\n### Method 3 - FIML in psychonetrics\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"Method 3: FIML\"}\nlibrary(psychonetrics)\nlibrary(magrittr)\n# With stepwise\nres_m3_1 <- ggm(data, estimator = \"FIML\", standardize = \"z\") %>% \n  prune(alpha = .01, recursive = FALSE) \n    \nestnet_m3_1 <- getmatrix(res_m3_1, \"omega\")\nfit(res_m3_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           Measure     Value\n              logl -89279.05\n unrestricted.logl -89178.37\n     baseline.logl -99313.20\n              nvar        25\n              nobs       350\n              npar       159\n                df       191\n         objective     17.82\n             chisq    201.36\n            pvalue      0.29\n    baseline.chisq  20269.64\n     baseline.npar        50\n       baseline.df       300\n   baseline.pvalue       ~ 0\n               nfi      0.99\n              pnfi      0.63\n               tli       1.0\n              nnfi       1.0\n               rfi      0.98\n               ifi       1.0\n               rni       1.0\n               cfi       1.0\n             rmsea    0.0044\n    rmsea.ci.lower       ~ 0\n    rmsea.ci.upper    0.0095\n      rmsea.pvalue         1\n            aic.ll 178876.11\n           aic.ll2 178895.38\n             aic.x   -180.64\n            aic.x2    519.36\n               bic 179820.15\n              bic2 179314.95\n           ebic.25 180331.95\n            ebic.5 180843.75\n           ebic.75 181253.19\n             ebic1 181867.35\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"Method 3: FIML\"}\nqgraph(estnet_m3_1)\n```\n\n::: {.cell-output-display}\n![Method 3: Network Plot for BFI-25 with FIML and Prue](index_files/figure-html/fig-m3_1-1.png){#fig-m3_1 width=288}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"Method 3: FIML\"}\n# With stepwise\nres_m3_2 <- ggm(data, estimator = \"FIML\", standardize = \"z\") %>% \n  prune(alpha = .01, recursive = FALSE) |> \n  stepup(alpha = .01)\n    \nestnet_m3_2 <- getmatrix(res_m3_2, \"omega\")\n\nqgraph(estnet_m3_2)\n```\n\n::: {.cell-output-display}\n![Method 3: Network Plot for BFI-25 with FIML and Stepup](index_files/figure-html/fig-m3_2-1.png){#fig-m3_2 width=288}\n:::\n:::\n\n\n\n\n### Method 4 - WLS in psychonetrics\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"Method 4: WLS\"}\n# With stepwise\nres_m4_1 <- ggm(data, estimator = \"WLS\", standardize = \"z\") %>% \n  prune(alpha = .01, recursive = FALSE) \n    \nestnet_m4_1 <- getmatrix(res_m4_1, \"omega\")\n\nqgraph(estnet_m4_1)\n```\n\n::: {.cell-output-display}\n![Method 4: Network Plot for BFI-25 with WLS and prune](index_files/figure-html/fig-m4_1-1.png){#fig-m4_1 width=288}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"Method 4: WLS\"}\nres_m4_2 <- ggm(data, estimator = \"WLS\", standardize = \"z\") %>% \n  prune(alpha = .01, recursive = FALSE) |> \n  modelsearch(prunealpha = .01, addalpha = .01)\n    \nestnet_m4_2 <- getmatrix(res_m4_2, \"omega\")\n\nqgraph(estnet_m4_2)\n```\n\n::: {.cell-output-display}\n![Method 4: Network Plot for BFI-25 with WLS, prune, and modelsearch](index_files/figure-html/fig-m4_2-1.png){#fig-m4_2 width=288}\n:::\n:::\n\n\n\n\n### Method 5 - mgm in mgm\n\n`mgm` package is used for estimating mixed graphical models.\nNode type can be \"g\" for Gaussian or \"c\" for categorical.\nFor continuous variables, set `level` to 1 and `type` to g.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"Method 5: mgm\"}\nlibrary(mgm)\n## mgm with CV\nres_m5_1 <- mgm(na.omit(data), type = rep(\"g\", ncol(data)), level = rep(1, ncol(data)), \n           lambdaFolds = 20,\n           lambdaSel = \"CV\", lambdaGam = EBICtuning, \n           pbar = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNote that the sign of parameter estimates is stored separately; see ?mgm\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"Method 5: mgm\"}\ngetmatrix_mgm <- function(res) {\n  sign = ifelse(is.na(res$pairwise$signs), 1, res$pairwise$signs)\n  sign * res$pairwise$wadj\n}\nestnet_m5_1 <- getmatrix_mgm(res_m5_1)\nqgraph(estnet_m5_1)\n```\n\n::: {.cell-output-display}\n![Method 5: Network Plot for BFI-25 with mgm and CV](index_files/figure-html/fig-m5_1-1.png){#fig-m5_1 width=288}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"Method 5: mgm\"}\n## mgm with EBIC\nres_m5_2 <- mgm(na.omit(data), type = rep(\"g\", ncol(data)), level = rep(1, ncol(data)), \n           lambdaFolds = 20,\n           lambdaSel = \"EBIC\", lambdaGam = EBICtuning,\n           pbar = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNote that the sign of parameter estimates is stored separately; see ?mgm\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"Method 5: mgm\"}\nestnet_m5_2 <- getmatrix_mgm(res_m5_2)\nqgraph(estnet_m5_2)\n```\n\n::: {.cell-output-display}\n![Method 5: Network Plot for BFI-25 with mgm and EBIC](index_files/figure-html/fig-m5_2-1.png){#fig-m5_2 width=288}\n:::\n:::\n\n\n\n\n### Method 6 - BGGM in BGGM\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"Method 6: BGGM\"}\nres_m6_1 <- BGGM::explore(data, type = \"continuous\") |> \n  BGGM:::select.explore(BF_cut = 3)\nestnet_m6_1 <- res_m6_1$pcor_mat_zero\nqgraph(estnet_m6_1)\n```\n\n::: {.cell-output-display}\n![Method 6: Network Plot for BFI-25 with BGGM and explore](index_files/figure-html/fig-m6_1-1.png){#fig-m6_1 width=288}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"Method 6: BGGM\"}\nres_m6_2 <- BGGM::explore(data, type = \"continuous\") |> \n  BGGM:::select.estimate(cred = 0.95)\nestnet_m6_2 <- res_m6_2$pcor_adj\nqgraph(estnet_m6_2)\n```\n\n::: {.cell-output-display}\n![Method 6: Network Plot for BFI-25 with BGGM and estimate](index_files/figure-html/fig-m6_2-1.png){#fig-m6_2 width=288}\n:::\n:::\n\n\n\n\n:::\n\n## Performance Comparison\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nperformance <- function(network) {\n  res_comparison <- comparison_metrics(real = as.matrix(bfi_truenetwork), est = as.matrix(network))\n  c(\n    sensitivity = res_comparison$sensitivity_full,\n    specificity = res_comparison$specificity_full,\n    precision = res_comparison$precision_full,\n    \n    abs_corr = res_comparison$abs_cor_true_edges_full, # The Pearson correlation between the absolute edge weights\n    bias = res_comparison$bias_full, # The average absolute deviation\n    bias_true = res_comparison$bias_true_edges_full # The average absolute deviation between the true edge weight and the estimated edge weight\n  )\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nperformance_compr <- Reduce(rbind, lapply(list(estnet_m1, estnet_m2_1, estnet_m2_2, \n                                               estnet_m3_1, estnet_m3_2,\n                                               estnet_m4_1, estnet_m4_2,\n                                               estnet_m5_1, estnet_m5_2,\n                                               estnet_m6_1, estnet_m6_2), performance))\nrownames(performance_compr) <- c(\"EBICglasso\", \"ggmModSelect_stepwise\", \"ggmModSelect_nostepwise\",\n                                 \"FIML_prune\", \"FIML_stepup\",\n                                 \"WLS_prune\", \"WLS_prune_modelsearch\",\n                                 \"mgm_CV\", \"mgm_EBIC\",\n                                 \"BGGM_explore\", \"BGGM_estimate\")\nkableExtra::kable(performance_compr, digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|                        | sensitivity| specificity| precision| abs_corr|  bias| bias_true|\n|:-----------------------|-----------:|-----------:|---------:|--------:|-----:|---------:|\n|EBICglasso              |       1.000|       0.791|     0.727|    0.966| 0.009|     0.021|\n|ggmModSelect_stepwise   |       0.884|       1.000|     1.000|    0.963| 0.008|     0.016|\n|ggmModSelect_nostepwise |       0.911|       0.930|     0.879|    0.968| 0.008|     0.015|\n|FIML_prune              |       0.964|       0.995|     0.991|    0.973| 0.005|     0.013|\n|FIML_stepup             |       0.982|       0.995|     0.991|    0.974| 0.005|     0.013|\n|WLS_prune               |       0.964|       0.995|     0.991|    0.972| 0.006|     0.013|\n|WLS_prune_modelsearch   |       0.964|       0.995|     0.991|    0.972| 0.006|     0.013|\n|mgm_CV                  |       0.991|       0.905|     0.854|    0.971| 0.007|     0.015|\n|mgm_EBIC                |       0.902|       1.000|     1.000|    0.963| 0.009|     0.022|\n|BGGM_explore            |       0.884|       1.000|     1.000|    0.971| 0.007|     0.013|\n|BGGM_estimate           |       0.991|       0.945|     0.910|    0.970| 0.007|     0.014|\n\n\n:::\n:::\n\n\n\n\n## Summary\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nmycolors = c(\"#4682B4\", \"#B4464B\", \"#752021\",  \n             \"#1B9E77\", \"#66A61E\", \"#D95F02\", \"#7570B3\",\n             \"#E7298A\", \"#E75981\", \"#B4AF46\", \"#B4726A\")\nperformance_tbl <- performance_compr |> \n  as.data.frame() |> \n  mutate(method = rownames(performance_compr)) |> \n  mutate(method = factor(method, levels = rownames(performance_compr))) |> \n  filter(\n    method != \"WLS_prune_modelsearch\"\n  )\nggplot(performance_tbl) +\n  geom_point(aes(x = sensitivity, y = specificity, col = method), size = 3) +\n  geom_text(aes(x = sensitivity, y = specificity, label = method), size = 3,\n            nudge_x = .005, nudge_y = .005) +\n  geom_smooth(aes(x = sensitivity, y = specificity), se = FALSE, method = lm) +\n  theme_bw() +\n  scale_color_manual(values = mycolors) +\n  theme(legend.position = 'bottom')\n```\n\n::: {.cell-output-display}\n![Specificity and Sensitivity Balance](index_files/figure-html/fig-summary01-1.png){#fig-summary01 width=768}\n:::\n:::\n\n\n\n\n`FLML_prune` and `BGGM_estimation` seem to perform best among all methods regarding balance between sensitivity and specificity of network weights.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(performance_tbl) +\n  geom_col(aes(y = forcats::fct_reorder(method, precision), x = precision, fill = method)) +\n  theme_bw() +\n  labs(y = \"\") +\n  theme(legend.position = 'bottom')\n```\n\n::: {.cell-output-display}\n![Precision among all methods](index_files/figure-html/fig-summary02-1.png){#fig-summary02 width=960}\n:::\n:::\n\n\n\n\n`ggmMoSelect` with the stepwise procedure appears to have highest precision, followed by BGGM explore.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}