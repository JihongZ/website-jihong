{
  "hash": "aee0b016c5365a752a2af11e19c5ebee",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lecture 05: ANOVA Comparisons and Contrasts\"\nsubtitle: \"Experimental Design in Education\"\ndate: \"2025-02-17\"\nexecute: \n  eval: true\n  echo: true\n  message: false\n  warning: false\nformat: \n  html:\n    code-tools: true\n    code-line-numbers: false\n    code-fold: false\n    number-offset: 1\n    fig.width: 10\n    fig-align: center\n    message: false\n    grid:\n      sidebar-width: 350px\n  uark-revealjs:\n    chalkboard: true\n    embed-resources: false\n    code-fold: false\n    number-sections: true\n    number-depth: 1\n    footer: \"ESRM 64503\"\n    slide-number: c/t\n    tbl-colwidths: auto\n    scrollable: true\n    output-file: slides-index.html\n    mermaid:\n      theme: forest  \nfilters:\n  - webr      \n---\n\n::: objectives\n[Class Outline]{.redcolor .bigger}\n\n-   [GPT AI Tutor](https://chatgpt.com/g/g-68cf5bdeb74c8191bba4dfdd768d299b-experimental-design-tutor) for ESRM64103\n-   Planned Contrast\n-   Example: Group Comparison - STEM vs. Non-STEM Groups\n    -   ANOVA-style t statistics and regression-style coding in R\n    -   Effect sizes\n:::\n\n# Planned Contrasts\n\n## Definition: Planned Contrasts\n\n-   Pre-defined:\n\n    -   Unlike post hoc tests, planned contrasts are determined **before** looking at the data, meaning the researcher has a specific [[hypothesis about which groups to compare]{.underline}]{.bigger}.\n    -   **Definition**: Planned contrasts are hypothesis-driven comparisons made before data collection.\n\n-   Weights assigned:\n\n    -   To perform a planned contrast, each group is assigned a numerical \"weight\" which reflects its role in the comparison, with the [weights usually summing to zero]{.underline}.\n\n    $$\n    D = weights * means\n    $$\n\n    -   **D**: unscaled group differences given coding scheme\n\n## Example of Planned Contrasts\n\n-   **Imagine** a study comparing the effects of three different study methods (**A, B, C**) on test scores.\n\n    -   One planned contrast might be to compare the average score of method A (considered the \"experimental\" method) against the combined average of methods B and C (considered the \"control\" conditions),\n\n    -   Testing the hypothesis that method A leads to significantly higher scores than the traditional methods.\n\n    -   $H_0: \\mu_{A} = \\frac{\\mu_B+\\mu_C}{2}$; we also call this a **complex contrast**\n\n-   **When** to use planned contrasts:\n\n    -   When you have a clear theoretical basis for predicting specific differences between groups in your study.\n    -   When you are only interested in a few specific comparisons, not all possible pairwise comparisons.\n\n## What Does Each Contrast Tell Us?\n\n-   Each contrast is a mean comparison (via t-test).\n-   **Simple** contrast (pairwise) compares two individual group means.\n-   **Complex** contrast compares a combination of group means.\n-   Must be theoretically justified for meaningful interpretation.\n\n## Simple vs. Complex Comparisons\n\n-   **Simple Comparison:** Two groups directly compared.\n    -   Example: $H_0: \\mu_2 = \\mu_3$\n-   **Complex Comparison:** Combines means of multiple groups.\n    -   Example: $H_0: \\frac{(\\mu_1 + \\mu_2)}{2} = \\mu_3$\n    -   Example: $H_0: \\frac{(\\mu_1 + \\mu_2 + \\mu_3)}{3} = \\frac{(\\mu_4 + \\mu_5)}{2}$\n\n::: callout-note\nWe should not test all possible combinations of groups. Instead, justify your comparison plan before performing statistic analysis.\n:::\n\n## Today's focus: Complex Comparisons\n\n-   We performed omnibus tests in the last lecture, which provide all pairwise group comparisons (simple contrasts)\n\n-   Today we focus more on **complex contrasts**.\n    -   **Helmert** contrast: Compares each mean to the mean of subsequent groups.\n    -   **Sum (deviation)** contrast: each group compared to the grand mean\n    -   **Polynomial** contrast: Tests for trends in ordered data.\n-   By default, R uses **treatment** contrasts: each group compared to the reference group\n    -   Question: is \"treatment contrast\" a simple or complex contrast?\n    -   G1 vs. Treatment (reference)\n    -   G2 vs. Treatment (reference)\n    -   ....\n\n## Orthogonal vs. Non-Orthogonal Contrasts\n\n-   **Orthogonal Contrasts:** Independent from each other, sum of product of weights equals zero.\n\n-   **Non-Orthogonal Contrasts:** Not independent, lead to inflated Type I error rates.\n\n    ::: callout-note\n    Orthogonal contrasts allow clear interpretation without redundancy.\n    :::\n\n-   Orthogonal contrasts follow a series of group comparisons that do not overlap variances.\n\n## Orthogonal contrasts from variances: no redundancy\n\n[Helmert contrast example]{.redcolor}\n\n-   With a logical control group, a good first contrast compares all treatment groups to the one control group.\n-   To get each level of the IV alone, you should have one fewer contrast than your number of IV levels (3 levels = 2 contrasts)\n-   Once an IV level appears by itself, it shouldn’t reappear in subsequent contrasts\n\n```{dot}\n//| echo: FALSE\n//| fig-width: 15\ndigraph VarianceDiagram {\n    rankdir=LR;\n    \n    A [label=\"Total Variance Explained\", shape=box, style=filled, fillcolor=tomato, fontcolor=blue, fontsize=20, width=2.5, height=1.5];\n    B [label=\"Variance for G1 and G2\", shape=box, style=filled, fillcolor=lightgrey, fontcolor=red, fontsize=16, width=2.0, height=1];\n    C [label=\"Variance for G1\", shape=box, style=filled, fillcolor=lightblue, fontcolor=red];\n    D [label=\"Variance for G2\", shape=box, style=filled, fillcolor=lightblue, fontcolor=red];\n    E [label=\"Variance for G3\", shape=box, style=filled, fillcolor=lightgrey, fontcolor=red];\n\n    A -> B;\n    B -> C;\n    B -> D;\n    A -> E;\n}\n```\n\n## Example of Orthogonal Contrasts\n\n::::: columns\n::: {.column width=\"50%\"}\n-   Contrast 1: g3 vs. (g1, g2) ![](image/g3vsg12.jpg){width=\"90%\"}\n:::\n\n::: {.column width=\"50%\"}\n-   Contrast 2: g1 vs. g2 ![](image/g1vsg2.jpg){width=\"90%\"}\n:::\n:::::\n\n## Orthogonal Planned Contrasts\n\n-   If the same exact combination of means is not found in more than one contrast, the contrasts are independent (orthogonal)\n    -   Check this by ensuring that the product of the weights across all contrasts sums to zero\n-   For an orthogonal comparison, **contrasts are independent of each other:**\n    -   We weight the means included on each side of the contrast\n    -   Each contrast has weights that sum to 0\n    -   Groups not in the contrast get a weight of 0\n-   Why does independence matter?\n    -   [Type I error rate is unaffected by independent (orthogonal) contrasts]{.underline}\n    -   Interpretation of contrasts is cleaner because contrasts aren’t related (you’ve isolated effects)\n\n| Group | Contrast 1 | Contrast 2 | Product |\n|-------|------------|------------|---------|\n| G1    | +1         | -1         | -1      |\n| G2    | +1         | +1         | +1      |\n| G3    | -2         | 0          | 0       |\n| Sum   | 0          | 0          | 0       |\n\n## Contrasts' Independence checking in R\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ncat(\"## Constrasts and Coding \\n\")\ncontras <- matrix(\n  c(1, 1, -2,\n    -1, 1, 0), ncol = 2\n)\ncontras\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n## Constrasts and Coding \n     [,1] [,2]\n[1,]    1   -1\n[2,]    1    1\n[3,]   -2    0\n```\n\n\n:::\n:::\n\n\nTo understand if these contrasts are orthogonal, one could compute the dot product between the contrast vectors.\nThe dot product of first and second contrast is:\n\n$(1 * -1) + (1 * 1) + (-2 * 0) = -1 + 1 + 0 = 0$\n\nSince the dot product of the contrasts is equal to zero, these contrasts are indeed orthogonal.\n\nOrthogonal contrasts have the advantage that the comparison of the means of one contrast does not affect the comparison of the means of any other contrast.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ncat(\"## the dot-product of two contrasts should be zero\\n\")\nt(contras[,1]) %*% contras[,2] \ncat(\"## if non-diagonal elements are zero and diagnoal elements = 0 \\n\")\ncrossprod(contras) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n## the dot-product of two contrasts should be zero\n     [,1]\n[1,]    0\n## if non-diagonal elements are zero and diagnoal elements = 0 \n     [,1] [,2]\n[1,]    6    0\n[2,]    0    2\n```\n\n\n:::\n:::\n\n\n::: panel-tabset\n### Exercise\n\n```{webr-r}\nnew_code <- matrix(c(\n0, 0, 0, 0,\n1, 0, 0, 0,\n0, 1, 0, 0,\n0, 0, 1, 0,\n0, 0, 0, 1\n), byrow = TRUE, nrow = 5)\n\nnew_code\n```\n\n### Answer\n```{webr-r answer}\nnew_code <- matrix(c(\n0, 0, 0, 0,\n1, 0, 0, 0,\n0, 1, 0, 0,\n0, 0, 1, 0,\n0, 0, 0, 1\n), byrow = TRUE, nrow = 5)\n\ncat(\"## the cross-product of two contrasts should be zero\\n\")\nt(new_code[,1]) %*% new_code[,2]\nt(new_code[,1]) %*% new_code[,3]\nt(new_code[,1]) %*% new_code[,4]\nt(new_code[,2]) %*% new_code[,3]\ncat(\"## if non-diagonal elements are zero and diagnoal elements = 0 \\n\")\ncrossprod(new_code) \n```\n:::\n\n## Computing Planned Contrasts\n\n-   Formula for contrast value: $C = c_1\\mu_1 + c_2\\mu_2 + \\dots + c_k\\mu_k$\n-   Test statistic: $t = \\frac{C}{\\sqrt{MSE \\sum \\frac{c_i^2}{n_i}}}$\n    -   $MSE$: Mean Square Error from ANOVA\n    -   $c_i$: Contrast coefficients\n    -   $n_i$: Sample size per group\n    \n\n## Planned Contrasts and Coding Scheme\n\n-   The relationship between planned contrasts in ANOVA and coding in regression lies in how categorical variables are represented and interpreted in statistical models.\n\n-   Both approaches aim to test specific hypotheses about group differences, but their implementation varies based on the framework:\n\n    -   ANOVA focuses on partitioning variance,\n    -   Regression interprets categorical predictors through coding schemes.\n\n------------------------------------------------------------------------\n\n### Planned Contrast and Linear Regression\n\n-   Planned contrast can be done using `linear regression` + `contrasts`\n\n-   Let's look at the default contrasts plan: treatment contrasts == dummy coding\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(kableExtra)\nlibrary(here)\nset.seed(42)\ndt <- read.csv(here(\"teaching/2025-01-13-Experiment-Design/Lecture05\",\"week5_example.csv\"))\n## Treatment contrast matrix \nattributes(C(dt$group, treatment, 4))$contrasts\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   g2 g3 g4 g5\ng1  0  0  0  0\ng2  1  0  0  0\ng3  0  1  0  0\ng4  0  0  1  0\ng5  0  0  0  1\n```\n\n\n:::\n:::\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\n## Sum contrast matrix \nattributes(C(dt$group, sum, 4))$contrasts\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   [,1] [,2] [,3] [,4]\ng1    1    0    0    0\ng2    0    1    0    0\ng3    0    0    1    0\ng4    0    0    0    1\ng5   -1   -1   -1   -1\n```\n\n\n:::\n:::\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nattributes(C(dt$group, helmert, 4))$contrasts\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   [,1] [,2] [,3] [,4]\ng1   -1   -1   -1   -1\ng2    1   -1   -1   -1\ng3    0    2   -1   -1\ng4    0    0    3   -1\ng5    0    0    0    4\n```\n\n\n:::\n:::\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\ncrossprod(attributes(C(dt$group, treatment, 4))$contrasts)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   g2 g3 g4 g5\ng2  1  0  0  0\ng3  0  1  0  0\ng4  0  0  1  0\ng5  0  0  0  1\n```\n\n\n:::\n:::\n\n    \n\n# Example - STEM vs. Non-STEM Groups\n\n## Background\n\n-   Hypothesis: STEM students have different growth mindset scores than non-STEM students.\n-   Weights assigned:\n    -   STEM (Engineering, Chemistry): $+\\frac{1}{2}$\n    -   Non-STEM (Education, Political Science, Psychology): $-\\frac{1}{3}$\n-   Compute contrast value and test using t-statistic.\n\n## Set Contrasts in R\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Set seed for reproducibility\noptions(digits = 5)\nsummary_tbl <- dt |> \n  group_by(group) |> \n  summarise(\n    N = n(),\n    Mean = mean(score),\n    SD = sd(score),\n    shapiro.test.p.values = shapiro.test(score)$p.value\n  ) |> \n  mutate(department = c(\"Engineering\", \"Education\", \"Chemistry\", \"Political\", \"Psychology\")) |> \n  relocate(group, department)\nsummary_tbl\n```\n:::\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|group |department  |  N|   Mean|      SD| shapiro.test.p.values|\n|:-----|:-----------|--:|------:|-------:|---------------------:|\n|g1    |Engineering | 28| 4.2500| 3.15054|               0.07759|\n|g2    |Education   | 28| 2.7589| 2.19478|               0.07605|\n|g3    |Chemistry   | 28| 3.5446| 2.86506|               0.00623|\n|g4    |Political   | 28| 3.8568| 0.58325|               0.03023|\n|g5    |Psychology  | 28| 2.0243| 1.30911|               0.06147|\n\n\n:::\n:::\n\n\n-   Homogeneity of variance assumption: Levene's test\n\n-----------------------\n\n### Stem vs. Non-Stem \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\naov_fit <- aov(score ~ group, data = dt)\ncar::leveneTest(aov_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value  Pr(>F)    \ngroup   4      13 5.8e-09 ***\n      135                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\nEven though the assumption checks did not pass using the original categorical levels, we may still be interested in different group contrasts.\n\n-----------------------\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ncoef(lm(score ~ group, data = dt))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept)     groupg2     groupg3     groupg4     groupg5 \n    4.25000    -1.49107    -0.70536    -0.39321    -2.22571 \n```\n\n\n:::\n:::\n\n\n\n$$\n(\\beta_0 + \\beta_0 + \\beta_2) / 2 - (\\beta_0 + \\beta_1 + \\beta_0 + \\beta_3 + \\beta_0 + \\beta_4) / 3\n\\\\ = \\beta_2 / 2 - (\\beta_1 + \\beta_3 + \\beta_3) /3\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ncontrast <- matrix(\n  c(0, -1/3, 1/2, -1/3, -1/3), \n  nrow = 1\n)\nrownames(contrast) <- \"Stem vs. Non-Stem\"\nsummary(multcomp::glht(aov_fit, linfct = contrast))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\t Simultaneous Tests for General Linear Hypotheses\n\nFit: aov(formula = score ~ group, data = dt)\n\nLinear Hypotheses:\n                       Estimate Std. Error t value Pr(>|t|)   \nStem vs. Non-Stem == 0    1.017      0.386    2.64   0.0093 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmeans <- summary_tbl$Mean\nmean(means[c(1,3)]) - mean(means[-c(1,3)])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.0173\n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n### Complex Contrast Matrix\n\n-   There are multiple \"canned\" contrasts: Helmert, sum (effect coding), treatment\n\n[For example, Helmert: four contrasts]{.redcolor}\n\n1.  g1 vs. g2: $\\mu_{Engineering} = \\mu_{Education}$\n2.  $\\frac{g1+g2}{2}$ vs. g3: $\\mu_{non-Chemistry} = \\mu_{Chemistry}$\n3.  $\\frac{g1+g2+g3}{3}$ vs. g4: $\\mu_{non-Political} = \\mu_{Political}$\n4.  $\\frac{g1+g2+g3+g4}{4}$ vs. g5: $\\mu_{non-Psychology} = \\mu_{Psychology}$\n\nSummary Statistics:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndt$group <- factor(dt$group, levels = c(\"g1\", \"g2\", \"g3\", \"g4\", \"g5\"))\ngroups <- levels(dt$group)\ncH <- contr.helmert(groups) # pre-defined four contrasts\ncolnames(cH) <- paste0(\"Ctras\", 1:4)\nsummary_ctras_tbl <- cbind(summary_tbl, cH)\nsummary_ctras_tbl\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   group  department  N   Mean      SD shapiro.test.p.values Ctras1 Ctras2\ng1    g1 Engineering 28 4.2500 3.15054             0.0775874     -1     -1\ng2    g2   Education 28 2.7589 2.19478             0.0760542      1     -1\ng3    g3   Chemistry 28 3.5446 2.86506             0.0062253      0      2\ng4    g4   Political 28 3.8568 0.58325             0.0302312      0      0\ng5    g5  Psychology 28 2.0243 1.30911             0.0614743      0      0\n   Ctras3 Ctras4\ng1     -1     -1\ng2     -1     -1\ng3     -1     -1\ng4      3     -1\ng5      0      4\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Helmert contrasts are Orthogonal\n\n\n::: {.cell}\n\n```{.r .cell-code}\napply(cH, 2, sum)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCtras1 Ctras2 Ctras3 Ctras4 \n     0      0      0      0 \n```\n\n\n:::\n\n```{.r .cell-code}\ncrossprod(cH) # diagonal -- columns are orthogonal\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       Ctras1 Ctras2 Ctras3 Ctras4\nCtras1      2      0      0      0\nCtras2      0      6      0      0\nCtras3      0      0     12      0\nCtras4      0      0      0     20\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(aov(score ~ group, dt))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             Df Sum Sq Mean Sq F value Pr(>F)   \ngroup         4     89    22.3    4.47  0.002 **\nResiduals   135    675     5.0                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n## ANOVA: t-value formula for Defined Contrast Matrix\n\n$t = \\frac{C}{\\sqrt{MSE \\sum \\frac{c_i^2}{n_i}}}$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSum_C2_n <- colSums(cH^2 / summary_tbl$N)\nC <- crossprod(summary_tbl$Mean, cH)\nMSE <- 5\nt <- as.numeric(C / sqrt(MSE * Sum_C2_n))\ntibble(\n  t_value = t,\n  p_value = pt(t, df = 135) ## p-values\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 2\n  t_value  p_value\n    <dbl>    <dbl>\n1 -2.50   0.00690 \n2  0.0776 0.531   \n3  0.695  0.756   \n4 -3.34   0.000541\n```\n\n\n:::\n:::\n\n\n-   g1 vs. g2: We reject the null and determine that the mean of Education is different from the mean of Engineering in their growth mindset scores (p = 0.531).\n\n-   $\\frac{g1+g2}{2}$ vs. g3: We retain the null and determine that the mean of Chemistry is not significantly different from the mean of Education and Engineering in their growth mindset scores (p = 0.531).\n\n------------------------------------------------------------------------\n\n### Helmert Contrast\n\nRemember the planned contrast: g1 vs. g2 from the Helmert contrast:\n\n-   t-value: -2.495\n-   p-value: 0.0069\n-   df: 134\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ncontrasts(dt$group) <- \"contr.helmert\"\nfit_helmert <- lm(score ~ group, dt)\ncontr.helmert(levels(dt$group))\nsummary(fit_helmert)$coefficients\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   [,1] [,2] [,3] [,4]\ng1   -1   -1   -1   -1\ng2    1   -1   -1   -1\ng3    0    2   -1   -1\ng4    0    0    3   -1\ng5    0    0    0    4\n             Estimate Std. Error   t value   Pr(>|t|)\n(Intercept)  3.286929   0.189003 17.390874 2.8188e-36\ngroup1      -0.745536   0.298840 -2.494765 1.3810e-02\ngroup2       0.013393   0.172535  0.077624 9.3824e-01\ngroup3       0.084732   0.122001  0.694520 4.8855e-01\ngroup4      -0.315661   0.094502 -3.340271 1.0825e-03\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(summary_tbl$Mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.2869\n```\n\n\n:::\n\n```{.r .cell-code}\nunique(cbind(model.matrix(fit_helmert), group = dt$group))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    (Intercept) group1 group2 group3 group4 group\n1             1     -1     -1     -1     -1     1\n29            1      1     -1     -1     -1     2\n57            1      0      2     -1     -1     3\n85            1      0      0      3     -1     4\n113           1      0      0      0      4     5\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary_tbl$Mean %*% contrasts(dt$group) / c(2, 6, 12, 20)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         [,1]     [,2]     [,3]     [,4]\n[1,] -0.74554 0.013393 0.084732 -0.31566\n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n### Treatment contrasts\n\n::::: columns\n::: {.column width=\"50%\"}\n-   For treatment contrasts, four dummy variables are created to compare:\n\n    -   G1 (ref) vs. G2\n    -   G1 (ref) vs. G3\n    -   G1 (ref) vs. G4\n    -   G1 (ref) vs. G5\n:::\n\n::: {.column width=\"\\\"50%\"}\n-   `Intercept`: G1's mean\n-   `group2`: G2 vs. G1\n-   `group3`: G3 vs. G1\n-   `group4`: G4 vs. G1\n-   `group5`: G5 vs. G1\n:::\n:::::\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nlibrary(multcomp)\ncontrasts(dt$group) <- \"contr.treatment\"\nfit <- lm(score ~ group, dt)\nunique(cbind(model.matrix(fit), group = dt$group))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    (Intercept) groupg2 groupg3 groupg4 groupg5 group\n1             1       0       0       0       0     1\n29            1       1       0       0       0     2\n57            1       0       1       0       0     3\n85            1       0       0       1       0     4\n113           1       0       0       0       1     5\n```\n\n\n:::\n:::\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nsummary(fit)$coefficients\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Estimate Std. Error t value   Pr(>|t|)\n(Intercept)  4.25000    0.42262 10.0562 4.2275e-18\ngroupg2     -1.49107    0.59768 -2.4948 1.3810e-02\ngroupg3     -0.70536    0.59768 -1.1802 2.4001e-01\ngroupg4     -0.39321    0.59768 -0.6579 5.1172e-01\ngroupg5     -2.22571    0.59768 -3.7239 2.8718e-04\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Sum Contrasts\n\n-   Another type of coding is **effect coding**. In R, the corresponding contrast type is the so-called **sum contrasts**.\n\n-   A detailed post about sum contrasts can be found [here](https://learnb4ss.github.io/learnB4SS/articles/contrasts.html)\n\n-   With sum contrasts, the reference level is the grand mean.\n\n    -   $\\frac{g1+g2+g3+g4+g5}{5}$ vs. g1/g2/g3/g4: the difference between mean score of g1 with grand mean across all five groups\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\ncontrasts(dt$group) <- \"contr.sum\"\nfit2 <- lm(score ~ group, dt)\ncontr.sum(levels(dt$group))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   [,1] [,2] [,3] [,4]\ng1    1    0    0    0\ng2    0    1    0    0\ng3    0    0    1    0\ng4    0    0    0    1\ng5   -1   -1   -1   -1\n```\n\n\n:::\n:::\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nsummary(fit2)$coefficients\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Estimate Std. Error  t value   Pr(>|t|)\n(Intercept)  3.28693    0.18900 17.39087 2.8188e-36\ngroup1       0.96307    0.37801  2.54777 1.1962e-02\ngroup2      -0.52800    0.37801 -1.39680 1.6476e-01\ngroup3       0.25771    0.37801  0.68177 4.9655e-01\ngroup4       0.56986    0.37801  1.50753 1.3401e-01\n```\n\n\n:::\n:::\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nmean(dt$score) # (Intercept) grand mean\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.2869\n```\n\n\n:::\n:::\n\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\ntibble(\n  Label = paste0(\"group\", 1:4),\n  Estimate = summary_tbl$Mean[1:4] - mean(dt$score) \n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 2\n  Label  Estimate\n  <chr>     <dbl>\n1 group1    0.963\n2 group2   -0.528\n3 group3    0.258\n4 group4    0.570\n```\n\n\n:::\n:::\n\n\n## Effect Coding (Deviation Coding)\n\n-   In modern statistics, regression-style coding is statistically equivalent to an ANOVA-style contrast matrix.\n    -   Equivalent to ANOVA-style contrasts. ([we will use this in R to reproduce ANOVA-style contrast matrix]{.redcolor})\n-   Compares each level to the grand mean.\n\n::: callout-note\nEffect coding is a method of encoding categorical variables in regression models, similar to dummy coding, but with a different interpretation of the resulting coefficients. It is particularly useful when researchers want to compare each level of a categorical variable to the overall mean rather than to a specific reference category.\n:::\n\n------------------------------------------------------------------------\n\n### Definition and Representation\n\nIn effect coding, categorical variables are transformed into numerical variables, typically using values of -1, 0, and 1. The key difference from dummy coding is that the reference category is represented by -1 instead of 0, and the coefficients indicate deviations from the grand mean.\n\nFor a categorical variable with `k` levels, effect coding requires `k-1` coded variables. If we have a categorical variable X with three levels: $A, B, C$, the effect coding scheme could be:\n\n| Category      | $X_1$ | $X_2$ |\n|---------------|-------|-------|\n| A             | 1     | 0     |\n| B             | 0     | 1     |\n| C (reference) | -1    | -1    |\n\nThe last category ($C$) is the reference group, coded as -1 for all indicator \n\n------------------------------------------------\n\n- In effect coding, one level of the categorical variable (usually the last one or the one that is considered a 'reference' category) is coded as -1, and the others are coded as +1 or 0, suggesting their relation to the overall mean, rather than to a specific category.\n\nHere's how you could effect code a categorical variable with three levels (e.g., groups):\n\n```\n    [,1] [,2]\ng1   1    0\ng2   0    1\ng3  -1   -1\n```\n\nThis coding scheme shows that:\n\n- Group1 (`g1`) is compared to the overall effect by coding it as `1` in the first column and `0` in the second, suggesting it is above or below the overall mean.\n- Conversely, Group2 (`g2`) is also contrasted with the overall effect.\n- Group3 (`g3`), coded as `-1` in both columns, serves as the reference category against which the other two are compared.\n\nIn your regression output, the coefficients for the first two groups will show how the mean of these groups differs from the overall mean. The intercept will represent the overall mean across all groups.\n\n------------------------------------------------------------------------\n\n### Interpretation of Coefficients in effective coding\n\n::::: columns\n::: {.column width=\"40%\"}\nWhen effect coding is used in a regression model:\n\n$$\nY = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\epsilon\n$$\n\n-   $X_1$ and $X_2$ are coded variables. They have no much meaning, but their coefficients are **important**\n-   $\\beta_0$ represents the **grand mean** of $Y$ across all categories.\n-   $\\beta_1$ and $\\beta_2$ represent the **deviation** of categories $A$ and $B$ from the grand mean.\n-   The reference group ($C$) does not have a separate coefficient; instead, its deviation can be inferred as $-(\\beta_1 + \\beta_2)$.\n:::\n\n::: {.column width=\"60%\"}\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(ggplot2)\n# Create a data frame for text labels\ntext_data <- data.frame(\n  x = rep(0.25, 3),  # Repeating the same x-coordinate\n  y = c(0.3, 0.7, 0.9),  # Different y-coordinates\n  label = c(\"C: beta[0] - beta[1] - beta[2]\", \n            \"A: beta[0] + 1*'×'*beta[1] + 0*'×'*beta[2]\", \n            \"B: beta[0] + 0*'×'*beta[1] + 1*'×'*beta[2]\")  # Labels\n)\n\n# Create an empty ggplot with defined limits\nggplot() +\n  geom_text(data = text_data, aes(x = x, y = y, label = label), parse = TRUE, size = 11) +\n  # Add a vertical line at x = 0.5\n  # geom_vline(xintercept = 0.5, color = \"blue\", linetype = \"dashed\", linewidth = 1) +\n  # Add two horizontal lines at y = 0.3 and y = 0.7\n  geom_hline(yintercept = c(0.35, 0.75, 0.95), color = \"red\", linetype = \"solid\", linewidth = 1) +\n  geom_hline(yintercept = 0.5, color = \"grey\", linetype = \"solid\", linewidth = 1) +\n  geom_text(aes(x = .25, y = .45, label = \"grand mean of Y\"), color = \"grey\", size = 11) +\n  # Set axis limits\n  xlim(0, 1) + ylim(0, 1) +\n  labs(y = \"Y\", x = \"\") +\n  # Theme adjustments\n  theme_minimal() +\n  theme(text = element_text(size = 20))\n```\n\n::: {.cell-output-display}\n![](ESRM64103_Lecture05_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n:::\n:::::\n\n------------------------------------------------------------------------\n\n### Comparison to Dummy Coding\n\n-   **Dummy Coding**: Compares each category to a **specific reference category** (e.g., comparing A and B to C).\n\n| Category      | $X_1$ | $X_2$ |\n|---------------|-------|-------|\n| A             | 1     | 0     |\n| B             | 0     | 1     |\n| C (reference) | 0     | 0     |\n\n-   **Effect Coding**: Compares each category to the **grand mean** rather than a single reference category.\n\n------------------------------------------------------------------------\n\n### Use Cases\n\nEffect coding is beneficial when:\n\n-   There is no natural baseline category, and comparisons to the **overall mean** are more meaningful.\n-   Researchers want to maintain **sum-to-zero constraints** for categorical variables in linear models.\n-   In ANOVA-style analyses, where main effects and interaction effects are tested under an equal-weight assumption.\n\n------------------------------------------------------------------------\n\n### Implementation in R\n\nEffect coding can be set in R using the `contr.sum` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nX <- factor(c(\"A\", \"B\", \"C\"))\ncontrasts(X) <- contr.sum(3) # set up effect coding in R\nmodel <- lm(Y ~ X, data = mydata) # use linear regression to mimic ANOVA-style results\nsummary(model)\n```\n:::\n\n\n## Exercise\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ESRM64103)\nhead(ESRM64103::exp_political_attitude)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       party scores\n1   Democrat      4\n2   Democrat      3\n3   Democrat      5\n4   Democrat      4\n5   Democrat      4\n6 Republican      6\n```\n\n\n:::\n:::\n\n\n::: panel-tabset\n\n### Quiz\n1. Under treatment coding, which level is the reference and how do you interpret the coefficients?\n\n2.  Under effect coding, what does the intercept represent and how do you interpret each group coefficient relative to the grand mean?\n    \n```{webr-r}\nlibrary(ESRM64103)\ndat <- exp_political_attitude\ndat$party <- factor(dat$party, levels = c(\"Democrat\", \"Republican\", \"Independent\"))\n\n# 1) Fit with treatment (dummy) coding\ncontrasts(dat$party) <- __________\nfit_tr <- lm(__________)\n\n# 2) Fit with effect (sum) coding\ncontrasts(dat$party) <- __________\nfit_eff <- lm(__________)\n\n# Compare ANOVA tables and coefficients\nanova_tr <- anova(fit_tr)\ncoef_tr  <- summary(fit_tr)$coef\nanova_eff <- anova(fit_eff)\ncoef_eff  <- summary(fit_eff)$coef\n    \nlist(\n  Treatment_ANOVA = anova_tr,\n  Treatment_Coef  = round(coef_tr, 3),\n  Effect_ANOVA    = anova_eff,\n  Effect_Coef     = round(coef_eff, 3)\n)\n```\n\n### Answer\n```{webr-r}\nlibrary(ESRM64103)\ndat <- exp_political_attitude\ndat$party <- factor(dat$party, levels = c(\"Democrat\", \"Republican\", \"Independent\"))\n# 1) Fit with treatment (dummy) coding\ncontrasts(dat$party) <- contr.treatment(3)\nfit_tr <- lm(scores ~ party, data = dat)\n\n# 2) Fit with effect (sum) coding\ncontrasts(dat$party) <- contr.sum(3)\nfit_eff <- lm(scores ~ party, data = dat)\n\n# Compare ANOVA tables and coefficients\nanova_tr <- anova(fit_tr)\ncoef_tr  <- summary(fit_tr)$coef\nanova_eff <- anova(fit_eff)\ncoef_eff  <- summary(fit_eff)$coef\n    \nlist(\n  Treatment_ANOVA = anova_tr,\n  Treatment_Coef  = round(coef_tr, 3),\n  Effect_ANOVA    = anova_eff,\n  Effect_Coef     = round(coef_eff, 3)\n)\n```\n\n\n:::\n\n## Self-defined contrast\n\n-   Extended example 2: Assume now that the average of the STEM groups is different from the average of the non-STEM groups\n\n### Method 1: Calculation by Hand\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n  group  department  N   Mean      SD shapiro.test.p.values Contrasts\n1    g1 Engineering 28 4.2500 3.15054             0.0775874   0.50000\n2    g2   Education 28 2.7589 2.19478             0.0760542  -0.33333\n3    g3   Chemistry 28 3.5446 2.86506             0.0062253   0.50000\n4    g4   Political 28 3.8568 0.58325             0.0302312  -0.33333\n5    g5  Psychology 28 2.0243 1.30911             0.0614743  -0.33333\n```\n\n\n:::\n:::\n\n\n$$\nH_0: \\frac{\\mu_{Engineering}+\\mu_{Chemistry}}{2} = \\frac{\\mu_{Education}+\\mu_{PoliSci}+\\mu_{Psychology}}{3}\n$$\n\nWeighted mean difference:\n\n$$\nC = c_1\\mu_{Eng}+c_2\\mu_{Edu}+c_3\\mu_{Chem}+c_4\\mu_{PoliSci}+c_5\\mu_{Psych}\\\\\n= \\frac{1}{2}*4.25+(-\\frac13)*2.75+(\\frac12)*3.54+(-\\frac13)*3.85+(-\\frac13)*2.02\\\\\n= 1.0173\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(C <- sum(summary_tbl_ext$Contrasts*summary_tbl_ext$Mean))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.0173\n```\n\n\n:::\n:::\n\n\n$$\n\\sum\\frac{c^2}{n} = \\frac{(\\frac12)^2}{28}+\\frac{(-\\frac13)^2}{28}+\\frac{(\\frac12)^2}{28}+\\frac{(-\\frac13)^2}{28}+\\frac{(-\\frac13)^2}{28}\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSum_C2_n <- sum(summary_tbl_ext$Contrasts^2 / summary_tbl$N)\nMSE = sum((residuals(aov(score ~ group, dt)))^2) / (nrow(dt) - 5)\nt = as.numeric(C / sqrt(MSE * Sum_C2_n))\np.value = pt(t, df = 135, lower.tail = FALSE) * 2\ndata.frame(t, p.value)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       t   p.value\n1 2.6369 0.0093476\n```\n\n\n:::\n:::\n\n\n$$\nt = \\frac{C}{\\sqrt{MSE*\\sum\\frac{c^2}{n} }} = \\frac{1.0173}{\\sqrt{5.0011*0.029762}}=2.6368\n$$\n\n------------------------------------------------------------------------\n\n### Method 2: Linear regression contrasts in R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# set first contrast\ncontrasts(dt$group) <- matrix(\n  c(1/2, -1/3, 1/2, -1/3, -1/3)\n)\nfit_extended <- lm(score ~ group, dt)\nunique(model.matrix(fit_extended))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    (Intercept)   group1    group2   group3   group4\n1             1  0.50000 -0.692619 -0.10070 -0.10070\n29            1 -0.33333  0.164436 -0.56552 -0.56552\n57            1  0.50000  0.692619  0.10070  0.10070\n85            1 -0.33333 -0.082218  0.78276 -0.21724\n113           1 -0.33333 -0.082218 -0.21724  0.78276\n```\n\n\n:::\n:::\n\n\n\n::: {.cell output-line-numbers='3'}\n\n```{.r .cell-code}\nsummary(fit_extended)$coefficient[2,] |> round(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n``` highlight\n  Estimate Std. Error    t value   Pr(>|t|) \n     1.221      0.463      2.637      0.009 \n```\n\n\n:::\n:::\n\n\n## Exercise\n\n::: panel-tabset\n\n### Quiz\n(g1, g2, g3) vs (g4, g5)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrasts(dt$group) <- matrix(\n  __________________\n)\nfit <- lm(score ~ group, dt)\nunique(_____)\nsummary(________)$coefficient[_,] |> round(3)\n```\n:::\n\n\n### Anwser\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrasts(dt$group) <- matrix(\n  c(-1/3, -1/3, -1/3, 1/2, 1/2)\n)\nfit <- lm(score ~ group, dt)\nunique(model.matrix(fit))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    (Intercept)   group1      group2    group3    group4\n1             1 -0.33333 -4.3068e-01 -0.490501 -0.490501\n29            1 -0.33333 -3.8540e-01  0.508987  0.508987\n57            1 -0.33333  8.1608e-01 -0.018486 -0.018486\n85            1  0.50000 -1.6593e-18  0.500000 -0.500000\n113           1  0.50000 -1.6593e-18 -0.500000  0.500000\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fit)$coefficient[2,] |> round(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Estimate Std. Error    t value   Pr(>|t|) \n    -0.693      0.463     -1.496      0.137 \n```\n\n\n:::\n:::\n\n:::\n\n# Effect Sizes\n\n## What Are Effect Sizes?\n\n-   Effect size measures the magnitude of an effect beyond statistical significance.\n    -   Put simply: a p-value is partially dependent on sample size and does not give us any insight into the strength of the relationship\n    -   Lower p-value → can result from increasing sample size\n-   Provides context for interpreting practical significance.\n    -   In scientific experiments, it is often useful to know not only whether an experiment has a statistically significant effect, but also the size (magnitude) of any observed effects.\n-   Common measures: Eta squared ($\\eta^2$), Omega squared ($\\omega^2$), Cohen’s d.\n\n::: callout-note\nMany psychology journals require the reporting of effect sizes\n:::\n\n## Eta squared\n\n-   $\\eta^2$: Proportion of total variance explained by the independent variable.\n-   Formula: $\\eta^2 = \\frac{SS_{Model}}{SS_{Total}}$\n-   Interpretation:\n    -   Small: 0.01, Medium: 0.06, Large: 0.14\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(F_table <- as.data.frame(anova(fit)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           Df  Sum Sq Mean Sq F value    Pr(>F)\ngroup       4  89.368 22.3420  4.4674 0.0020173\nResiduals 135 675.149  5.0011      NA        NA\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(eta_2 <- F_table$`Sum Sq`[1] / sum(F_table$`Sum Sq`))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.11689\n```\n\n\n:::\n:::\n\n\n[Interpretation: 11.69% of variance in the DV is due to group differences.]{.redcolor}\n\n## Drawbacks of eta squared\n\n1.  **As you add more variables to the model, the proportion explained by any one variable will automatically decrease.**\n    -   This makes it hard to compare the effect of a single variable in different studies.\n    -   Partial Eta Squared solves this problem. There, the denominator is not the total variation in Y, but the unexplained variation in Y plus the variation explained just by that IV.\n        -   Any variation explained by other IVs is removed from the denominator.\n    -   In a one-way ANOVA, Eta Squared and Partial Eta Squared will be equal, but this isn’t true in models with more than one independent variable (factorial ANOVA).\n2.  **Eta Squared is a biased measure of population variance explained (although it is accurate for the sample).**\n    -   It always overestimates it. This bias gets very small as sample size increases, but for small samples an unbiased effect size measure is Omega Squared.\n\n## Omega squared\n\n-   Omega Squared ($\\omega^2$) has the same basic interpretation but uses unbiased measures of the variance components.\n    -   Because it is an unbiased estimate of population variances, omega squared is always smaller than eta squared.\n-   Unbiased estimate of effect size, preferred for small samples.\n-   Formula: $\\omega^2 = \\frac{SS_{Model} - df_{Model} \\cdot MSE}{SS_{Total} + MSE}$\n-   Interpretation follows $\\eta^2$ scale but slightly smaller values.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nF_table\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           Df  Sum Sq Mean Sq F value    Pr(>F)\ngroup       4  89.368 22.3420  4.4674 0.0020173\nResiduals 135 675.149  5.0011      NA        NA\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nattach(F_table) #<1>\n(Omega_2 <- (`Sum Sq`[1] - Df[1] * MSE) / (sum(`Sum Sq`) + MSE)) #<2>\ndetach(F_table)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.090139\n```\n\n\n:::\n:::\n\n\n1.  Attach data set so that you can directly call the columns without \"\\$\"\n2.  The formula of Omega square\n\n## Effect Size for Planned Contrasts\n\n-   Correlation-based effect size: $r = \\sqrt{\\frac{t^2}{t^2 + df}} = \\sqrt{\\frac{F}{F + df}}$\n-   Example: For $t = 2.49, df = 135$: $r = \\sqrt{\\frac{2.49^2}{2.49^2 + 135}} = 0.21$\n    -   Small to moderate effect.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(coef_tbl <- as.data.frame(summary(fit)$coefficients))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               Estimate Std. Error    t value   Pr(>|t|)\n(Intercept)  3.28692857    0.18900 17.3908736 2.8188e-36\ngroup1      -0.69278571    0.46296 -1.4964232 1.3688e-01\ngroup2      -0.00096962    0.42262 -0.0022943 9.9817e-01\ngroup3       0.17035380    0.42262  0.4030862 6.8752e-01\ngroup4      -1.66214620    0.42262 -3.9329222 1.3359e-04\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nattach(coef_tbl)\nround(sqrt(`t value`^2 / (`t value`^2 + 135)), 3)\ndetach(coef_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.831 0.128 0.000 0.035 0.321\n```\n\n\n:::\n:::\n\n\n-   Shows a small to moderate positive relationship between g1 and g5.\n\n## Cohen’s d and Hedges’ g\n\n-   Used for simple mean comparisons.\n-   Cohen’s d formula: $d = \\frac{M_1 - M_2}{SD_{pooled}}$\n-   Hedges’ g corrects for small sample bias.\n-   Guidelines:\n    -   Small: 0.2, Medium: 0.5, Large: 0.8\n\n## Guidelines for Effect Size\n\n![](images/clipboard-1482285190.png)\n\n-   For our example: there is a significant effect of academic program on growth mindset scores (F(4, 135) = 4.47).\n-   Academic program explains 11.69% of the variance in growth mindset scores. This is a medium to large effect ($\\eta^2$ = 0.1169).\n\n## Summary\n\n-   Planned contrasts allow hypothesis-driven mean comparisons.\n-   Orthogonal contrasts maintain Type I error control.\n-   Effect sizes help interpret the importance of results.\n-   Combining planned contrasts with effect size measures enhances statistical analysis.\n",
    "supporting": [
      "ESRM64103_Lecture05_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}