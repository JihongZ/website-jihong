{
  "hash": "6e27b4a30bcf4c987660881d8f4194a5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lecture 03: Introduction to One-way ANOVA\"\nsubtitle: \"Experimental Design in Education\"\ndate: \"2025-08-18\"\nexecute: \n  eval: false\n  echo: true\nformat: \n  html:\n    code-tools: true\n    code-line-numbers: false\n    code-fold: false\n    number-offset: 1\n    fig.width: 10\n    fig-align: center\n    message: false\n    grid:\n      sidebar-width: 350px\n  uark-revealjs:\n    chalkboard: true\n    embed-resources: false\n    code-fold: false\n    number-sections: true\n    number-depth: 1\n    footer: \"ESRM 64503\"\n    slide-number: c/t\n    tbl-colwidths: auto\n    scrollable: true\n    output-file: slides-index.html\n    mermaid:\n      theme: forest  \n---\n\n## Lecture Outline\n\n-   Homework assignment\n-   Introduction to ANOVA\n    -   Why use ANOVA instead of multiple t-tests?\n    -   Logic and components of ANOVA\n    -   Steps and assumptions in ANOVA\n    -   Example scenario and real-world applications\n-   Performing ANOVA in R\n    -   Checking homogeneity of variance\n    -   Post-hoc analysis\n    -   Using weights in ANOVA\n    -   Where to find weights for ANOVA\n-   Conclusion\n\n# Homework 1\n\n## Let's walk through HW1\n\n# One-Way ANOVA\n\n## Introduction\n\n-   Overview of ANOVA and its applications.\n-   Used for comparing means across multiple groups.\n-   Explanation of why ANOVA is essential in statistical analysis.\n\n## ANOVA Basics\n\n-   **Analysis of Variance (ANOVA)** compares multiple group means (more than two groups).\n-   If comparing only 2 groups, either a t-test or an F-test can be used.\n-   When more than 2 groups are compared, an F-test (ANOVA) is required.\n\n## Why Use ANOVA Instead of Multiple t-tests?\n\n1.  Computational complexity increases as the number of groups increases.\n2.  Multiple t-tests inflate the Type I error rate.\n3.  ANOVA provides an omnibus test to detect any significant difference.\n4.  Example demonstrating inflated Type I error with multiple t-tests.\n\n## Logic of ANOVA\n\n-   ANOVA compares group means by analyzing [variance components]{.underline}.\n-   Two independent variance estimates:\n    1.  **Between-group variability** (treatment effect)\n    2.  **Within-group variability** (error or chance)\n-   Illustration: Graph showing variance breakdown.\n\n## Components of ANOVA\n\n1.  **Total Sum of Squares** ($SS_{total}$): Total variance of outcomes in the data.\n2.  **Sum of Squares Between** ($SS_{between}$): Variability of outcomes due to the group(s).\n3.  **Sum of Squares Within** ($SS_{within}$): Variability due to error (some we do not test yet).\n    -   Relationship: $SS_{total} = SS_{between} + SS_{within}$\n\n------------------------------------------------------------------------\n\n### If $SS_{between}$ \\> $SS_{within}$ ...\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'dplyr'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](ESRM64103_Lecture03_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n#### R output:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df Sum Sq Mean Sq F value Pr(>F)    \ngroup        1 218.42  218.42   264.1 <2e-16 ***\nResiduals   38  31.43    0.83                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### If $SS_{between}$ \\< $SS_{within}$ ...\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](ESRM64103_Lecture03_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n#### R output:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df Sum Sq Mean Sq F value Pr(>F)  \ngroup        1  113.4  113.43   5.485 0.0245 *\nResiduals   38  785.8   20.68                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n## Practical Steps in One-way ANOVA\n\n1.  Compute total variability.\n2.  Decompose total variability into model-related and error-related components.\n3.  Compute the F-statistic: $F_{obs} = \\frac{SS_{between}/df_{between}}{SS_{within}/df_{within}}=  \\frac{MS_{between}}{MS_{within}}$\n4.  Construct the ANOVA table, determine alpha level and draw conclusions.\n5.  Examine Homogeneity of Variance\n6.  Conduct Post-Hoc Analysis\n\n## Assumptions of ANOVA\n\n-   Independence of observations.\n-   Normality of residuals.\n-   Homogeneity of variance (homoscedasticity).\n-   Consequences of violating these assumptions.\n\n## Homogeneity of Variance\n\n-   ANOVA assumes that variance across groups is equal.\n-   Unequal variances can lead to incorrect conclusions.\n-   Example illustrating different variance conditions.\n\n::: callout-note\n## We will talk more details about this in the next lecture\n:::\n\n## Methods to Check Homogeneity of Variance\n\n-   **Levene’s Test**: Tests for equal variances across groups.\n-   **Bartlett’s Test**: Specifically tests for homogeneity in normally distributed data.\n-   **Visual Inspection**: Boxplots can help assess variance equality.\n-   Graph: Example of equal and unequal variance in boxplots.\n\n# Example: One-way ANOVA in R\n\n## Example Scenario\n\n-   **Research Aim**: Investigating the effect of an teaching intervention on children's [verbal acquisition]{.underline}.\n-   **IV (Factor):** Intervention groups (G1, G2, G3, Control).\n-   **DV:** Verbal acquisition scores.\n-   **Hypotheses:**\n    -   $H_0$: $\\mu_{Control} = \\mu_{G1} = \\mu_{G2} = \\mu_{G3}$\n    -   $H_A$: At least two group means differ.\n\n## Performing ANOVA in R\n\n### Load Libraries\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(car) # used for leveneTest; install.packages(\"car\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: carData\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'car'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:dplyr':\n\n    recode\n```\n\n\n:::\n:::\n\n\n### Generate Sample Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\nrnorm(10, 20, 10) # generate 10 data points from a normal distribution of mean as 20 and SD as 10\n```\n:::\n\n\n-   Context: the example research focus on whether three different teaching methods (labeled as G1, G2, G3) on students' test scores.\n\n-   In total, 40 students are assigned to three teaching group and one default teaching group. Each group have 10 samples.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\ndata <- data.frame(\n  group = rep(c(\"G1\", \"G2\", \"G3\", \"Control\"), each = 10),\n  score = c(rnorm(10, 20, 5), rnorm(10, 25, 5), rnorm(10, 30, 5), rnorm(10, 22, 5))\n)\ndata_unequal <- data.frame(\n  group = rep(c(\"G1\", \"G2\", \"G3\", \"Control\"), each = 10),\n  score = c(rnorm(10, 20, 10), rnorm(10, 25, 5), rnorm(10, 30, 1), rnorm(10, 22, .1))\n)\n```\n:::\n\n\n------------------------------------------------------------------------\n\n### Conduct ANOVA Test\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova_result <- aov(score ~ group, data = data)\nsummary(anova_result)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ngroup        3  724.1  241.37   11.45 2.04e-05 ***\nResiduals   36  759.2   21.09                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\nanova_result2 <- aov(score ~ group, data = data_unequal)\nsummary(anova_result2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ngroup        3   1413   470.9   19.14 1.37e-07 ***\nResiduals   36    886    24.6                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n## Checking Homogeneity of Variance (HoV)\n\n### Method 1: Visual Inspection of Variance Equality\n\n#### Equal Variances across groups\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data, aes(x = group, y = score)) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(title = \"Equal Variance: Boxplot of Scores by Group\", x = \"Group\", y = \"Score\")\n```\n\n::: {.cell-output-display}\n![](ESRM64103_Lecture03_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n#### Unequal Variances across groups\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data_unequal, aes(x = group, y = score)) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(title = \"Unequal Variances: Boxplot of Scores by Group\", x = \"Group\", y = \"Score\")\n```\n\n::: {.cell-output-display}\n![](ESRM64103_Lecture03_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Method 2: Using Bartlett’s Test\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(\"Equal group:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEqual group:\n```\n\n\n:::\n\n```{.r .cell-code}\nbartlett.test(score ~ group, data = data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tBartlett test of homogeneity of variances\n\ndata:  score by group\nBartlett's K-squared = 2.0115, df = 3, p-value = 0.57\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Unequal group:\\n\" )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nUnequal group:\n```\n\n\n:::\n\n```{.r .cell-code}\nbartlett.test(score ~ group, data = data_unequal)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tBartlett test of homogeneity of variances\n\ndata:  score by group\nBartlett's K-squared = 82.755, df = 3, p-value < 2.2e-16\n```\n\n\n:::\n:::\n\n\nBartlett test of HoV for equal-group sample is non-significant, suggesting we have no evidence against the null hypothesis and should consider groups are homogeneous.\n\n------------------------------------------------------------------------\n\n### Method 3: Using Levene’s Test\n\n\n::: {.cell}\n\n```{.r .cell-code}\nleveneTest(score ~ group, data = data)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(>F)\ngroup  3  0.1779 0.9107\n      36               \n```\n\n\n:::\n\n```{.r .cell-code}\nleveneTest(score ~ group, data = data_unequal)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value  Pr(>F)  \ngroup  3  3.4749 0.02581 *\n      36                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n### When to use each test\n\n\n- Use Levene's Test (more frequently used) when:\n\n  - Data may not be normally distributed\n  - Dealing with outliers in the dataset\n  - Working with small sample sizes\n  - Conducting preliminary tests for ANOVA with non-normal data\n  - General robustness is prioritized over power\n  \n- Use Bartlett's Test when:\n\n  - Data is confirmed to be normally distributed\n  - No significant outliers are present\n  - Larger sample sizes are available\n  - Maximum statistical power is desired (under normality)\n  - Preliminary testing for parametric procedures with normal data\n\n## Post-hoc Analysis\n\n### Tukey Honest Significant Differences (HSD) Test\n\n-   Create a set of confidence intervals on the differences between the means of the pairwise levels of a factor with the specified family-wise probability of coverage.\n\n-   When comparing the means for the levels of a factor in an analysis of variance, a simple comparison using t-tests will inflate the probability of declaring a significant difference when it is not in fact present.\n\n-   Based on Tukey's 'Honest Significant Differences' method\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntukey_result <- TukeyHSD(anova_result)\nprint(tukey_result$group)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  diff        lwr       upr        p adj\nG1-Control -0.08482175 -5.6158112  5.446168 0.9999741881\nG2-Control  6.24011176  0.7091223 11.771101 0.0218818550\nG3-Control  9.89123122  4.3602418 15.422221 0.0001491636\nG2-G1       6.32493351  0.7939441 11.855923 0.0197364909\nG3-G1       9.97605296  4.4450635 15.507042 0.0001317258\nG3-G2       3.65111946 -1.8798700  9.182109 0.3003394077\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(tukey_result)\n```\n\n::: {.cell-output-display}\n![](ESRM64103_Lecture03_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n## Interpreting Results\n\n### ANOVA Statistics\n\n```         \n           Df Sum Sq Mean Sq F value   Pr(>F)    \ngroup        3  724.1  241.37   11.45 2.04e-05 ***\nResiduals   36  759.2   21.09                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(dplyr)\ndata |> \n  group_by(group) |> \n  summarise(\n    Mean = mean(score),\n    SD = sd(score)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n  group    Mean    SD\n  <chr>   <dbl> <dbl>\n1 Control  18.2  4.47\n2 G1       18.1  4.98\n3 G2       24.4  5.34\n4 G3       28.1  3.33\n```\n\n\n:::\n:::\n\n\n-   A one-way analysis of variance (ANOVA) was conducted to examine the effect of teaching method on students' test scores. The results indicated a statistically significant difference in test scores across the three teaching methods, ( F(3, 27) = 11.45, p \\< .001 ). Post-hoc comparisons using the Tukey HSD test revealed that the Interactive method (G3) ( M = 28.06, SD = 3.33 ) resulted in significantly higher scores than the Traditional method ( M = 18.17, SD = 4.47) with the p-value lower than .001, but no significant difference was found between the Interactive (G1) and the traditional methods ( p = .99 ). These results suggest that using interactive teaching methods can improve student performance compared to traditional methods.\n\n## Real-world Applications of ANOVA\n\n-   Experimental designs in psychology.\n-   Clinical trials in medicine.\n-   Market research and A/B testing.\n-   Example case studies.\n\n## Using Weights in ANOVA\n\n-   In some cases, observations may have different levels of reliability or importance.\n-   Weighted ANOVA allows us to account for these differences by assigning weights.\n-   Example: A study where some groups have higher variance and should contribute less to the analysis.\n\n## Example: Applying Weights in `aov()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweights <- c(rep(1, 10), rep(2, 10), rep(0.5, 10), rep(1.5, 10))\nanova_weighted <- aov(score ~ group, data = data, weights = weights)\nsummary(anova_weighted)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ngroup        3  666.6  222.20   7.578 0.000471 ***\nResiduals   36 1055.5   29.32                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n-   The weights modify the influence of each observation in the model.\n-   Helps in cases where data reliability varies across groups.\n\n## Where Do We Get Weights for ANOVA?\n\n-   Weights can be derived from:\n    -   **Large-scale assessments**: Different student groups may have varying reliability in measurement.\n    -   **Survey data**: Unequal probability of selection can be adjusted using weights.\n    -   **Experimental data**: Measurement error models may dictate different weight assignments.\n\n## Example: Using Weights in Large-Scale Assessments\n\n-   Consider an educational study where test scores are collected from schools of varying sizes.\n-   Larger schools may contribute more observations but should not dominate the analysis.\n-   Weighting adjusts for this imbalance:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweights <- ifelse(data$group == \"LargeSchool\", 0.5, 1)\nanova_weighted <- aov(score ~ group, data = data, weights = weights)\nsummary(anova_weighted)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ngroup        3  724.1  241.37   11.45 2.04e-05 ***\nResiduals   36  759.2   21.09                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n-   Ensures fair representation in the analysis.\n\n## Conclusion and Interpretation\n\n-   Review results and discuss findings.\n-   Key takeaways from the analysis.\n\n\n",
    "supporting": [
      "ESRM64103_Lecture03_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}