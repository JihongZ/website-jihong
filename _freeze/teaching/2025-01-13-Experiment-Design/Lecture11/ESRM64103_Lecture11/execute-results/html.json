{
  "hash": "070529f270552f197fe0055edd17666a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lecture 11: Repeated Measure ANOVA\"\nsubtitle: \"Experimental Design in Education\"\ndate: \"2025-04-06\"\ndate-modified: \"2025-04-06\"\nexecute: \n  eval: true\n  echo: true\n  warning: false\n  message: false\nwebr:\n  editor-font-scale: 1.2\nformat: \n  html:\n    toc-expand: 3\n    code-tools: true\n    code-line-numbers: false\n    code-fold: false\n    code-summary: \"Click to see R code\"\n    number-offset: 1\n    fig.width: 10\n    fig-align: center\n    message: false\n    grid:\n      sidebar-width: 350px\n  uark-revealjs:\n    chalkboard: true\n    embed-resources: false\n    code-fold: false\n    number-sections: true\n    number-depth: 1\n    footer: \"ESRM 64503\"\n    slide-number: c/t\n    tbl-colwidths: auto\n    scrollable: true\n    output-file: slides-index.html\n    mermaid:\n      theme: forest    \n---\n\n\n\n\n\n\n::: objectives\n## Overview of Lecture 11 {.unnumbered}\n\n1.  The rest of the semester\n2.  Advantage of Factorial Design\n3.  Repeated-measure ANOVA:\n    -   Steps for conducting 2-way ANOVA\n    -   Hypothesis testing\n    -   Assumptions for 2-way ANOVA\n    -   Visualization\n    -   Difference between 1-way and 2-way ANOVA\n\n**Question**: How about the research scenario when more than two independent variables?\n:::\n\n## More independent variables\n\n-   When we want to add more independent variables to ANOVA-design,\n    1.  Blocking Design: 1 independent variable, 1 blocking variable\n    2.  Factorial Design: N-way ANOVA (e.g., 2-way ANOVA = 2 independent variables)\n    3.  Repeated Measures ANOVA: 1 independent variable measured only one time, and 1 independent variable measured repeated time points\n    4.  ANCOVA: 1 independent variable, and 1 covariate (continuous IV!)\n    5.  Mixed Design\n\n::: macwindow\nNote. All ANOVA-related designs talked about in this class can handle only one dependent variable; if you want to deal with more than 2 dependent variable, we may consider other research designs‚Ä¶\n:::\n\n## Procedure of RM ANOVA\n\n-   To conduct the hypothesis test, we follow:\n\n    1.  Set the null hypothesis, and the alternative hypothesis\n    2.  Determine alpha level, and calculate dfs ‚Üí critical value of test statistics\n    3.  Calculate the observed value of test statistics\n    4.  Make the statistical conclusion ‚Üí (1) critical vs. observed, OR (2) ùõº vs. p\n    5.  Make the research conclusion ‚Üí research question?\n\n-   Before conducting the hypothesis test, we check:\n\n    1.  Independence of observations ‚Üí [!!!ANOVA it NOT robust to violation of this!!!]{.redcolor}\n    2.  Normality ‚Üí ANOVA tends to be relatively robust to non-normality.\n    3.  Homogeneity of variance ‚Üí ANOVA can handle the violation of HOV when the group sizes are equal (i.e., balanced) and the group sizes are large enough. Or we can use Welch‚Äôs.\n\n-   Independence of the observations:\n\n    1.  Measurements from one case in the study are independent of other cases in the study.\n    2.  If we violate this assumption, we have to do something else!\n\n    -   ‚Üí One of the remedies would be to use ‚Äú**Repeated Measures ANOVA** (RM ANOVA)‚Äù\n\n## What Is RM ANOVA\n\n-   When multiple, repeat measurements are made on an experimental unit:\n    -   The observations can no longer be assumed to be independent.\n        -   ‚Üí Result: Correlations in the residual errors among time periods!\n        -   ‚Üí The correlations indicate the shared part among the individuals.\n    -   Not just over time, many other scenarios can result in repeated measures:\n        -   ‚Üí Ex: Cross-over design where the treatments themselves are switched on the same experimental unit during the course of the experiment.\n        -   ‚Üí In a cross-over design: each person goes through each treatment condition.\n        -   ‚Üí Repeated measures are frequently encountered in clinical trials, development of growth models, and situations in which experimental units are difficult to acquire.\n\n## RM ANOVA Design\n\n::::: columns\n::: {.column width=\"50%\"}\n![](images/within-subject-design.jpg){width=\"120%\"}\n:::\n\n::: {.column width=\"50%\"}\n![](images/crossover-repeated-measures-design.jpg){width=\"120%\"}\n:::\n\nSource: <https://explorable.com/repeated-measures-design>\n:::::\n\n## First Type of RM ANOVA: Repeated Measure Design\n\n-   Two types of repeated measures are common:\n    1.  Repeated measures in time: individuals receive a treatment, and then are followed with repeated measures on the response variable over several times.\n        -   [x] Ex: The dataset might be:\n        -   For example, Sally is only in the ‚ÄúNone‚Äù group. She never receives the ‚Äúdaily tutoring‚Äù condition.\n        -   Chi is only in the ‚Äúdaily tutoring‚Äù condition.\n\n| Tutoring Type | Time1 (1st week out) | Time2 (2nd week out) | Time3 (3rd week out) |\n|------------------|------------------|------------------|------------------|\n| None | Sally <br> Joe <br> Montes | Sally <br> Joe <br> Montes | Sally <br> Joe <br> Montes |\n| Once/week | Omar <br> Fred <br> Jenny | Omar <br> Fred <br> Jenny | Omar <br> Fred <br> Jenny |\n| Daily | Chi <br> Lena <br> Caroline | Chi <br> Lena <br> Caroline | Chi <br> Lena <br> Caroline |\n\n## Second Type of RM ANOVA: Cross-Over Design\n\n-   **Two types of repeated measures are common:**\n\n    2.  **Cross-over Design**: alternatively, experiments can involve administering all treatment levels (in a sequence) to each experimental unit.\n\n    -   [x] Require a wash-out period between treatment applications to prevent (or minimize) **carry-over effects**.\n        -   Carry-over effects occur when the application of one treatment affects the response of the next treatment applied in the cross-over design.\n    -   [x] The **order** of treatment administration in a crossover experiment is called a **‚Äúsequence.‚Äù**\n        -   The sequences should be determined a priori and the experimental units are randomized to sequences.\n    -   [x] **Time** of a treatment administration is called a **‚Äúperiod.‚Äù**\n        -   Treatments are designated with capital letters, such as A, B, etc.\n    -   [x] The most popular crossover design is the 2-sequence, 2-period, 2-treatment crossover design, with sequences AB and BA.\n        -   Often called the **2 √ó 2 crossover design**.\n\n## Cross-Over Design: 2 x 2\n\n2.  **Cross-over Design**: alternatively, experiments can involve administering all treatment levels (in a sequence) to each experimental unit.\n\n    -   [x] **2 √ó 2 crossover design**:\n        -   [x] Experimental units that are randomized to the AB sequence receive treatment A in the first period and treatment B in the second period.\n        -   [x] Experimental units that are randomized to the BA sequence receive treatment B in the first period and treatment A in the second period.\n\n    |                 | **Period 1** | **Period 2** |\n    |-----------------|--------------|--------------|\n    | **Sequence AB** | A            | B            |\n    | **Sequence BA** | B            | A            |\n\n:::: callout-important\nHow many potential sequences are for J x J design?\n\n::: mohu\n$$\n\\prod (J, J-1, \\cdots,1)\n$$\n:::\n::::\n\n## Cross-Over Design: 3 x 3\n\n-   **Two types of repeated measures are common:**\n\n    2.  **Cross-over Design**: alternatively, experiments can involve administering all treatment levels (in a sequence) to each experimental unit.\n\n    -   ‚úî **3 √ó 3 crossover design**:\n        -   ‚úî Consider a 3-treatment, 3-period design\\\n        -   ‚úî A = no tutoring, B = once/week, C = daily\n\n|                  | **Period 1** | **Period 2** | **Period 3** |\n|------------------|--------------|--------------|--------------|\n| **Sequence ABC** | A            | B            | C            |\n| **Sequence BCA** | B            | C            | A            |\n| **Sequence CAB** | C            | A            | B            |\n| **Sequence ACB** | A            | C            | B            |\n| **Sequence BAC** | B            | A            | C            |\n| **Sequence CBA** | C            | B            | A            |\n\n## Carryover effects in Cross-Over Design\n\n::: macwindow\n**Carryover effects**:\n\nIn a cross-over design, carryover effects refer to the residual effects of a treatment that persist and influence responses in subsequent treatment periods. Since each participant receives multiple treatments in sequence, the outcome measured in a later period may be affected not only by the current treatment but also by the lingering influence of prior treatments.\n:::\n\n-   ‚úî **Example**:\n\n    -   One student was measured three math tests (Math A/B/C). Math A and B has overlapping items with similar difficulty.\n    -   Consider a 3√ó3 crossover design where a subject receives treatments A, B, and C across three periods. If the subject receives treatment B in Period 1 and treatment A in Period 2, the effect observed in Period 2 may not reflect the pure effect of A‚Äîit may be contaminated by the residual effect of B, thus biasing the estimation of treatment A's effectiveness.\n\n-   **Discussion**: Can you think about more carryover effect in your research area?\n\n## Disadvantage of Cross-Over\n\n-   ‚úî **Main disadvantage**: carryover effects may be confounded with treatment effects, because these effects cannot be estimated separately.\n    -   ‚úî *Think about Sequence BCA*: You think you are estimating the effect of treatment A, but there is also a bias (or carryover) from the previous treatments to account for.\n-   ‚úî **However, carryover effects** can bias the interpretation of data analysis, so an investigator should proceed cautiously when implementing a crossover design.\n    -   ‚úî *So, what do we do?* Washout periods can diminish the impact of carryover effects\\\n    -   ‚ûî **Washout period**: time between treatment periods.\n-   ‚úî These are especially helpful in clinical trials: Instead of immediately stopping and then starting the new treatment, a period of time where the drug is washed out of the patient's system is used.\n    -   ‚úî *Ex: educational tests* ‚ûî Subjects may be affected permanently by what they learned during the first period.\n\n## RM ANOVA Factors\n\n-   As with any ANOVA, **repeated measures ANOVA tests the equality of means**.\n    -   But, the statistical approach might differ.\n-   **Statistical Terminology:**\n    -   When a dependent variable is measured repeatedly for all sampled, this set of conditions is called a **within-subjects factor**.\n        -   ‚úî **Time** (or trial) is typically used as our within-subject factor.\n    -   When a dependent variable is measured on independent groups of sample members, where each group is exposed to a different condition, the set of conditions is called a **between-subjects factor**.\n        -   ‚úî In the previous example, **tutoring type** would be the between-subject factor.\n        -   ‚úî We think of these as the IVs from our ‚Äúusual‚Äù ANOVAs.\n    -   When an analysis has both within-subjects factors and between-subjects factors, and considers their interaction effect, it is called a **mixed design**.\\\n        *(We will talk about it later!)*\n\n## RM ANOVA Logic\n\n-   The logic behind a **repeated measures ANOVA** is very similar to that of a **between-subjects ANOVA**.\n-   Recall that in a **between-subjects ANOVA** (i.e., the ‚Äúusual‚Äù ANOVA), we partition total variability into:\n    -   **Model** (i.e., between-groups variability; SS<sub>Model</sub>)\n    -   **Error** (i.e., within-groups variability; SS<sub>Error</sub>)\n\n![](images/clipboard-1193144382.png)\n\n## RM ANOVA Logic II\n\n-   In this design, **within-group variability** (SS<sub>w</sub>) is used as the **error variability** (SS<sub>Error</sub>).\n\n    -   That said, \"Why subjects differ within the same group\" is **unexplained**!\n\n-   The **F-statistic** is calculated as the ratio of MS<sub>Model</sub> to MS<sub>Error</sub>:\n\n    *Independent ANOVA:*\\\n    $$ F = \\frac{MS_b}{MS_w} = \\frac{MS_b}{MS_{error}} $$\n\n## RM ANOVA Logic III\n\n::: callout-important\n\"Why subjects differ within the same group (e.g., treatment/control groups)\" can be **explained** in RM ANOVA!\n:::\n\n::::: columns\n::: column\n-   **The advantage of a repeated measures ANOVA**:\n\n    -   ‚úî Within-group variability (SS<sub>w</sub>) is the error variability (SS<sub>error</sub>) in an independent (between-subjects) ANOVA.\\\n    -   ‚úî But, in a repeated measures ANOVA we further partition this error term, reducing its size, and **increasing power**!\n\n-   **A repeated measures ANOVA calculates an F-statistic in a similar way**:\n\n    -   *Repeated Measures ANOVA:* $F = \\frac{MS_{conditions}}{MS_{error}}$\n:::\n\n::: column\n![](images/Lecture%2011_%20Repeated%20Measure%20ANOVA-2025-04-06-232317.png) Generated by <https://www.mermaidchart.com/app/projects>\n:::\n:::::\n\n## RM ANOVA Logic IV\n\n-   Mathematically, we are partitioning the variability attributable to the differences between groups (SS<sub>conditions</sub>) and variability within groups (SS<sub>w</sub>) exactly as we do in a between-subjects (independent) ANOVA.\n\n-   With a repeated measures ANOVA, we are using the same subjects in each group, so we can remove the variability due to the individual differences *between subjects*, referred to as SS<sub>subjects</sub>, from the within-groups variability (SS<sub>w</sub>).\n\n-   We simply **treat each subject as a ‚Äúblock.‚Äù**\n\n    -   ‚úî Each subject becomes a level of a factor, called **subjects**.\n    -   ‚úî Then, we **do not care** about the **interaction** between within- and between-subjects.\n\n-   The ability to subtract SS<sub>subjects</sub> will leave us with a smaller SS<sub>error</sub> term:\n\n    *Independent ANOVA:* $SS_{error} = SS_{w}$\n\n    *Repeated Measures ANOVA:* $SS_{error} = SS_{w} - SS_{subjects}$\n\n## Example #1\n\n-   **Researchers are interested in the effect of drug on blood concentration of histamine at 0, 1, 3, and 5 minutes after injection of the drug.**\n    -   **Subjects**: dogs\n    -   ‚úî **DV**: blood concentration of histamine\n    -   ‚úî **Within-subject factor**: time (4 levels: 0, 1, 3, and 5 minutes)\n-   Six dogs, four time points\n\n| Dog ID        | time1     | time2     | time3     | time4     | Dog mean               |\n|------------|------------|------------|------------|------------|------------|\n| 1             | 10        | 16        | 25        | 26        | 19.25                  |\n| 2             | 12        | 19        | 27        | 25        | 20.75                  |\n| 3             | 13        | 20        | 28        | 28        | 22.25                  |\n| 4             | 12        | 18        | 25        | 15        | 17.50                  |\n| 5             | 11        | 20        | 26        | 18        | 18.75                  |\n| 6             | 10        | 22        | 27        | 19        | 19.50                  |\n| **Time mean** | **11.33** | **19.17** | **26.33** | **21.83** | **Grand mean = 19.67** |\n\n## Table for RM ANOVA Report\n\n| Source           | Sub-Component | SS  | df  | MS  | F   |\n|------------------|---------------|-----|-----|-----|-----|\n| Between-time     |               |     |     |     |     |\n| Within-time      |               |     |     |     |     |\n| Between-Subjects |               |     |     |     |     |\n| Error            |               |     |     |     |     |\n\n: üî¥ ANOVA Table of Repeated Measures ANOVA {tbl-colwidths=\"\\[30,30,10,10,10,10\\]\"}\n\n***Note.*** Under the repeated measures ANOVA, we can decompose the total variability:\n\n**Total variability of DV = \"between-time\" variability + \"within-time\" variability**\n\n-   ‚ûî *\"within-time\"* variability = *\"between-subjects\"* variability + *\"within-subjects\"* variability\\\n-   ‚ûî *\"within-subjects\"* variability is treated as **\"error\"**\n\n---\n\n### Think about ‚Äúbetween-time‚Äù row in ANOVA table\n\n:::::: panel-tabset\n#### Statistics\n\nWe calculate mean square for **between-time** as:\n\n$$\nMS_{btime} = \\frac{SS_{btime}}{df_{btime}}\n$$\n\nWhere:\n\n$$\nSS_{btime} = \\sum n_{time}(\\bar{Y}_{time} - \\bar{Y}_{grand})^2 = \n6(11.33 - 19.67)^2 + \\cdots + 6(21.83 - 19.67)^2 = 712.961\n$$\n\n$$\ndf_{btime} = \\text{Number of time points} - 1 = 4 - 1 = 3\n$$\n\nThus,\n\n$$\nMS_{btime} = \\frac{712.96}{3} = 237.65\n$$\n\n#### Results\n\n::::: columns\n::: column\n| Dog ID         | time1 | time2 | time3 | time4 | Dog mean               |\n|----------------|-------|-------|-------|-------|------------------------|\n| 1              | 10    | 16    | 25    | 26    | 19.25                  |\n| 2              | 12    | 19    | 27    | 25    | 20.75                  |\n| 3              | 13    | 20    | 28    | 28    | 22.25                  |\n| 4              | 12    | 18    | 25    | 15    | 17.50                  |\n| 5              | 11    | 20    | 26    | 18    | 18.75                  |\n| 6              | 10    | 22    | 27    | 19    | 19.50                  |\n| **Time means** | 11.33 | 19.17 | 26.33 | 21.83 | **Grand Mean = 19.67** |\n\n: Data\n:::\n\n::: column\n| Source           | SS     | df  | MS     | F   |\n|------------------|--------|-----|--------|-----|\n| Between-time     | 712.96 | 3   | 237.65 |     |\n| Within-time      |        |     |        |     |\n| Between-Subjects |        |     |        |     |\n| Error            |        |     |        |     |\n\n: ANOVA Table (Partial)\n:::\n:::::\n::::::\n\n---\n\n### Think about ‚Äúbetween-dog‚Äù row in ANOVA table\n\n:::::: panel-tabset\n#### Statistics\n\nWe calculate mean square for **between-subjects** (between-dog) as:\n\n$$\nMS_{bsubjects} = \\frac{SS_{bsubjects}}{df_{bsubjects}}\n$$\n\nWhere:\n\n$$\nSS_{bsubjects} = \\sum k_i(\\bar{Y}_i - \\bar{Y}_{grand})^2 = \n4*(19.25 - 19.67)^2 + \\cdots + 4*(19.50 - 19.67)^2 = 54.33\n$$\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Click here to see R code\"}\ndog_means <- c(19.25, 20.75, 22.25, 17.50, 18.75, 19.50 )\nsum(4 * (dog_means - 19.67)^2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 54.3336\n```\n\n\n:::\n:::\n\n\n\n\n\n\n$$\ndf_{bsubject} = N_{dogs} - 1 = 6 - 1 = 5\n$$\n\nThus,\n\n$$\nMS_{bsubjects} = \\frac{54.33}{5} = 10.866\n$$\n\n#### Results\n\n::::: columns\n::: column\n| Dog ID         | time1 | time2 | time3 | time4 | Dog mean               |\n|----------------|-------|-------|-------|-------|------------------------|\n| 1              | 10    | 16    | 25    | 26    | 19.25                  |\n| 2              | 12    | 19    | 27    | 25    | 20.75                  |\n| 3              | 13    | 20    | 28    | 28    | 22.25                  |\n| 4              | 12    | 18    | 25    | 15    | 17.50                  |\n| 5              | 11    | 20    | 26    | 18    | 18.75                  |\n| 6              | 10    | 22    | 27    | 19    | 19.50                  |\n| **Time means** | 11.33 | 19.17 | 26.33 | 21.83 | **Grand Mean = 19.67** |\n\n: Data\n:::\n\n::: column\n| Source           | SS     | df  | MS     | F   |\n|------------------|--------|-----|--------|-----|\n| Between-time     | 712.96 | 3   | 237.65 |     |\n| Within-time      |        |     |        |     |\n| Between-Subjects | 54.33  | 5   | 10.87  |     |\n| Error            |        |     |        |     |\n\n: ANOVA Table (Partial)\n:::\n:::::\n::::::\n\n---\n\n### Think about ‚Äúwithin-time‚Äù row in ANOVA table\n\n:::::: panel-tabset\n#### Statistics\n\nWe calculate the mean square for within-time as:\n\n$$\nMS_{wtime} = \\frac{SS_{wtime}}{df_{wtime}}\n$$\n\nWhere:\n\n$$\nSS_{wtime} = \\sum_{i,time}(y_{i,time} - \\bar{Y}_{time})^2 = \n(10 - 11.33)^2 + \\cdots + (19 - 21.83)^2 = 170.33\n$$\n\n$$\ndf_{wtime} = (6 - 1) + (6 - 1) + (6 - 1) + (6 - 1) = 20\n$$\n\nThus,\n\n$$\nMS_{wtime} = \\frac{170.33}{20} = 8.5165\n$$\n\n#### Results\n\n::::: columns\n::: column\n| Dog ID         | time1 | time2 | time3 | time4 | Dog mean               |\n|----------------|-------|-------|-------|-------|------------------------|\n| 1              | 10    | 16    | 25    | 26    | 19.25                  |\n| 2              | 12    | 19    | 27    | 25    | 20.75                  |\n| 3              | 13    | 20    | 28    | 28    | 22.25                  |\n| 4              | 12    | 18    | 25    | 15    | 17.50                  |\n| 5              | 11    | 20    | 26    | 18    | 18.75                  |\n| 6              | 10    | 22    | 27    | 19    | 19.50                  |\n| **Time means** | 11.33 | 19.17 | 26.33 | 21.83 | **Grand Mean = 19.67** |\n\n: Data\n:::\n\n::: column\n| Source           | SS     | df  | MS     | F   |\n|------------------|--------|-----|--------|-----|\n| Between-time     | 712.96 | 3   | 237.65 |     |\n| Within-time      | 170.33 | 20  | 8.52   |     |\n| Between-Subjects | 54.33  | 5   | 10.87  |     |\n| Error            |        |     |        |     |\n\n: ANOVA Table (Partial)\n:::\n:::::\n::::::\n\n---\n\n### Think about ‚ÄúError‚Äù row in ANOVA table\n\n:::::: panel-tabset\n#### Statistics\n\nWe calculate the mean square for error as:\n\n$$\nMS_{error} = \\frac{SS_{error}}{df_{error}}\n$$\n\nWhere:\n\n$$\nSS_{error} = SS_{wtime} - SS_{bsubjects} = 170.33 - 54.33 = 116\n$$\n\n$$\ndf_{error} = df_{wtime} - df_{bsubjects} = 20 - 5 = 15\n$$\n\nThus:\n\n$$\nMS_{error} = \\frac{116}{15} = 7.333\n$$\n\n#### Results\n\n::::: columns\n::: column\n| Dog ID         | time1 | time2 | time3 | time4 | Dog mean               |\n|----------------|-------|-------|-------|-------|------------------------|\n| 1              | 10    | 16    | 25    | 26    | 19.25                  |\n| 2              | 12    | 19    | 27    | 25    | 20.75                  |\n| 3              | 13    | 20    | 28    | 28    | 22.25                  |\n| 4              | 12    | 18    | 25    | 15    | 17.50                  |\n| 5              | 11    | 20    | 26    | 18    | 18.75                  |\n| 6              | 10    | 22    | 27    | 19    | 19.50                  |\n| **Time means** | 11.33 | 19.17 | 26.33 | 21.83 | **Grand Mean = 19.67** |\n\n: Data\n:::\n\n::: column\n| Source           | SS     | df  | MS     | F   |\n|------------------|--------|-----|--------|-----|\n| Between-time     | 712.96 | 3   | 237.65 |     |\n| Within-time      | 170.33 | 20  | 8.52   |     |\n| Between-Subjects | 54.33  | 5   | 10.87  |     |\n| Error            | 116.00 | 15  | 7.33   |     |\n\n: ANOVA Table (Complete)\n:::\n:::::\n::::::\n\n## Hypothesis Test Procedure\n\n### ‚úÖ Main Effect of Time:\n\n**Research Question:**\\\nDoes histamine concentration change over time?\\\n(That is, does mean histamine concentration differ across the four time points?)\n\n**Null Hypothesis:**\\\n$$\nH_0: \\mu_{time1} = \\mu_{time2} = \\mu_{time3} = \\mu_{time4}\n$$\n\n::::: columns\n::: column\n**ANOVA Table**\n\n| Source           | SS     | df  | MS     | F                         |\n|------------------|--------|-----|--------|---------------------------|\n| **Between-time** | 712.96 | 3   | 237.65 | **237.65 / 7.33 = 30.73** |\n| Within-time      | 170.33 | 20  | 8.52   | 8.52 / 7.33 = 1.16        |\n| Between-Subjects | 54.33  | 5   | 10.87  | 10.87 / 7.33 = 1.48       |\n| Error            | 116.00 | 15  | 7.33   |                           |\n:::\n\n::: column\n**Conclusion**\n\n-   Under $\\alpha = 0.05$, the critical value for $df_{time} = 3$ and $df_{error} = 15$ from the F-table is:\\\n    $F_{crit} = 3.29$\n\n-   Since the observed F-value for the time effect is **30.73**, which exceeds the critical value of 3.29:\n\n    -   ‚úÖ We **reject the null hypothesis**.\n    -   ‚úÖ There is a **significant main effect of time**.\n\n**Conclusion:**\\\nThere is a significant difference in histamine concentration across the four time points.\n:::\n:::::\n\n## Repeated Measures ANOVA: Assumption I\n\n::::: columns\n::: column\nüîç Before conducting the hypothesis test, we check:\n\n1.  **Independence of observations**\\\n    ‚ûî **!!! ANOVA is NOT robust to violation of this !!!**\n\n2.  **Normality**\\\n    ‚ûî ANOVA tends to be relatively robust to non-normality.\n\n3.  **Homogeneity of variance (HOV)**\\\n    ‚ûî ANOVA can handle HOV violations when:\n\n    -   Group sizes are equal (i.e., balanced)\n    -   Group sizes are large enough\\\n        ‚ûî Otherwise, consider using **Welch‚Äôs ANOVA**\n:::\n\n::: column\n‚úÖ Independence of the Observations:\n\n-   ‚úî **Measurements from one case in the study are independent of other cases in the study.**\n-   ‚úî **If we violate this assumption, we have to do something else!**\\\n    ‚ûî One remedy would be to use **repeated measures ANOVA**.\n:::\n:::::\n\n‚ùì Then, which assumption should we check for **repeated measures ANOVA**?\n\n## Repeated Measures ANOVA: Assumption II\n\n### üîç Before conducting the hypothesis test, we check:\n\n1.  **Independency**\\\n    ‚ûî **Do not need to check!** (in repeated measures designs)\n\n2.  **Normality**\\\n    ‚ûî The dependent variable (DV) at each level of the independent variable(s) should be approximately normally distributed.\\\n    ‚ûî However, ANOVA tends to be **relatively robust to non-normality**.\n\n3.  **Instead of HOV (Homogeneity of Variance)**\\\n    ‚ûî We should check **\"Sphericity\"**\n\n### üß† Sphericity\n\n-   The concept of **sphericity** is the repeated measures equivalent of homogeneity of variances.\n-   Sphericity is the condition where **the variances of the differences** between all combinations of related groups (levels) are equal.\n-   Violation of sphericity occurs when **the variances of the differences** between all combinations of related groups are **not equal**.\n-   Testing for sphericity\n    -   is an option in **PROC GLM** using **Mauchly's Test for Sphericity**.\n    -   In R, testing for sphericity in a repeated measures ANOVA is typically conducted using the `anova_test()` function from the `rstatix` package, which includes Mauchly‚Äôs Test of Sphericity.\n    \n## Sphericity Illustration\n\n::: panel-tabset\n\n### Table\n| Dog ID | time1 | time2 | time3 | t1 - t2 | t1 - t3 | t2 - t3 |\n|--------|-------|-------|-------|---------|---------|---------|\n| 1      | 10    | 16    | 25    | -6      | -15     | -9      |\n| 2      | 12    | 19    | 27    | -7      | -15     | -8      |\n| 3      | 13    | 20    | 28    | -7      | -15     | -8      |\n| 4      | 12    | 18    | 25    | -6      | -13     | -7      |\n| 5      | 11    | 20    | 26    | -9      | -15     | -6      |\n| 6      | 10    | 22    | 27    | -12     | -17     | -5      |\n| **Variance** |       |       |       | **5.367** | **1.6** | **2.167** |\n\n### Figure\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Click to see code\"}\nlibrary(tidyverse)\nlibrary(plotly)\ndat_wide <- tribble(\n  ~ID, ~T1, ~T2, ~T3,\n  1, 10, 16, 25,\n  2, 12, 19, 27,\n  3, 13, 20, 28,\n  4, 12, 18, 25,\n  5, 11, 20, 26,\n  6, 10, 22, 27\n)\ndat_long <- dat_wide |> \n  pivot_longer(starts_with(\"T\"), names_to = \"Time\", values_to = \"Y\") |> \n  mutate(Time = factor(Time, levels = paste0(\"T\",1:3)),\n         ID = factor(ID, levels = 1:6)) \ndat_long |> \n  plot_ly(x=~Time, y=~Y) |> \n  add_markers(color=~ID) |> \n  add_lines(color=~ID)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"plotly html-widget html-fill-item\" id=\"htmlwidget-f31918d76f905061697c\" style=\"width:100%;height:464px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-f31918d76f905061697c\">{\"x\":{\"visdat\":{\"a92ad278add\":[\"function () \",\"plotlyVisDat\"]},\"cur_data\":\"a92ad278add\",\"attrs\":{\"a92ad278add\":{\"x\":{},\"y\":{},\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"scatter\",\"mode\":\"markers\",\"color\":{},\"inherit\":true},\"a92ad278add.1\":{\"x\":{},\"y\":{},\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"scatter\",\"mode\":\"lines\",\"color\":{},\"inherit\":true}},\"layout\":{\"margin\":{\"b\":40,\"l\":60,\"t\":25,\"r\":10},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"title\":\"Time\",\"type\":\"category\",\"categoryorder\":\"array\",\"categoryarray\":[\"T1\",\"T2\",\"T3\"]},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"title\":\"Y\"},\"hovermode\":\"closest\",\"showlegend\":true},\"source\":\"A\",\"config\":{\"modeBarButtonsToAdd\":[\"hoverclosest\",\"hovercompare\"],\"showSendToCloud\":false},\"data\":[{\"x\":[\"T1\",\"T2\",\"T3\"],\"y\":[10,16,25],\"type\":\"scatter\",\"mode\":\"markers\",\"name\":\"1\",\"marker\":{\"color\":\"rgba(102,194,165,1)\",\"line\":{\"color\":\"rgba(102,194,165,1)\"}},\"textfont\":{\"color\":\"rgba(102,194,165,1)\"},\"error_y\":{\"color\":\"rgba(102,194,165,1)\"},\"error_x\":{\"color\":\"rgba(102,194,165,1)\"},\"line\":{\"color\":\"rgba(102,194,165,1)\"},\"xaxis\":\"x\",\"yaxis\":\"y\",\"frame\":null},{\"x\":[\"T1\",\"T2\",\"T3\"],\"y\":[12,19,27],\"type\":\"scatter\",\"mode\":\"markers\",\"name\":\"2\",\"marker\":{\"color\":\"rgba(252,141,98,1)\",\"line\":{\"color\":\"rgba(252,141,98,1)\"}},\"textfont\":{\"color\":\"rgba(252,141,98,1)\"},\"error_y\":{\"color\":\"rgba(252,141,98,1)\"},\"error_x\":{\"color\":\"rgba(252,141,98,1)\"},\"line\":{\"color\":\"rgba(252,141,98,1)\"},\"xaxis\":\"x\",\"yaxis\":\"y\",\"frame\":null},{\"x\":[\"T1\",\"T2\",\"T3\"],\"y\":[13,20,28],\"type\":\"scatter\",\"mode\":\"markers\",\"name\":\"3\",\"marker\":{\"color\":\"rgba(141,160,203,1)\",\"line\":{\"color\":\"rgba(141,160,203,1)\"}},\"textfont\":{\"color\":\"rgba(141,160,203,1)\"},\"error_y\":{\"color\":\"rgba(141,160,203,1)\"},\"error_x\":{\"color\":\"rgba(141,160,203,1)\"},\"line\":{\"color\":\"rgba(141,160,203,1)\"},\"xaxis\":\"x\",\"yaxis\":\"y\",\"frame\":null},{\"x\":[\"T1\",\"T2\",\"T3\"],\"y\":[12,18,25],\"type\":\"scatter\",\"mode\":\"markers\",\"name\":\"4\",\"marker\":{\"color\":\"rgba(231,138,195,1)\",\"line\":{\"color\":\"rgba(231,138,195,1)\"}},\"textfont\":{\"color\":\"rgba(231,138,195,1)\"},\"error_y\":{\"color\":\"rgba(231,138,195,1)\"},\"error_x\":{\"color\":\"rgba(231,138,195,1)\"},\"line\":{\"color\":\"rgba(231,138,195,1)\"},\"xaxis\":\"x\",\"yaxis\":\"y\",\"frame\":null},{\"x\":[\"T1\",\"T2\",\"T3\"],\"y\":[11,20,26],\"type\":\"scatter\",\"mode\":\"markers\",\"name\":\"5\",\"marker\":{\"color\":\"rgba(166,216,84,1)\",\"line\":{\"color\":\"rgba(166,216,84,1)\"}},\"textfont\":{\"color\":\"rgba(166,216,84,1)\"},\"error_y\":{\"color\":\"rgba(166,216,84,1)\"},\"error_x\":{\"color\":\"rgba(166,216,84,1)\"},\"line\":{\"color\":\"rgba(166,216,84,1)\"},\"xaxis\":\"x\",\"yaxis\":\"y\",\"frame\":null},{\"x\":[\"T1\",\"T2\",\"T3\"],\"y\":[10,22,27],\"type\":\"scatter\",\"mode\":\"markers\",\"name\":\"6\",\"marker\":{\"color\":\"rgba(255,217,47,1)\",\"line\":{\"color\":\"rgba(255,217,47,1)\"}},\"textfont\":{\"color\":\"rgba(255,217,47,1)\"},\"error_y\":{\"color\":\"rgba(255,217,47,1)\"},\"error_x\":{\"color\":\"rgba(255,217,47,1)\"},\"line\":{\"color\":\"rgba(255,217,47,1)\"},\"xaxis\":\"x\",\"yaxis\":\"y\",\"frame\":null},{\"x\":[\"T1\",\"T2\",\"T3\"],\"y\":[10,16,25],\"type\":\"scatter\",\"mode\":\"lines\",\"name\":\"1\",\"marker\":{\"color\":\"rgba(102,194,165,1)\",\"line\":{\"color\":\"rgba(102,194,165,1)\"}},\"textfont\":{\"color\":\"rgba(102,194,165,1)\"},\"error_y\":{\"color\":\"rgba(102,194,165,1)\"},\"error_x\":{\"color\":\"rgba(102,194,165,1)\"},\"line\":{\"color\":\"rgba(102,194,165,1)\"},\"xaxis\":\"x\",\"yaxis\":\"y\",\"frame\":null},{\"x\":[\"T1\",\"T2\",\"T3\"],\"y\":[12,19,27],\"type\":\"scatter\",\"mode\":\"lines\",\"name\":\"2\",\"marker\":{\"color\":\"rgba(252,141,98,1)\",\"line\":{\"color\":\"rgba(252,141,98,1)\"}},\"textfont\":{\"color\":\"rgba(252,141,98,1)\"},\"error_y\":{\"color\":\"rgba(252,141,98,1)\"},\"error_x\":{\"color\":\"rgba(252,141,98,1)\"},\"line\":{\"color\":\"rgba(252,141,98,1)\"},\"xaxis\":\"x\",\"yaxis\":\"y\",\"frame\":null},{\"x\":[\"T1\",\"T2\",\"T3\"],\"y\":[13,20,28],\"type\":\"scatter\",\"mode\":\"lines\",\"name\":\"3\",\"marker\":{\"color\":\"rgba(141,160,203,1)\",\"line\":{\"color\":\"rgba(141,160,203,1)\"}},\"textfont\":{\"color\":\"rgba(141,160,203,1)\"},\"error_y\":{\"color\":\"rgba(141,160,203,1)\"},\"error_x\":{\"color\":\"rgba(141,160,203,1)\"},\"line\":{\"color\":\"rgba(141,160,203,1)\"},\"xaxis\":\"x\",\"yaxis\":\"y\",\"frame\":null},{\"x\":[\"T1\",\"T2\",\"T3\"],\"y\":[12,18,25],\"type\":\"scatter\",\"mode\":\"lines\",\"name\":\"4\",\"marker\":{\"color\":\"rgba(231,138,195,1)\",\"line\":{\"color\":\"rgba(231,138,195,1)\"}},\"textfont\":{\"color\":\"rgba(231,138,195,1)\"},\"error_y\":{\"color\":\"rgba(231,138,195,1)\"},\"error_x\":{\"color\":\"rgba(231,138,195,1)\"},\"line\":{\"color\":\"rgba(231,138,195,1)\"},\"xaxis\":\"x\",\"yaxis\":\"y\",\"frame\":null},{\"x\":[\"T1\",\"T2\",\"T3\"],\"y\":[11,20,26],\"type\":\"scatter\",\"mode\":\"lines\",\"name\":\"5\",\"marker\":{\"color\":\"rgba(166,216,84,1)\",\"line\":{\"color\":\"rgba(166,216,84,1)\"}},\"textfont\":{\"color\":\"rgba(166,216,84,1)\"},\"error_y\":{\"color\":\"rgba(166,216,84,1)\"},\"error_x\":{\"color\":\"rgba(166,216,84,1)\"},\"line\":{\"color\":\"rgba(166,216,84,1)\"},\"xaxis\":\"x\",\"yaxis\":\"y\",\"frame\":null},{\"x\":[\"T1\",\"T2\",\"T3\"],\"y\":[10,22,27],\"type\":\"scatter\",\"mode\":\"lines\",\"name\":\"6\",\"marker\":{\"color\":\"rgba(255,217,47,1)\",\"line\":{\"color\":\"rgba(255,217,47,1)\"}},\"textfont\":{\"color\":\"rgba(255,217,47,1)\"},\"error_y\":{\"color\":\"rgba(255,217,47,1)\"},\"error_x\":{\"color\":\"rgba(255,217,47,1)\"},\"line\":{\"color\":\"rgba(255,217,47,1)\"},\"xaxis\":\"x\",\"yaxis\":\"y\",\"frame\":null}],\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.20000000000000001,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n\n\n:::\n\n\nThis table presents:\n\n- The raw time-point measurements (time1, time2, time3)\n- Pairwise difference scores (t1 - t2, t1 - t3, t2 - t3)\n- Variance of each set of pairwise differences at the bottom (used to assess sphericity)\n\n[We are concerned with these variances for ‚Äúsphericity‚Äù]{.redcolor}\n\n\n## ‚úÖ Step-by-step: Testing Sphericity in R\n\n::: panel-tabset\n### 1. Prepare your data\n\nYou need your data in **long format**: one row per subject per time point.\n\nExample:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rstatix)\nlibrary(tidyverse)\n# Sample wide-format data\nhead(dat_long)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 √ó 3\n  ID    Time      Y\n  <fct> <fct> <dbl>\n1 1     T1       10\n2 1     T2       16\n3 1     T3       25\n4 2     T1       12\n5 2     T2       19\n6 2     T3       27\n```\n\n\n:::\n:::\n\n\n\n\n\n\n### 2. Run repeated measures ANOVA with sphericity test\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova_results <- dat_long %>%\n  anova_test(dv = Y, wid = ID, within = Time)\n\nanova_results\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nANOVA Table (type III tests)\n\n$ANOVA\n  Effect DFn DFd       F       p p<.05  ges\n1   Time   2  10 221.861 5.2e-09     * 0.95\n\n$`Mauchly's Test for Sphericity`\n  Effect     W     p p<.05\n1   Time 0.407 0.165      \n\n$`Sphericity Corrections`\n  Effect   GGe     DF[GG]   p[GG] p[GG]<.05   HFe     DF[HF]    p[HF] p[HF]<.05\n1   Time 0.628 1.26, 6.28 2.8e-06         * 0.739 1.48, 7.39 4.28e-07         *\n```\n\n\n:::\n:::\n\n\n\n\n\n\n-   This will output:\n\n    1.  ANOVA table\n    2.  **Mauchly‚Äôs Test of Sphericity**\n    3.  **Greenhouse-Geisser** and **Huynh-Feldt** corrections (if sphericity is violated)\n\n### 3. View the sphericity test\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova_results$`Mauchly's Test for Sphericity`\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Effect     W     p p<.05\n1   Time 0.407 0.165      \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nanova_results$`Sphericity Corrections`\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Effect   GGe     DF[GG]   p[GG] p[GG]<.05   HFe     DF[HF]    p[HF] p[HF]<.05\n1   Time 0.628 1.26, 6.28 2.8e-06         * 0.739 1.48, 7.39 4.28e-07         *\n```\n\n\n:::\n:::\n\n\n\n\n\n\n### üìå Interpreting the Output:\n\n| Test | Interpretation |\n|--------------------------|----------------------------------------------|\n| **Mauchly's Test (p \\> .05)** | Sphericity holds ‚Äì use standard F-statistic |\n| **Mauchly's Test (p \\< .05)** | Sphericity violated ‚Äì use corrected F-statistics |\n\nIf violated, refer to the corrected tests: \n\n  - Use **Greenhouse-Geisser** correction unless `epsilon > 0.75` \n  - Otherwise, **Huynh-Feldt** is often preferred\n\n### üìù Example Reporting:\n\n> Mauchly's test indicated that the assumption of sphericity had not been violated, W = 0.407, p = .165. We can use standard F-test.\n\n:::\n\n\n## Fin\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../../site_libs/htmltools-fill-0.5.8.1/fill.css\" rel=\"stylesheet\" />\n<script src=\"../../../site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<script src=\"../../../site_libs/plotly-binding-4.10.4/plotly.js\"></script>\n<script src=\"../../../site_libs/typedarray-0.1/typedarray.min.js\"></script>\n<script src=\"../../../site_libs/jquery-3.5.1/jquery.min.js\"></script>\n<link href=\"../../../site_libs/crosstalk-1.2.1/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"../../../site_libs/crosstalk-1.2.1/js/crosstalk.min.js\"></script>\n<link href=\"../../../site_libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css\" rel=\"stylesheet\" />\n<script src=\"../../../site_libs/plotly-main-2.11.1/plotly-latest.min.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}