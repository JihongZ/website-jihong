{
  "hash": "ef8ff7dce53a91a3c9f6d1e38d2517f1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lecture 07: Matrix Algebra\"\nsubtitle: \"Matrix Algebra in R\"\nauthor: \"Jihong Zhang*, Ph.D\"\ninstitute: | \n  Educational Statistics and Research Methods (ESRM) Program*\n  University of Arkansas\ndate: \"2024-10-07\"\nsidebar: false\nexecute: \n  echo: true\n  warning: false\noutput-location: column\ncode-annotations: below\nformat: \n  uark-revealjs:\n    scrollable: true\n    chalkboard: true\n    embed-resources: false\n    code-fold: false\n    number-sections: false\n    footer: \"ESRM 64503 - Lecture 07: Matrix Algebra\"\n    slide-number: c/t\n    tbl-colwidths: auto\n    output-file: slides-index.html\n  html: \n    page-layout: full\n    toc: true\n    toc-depth: 2\n    toc-expand: true\n    lightbox: true\n    code-fold: false\n    fig-align: center\nfilters:\n  - quarto\n  - webr\n  - line-highlight\n---\n\n## Today's Class\n\n-   Matrix Algebra\n-   Multivariate Normal Distribution\n-   Multivariate Linear Analysis\n\n## Spring 2026 Course - Advanced Multivariate Analysis \n\n1.  See the online syllabus [here](https://jihongzhang.org/teaching/2024-01-12-syllabus-adv-multivariate-esrm-6553/ESRM6554_syllabus.html)\n\n2.  Recommended for ESRM students and others interested in applied statistics in the social sciences.\n\n# A Brief Introduction to Matrices\n\n## Today's Example Data\n\n-   Imagine that I collected SAT test scores for both the Math (SATM) and Verbal (SATV) sections for 1,000 students.\n\n\n::: {.cell output-location='default'}\n\n```{.r .cell-code}\nlibrary(ESRM64503)\nlibrary(kableExtra)\nshow_table(head(dataSAT))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> id </th>\n   <th style=\"text-align:right;\"> SATV </th>\n   <th style=\"text-align:right;\"> SATM </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 520 </td>\n   <td style=\"text-align:right;\"> 580 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 520 </td>\n   <td style=\"text-align:right;\"> 550 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 460 </td>\n   <td style=\"text-align:right;\"> 440 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 560 </td>\n   <td style=\"text-align:right;\"> 530 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:right;\"> 430 </td>\n   <td style=\"text-align:right;\"> 440 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 6 </td>\n   <td style=\"text-align:right;\"> 490 </td>\n   <td style=\"text-align:right;\"> 530 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n---------------\n\nLast several rows of the data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_table(tail(dataSAT))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">  </th>\n   <th style=\"text-align:right;\"> id </th>\n   <th style=\"text-align:right;\"> SATV </th>\n   <th style=\"text-align:right;\"> SATM </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 995 </td>\n   <td style=\"text-align:right;\"> 995 </td>\n   <td style=\"text-align:right;\"> 570 </td>\n   <td style=\"text-align:right;\"> 560 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 996 </td>\n   <td style=\"text-align:right;\"> 996 </td>\n   <td style=\"text-align:right;\"> 480 </td>\n   <td style=\"text-align:right;\"> 420 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 997 </td>\n   <td style=\"text-align:right;\"> 997 </td>\n   <td style=\"text-align:right;\"> 430 </td>\n   <td style=\"text-align:right;\"> 330 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 998 </td>\n   <td style=\"text-align:right;\"> 998 </td>\n   <td style=\"text-align:right;\"> 560 </td>\n   <td style=\"text-align:right;\"> 540 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 999 </td>\n   <td style=\"text-align:right;\"> 999 </td>\n   <td style=\"text-align:right;\"> 470 </td>\n   <td style=\"text-align:right;\"> 410 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 1000 </td>\n   <td style=\"text-align:right;\"> 1000 </td>\n   <td style=\"text-align:right;\"> 540 </td>\n   <td style=\"text-align:right;\"> 660 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n---------------\n\nRelationship between SATV and SATM:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(dataSAT$SATV, dataSAT$SATM)\n```\n\n::: {.cell-output-display}\n![](Lecture07_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n## Background\n\n-   Matrix operations are fundamental to all modern statistical software.\n\n-   When you installed R, it also came with required matrix algorithm libraries. Two popular ones are **BLAS** and **LAPACK**.\n\n    -   Other optimized libraries include OpenBLAS, AtlasBLAS, GotoBLAS, and Intel MKL.\n\n        `{bash} Matrix products: default LAPACK: /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRlapack.dylib`\n\n-   From the LAPACK [website](https://www.netlib.org/lapack/),\n\n    > **LAPACK** is written in Fortran 90 and provides routines for solving systems of simultaneous linear equations, least-squares solutions of linear systems of equations, eigenvalue problems, and singular value problems.\n    >\n    > LAPACK routines are written so that as much as possible of the computation is performed by calls to the Basic Linear Algebra Subprograms (**BLAS**).\n\n## Matrix Elements\n\n-   A matrix (denoted with a capital **X**) is composed of a set of elements.\n\n    -   Each element is denoted by its position in the matrix (row and column).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nX = matrix(c(\n  1, 2,\n  3, 4,\n  5, 6\n), nrow = 3, byrow = TRUE)\nX\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n[3,]    5    6\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(X) # Number of rows and columns\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3 2\n```\n\n\n:::\n:::\n\n\n-   In R, use `matrix[rowIndex, columnIndex]` to extract the element at `rowIndex` and `columnIndex`.\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nX[2, 1]\nX[3] # No comma in the bracket will output the element in column-wise order\nX[2, ] # 2nd row vector\nX[, 1] # 1st column vector\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3\n[1] 5\n[1] 3 4\n[1] 1 3 5\n```\n\n\n:::\n:::\n\n\n-   In statistics, we use $x_{ij}$ to represent the element in the *i*th row and *j*th column. For example, consider a matrix $\\mathbf{X}$ with 1,000 rows and 2 columns:\n\n    -   The first subscript is the index of the rows\n\n    -   The second subscript is the index of the columns\n\n$$\n\\mathbf{X} = \\begin{bmatrix}\nx_{11} & x_{12}\\\\\nx_{21} & x_{22}\\\\\n\\dots &  \\dots \\\\\nx_{1000, 1} & x_{1000,2}\n\\end{bmatrix}\n$$\n\n## Scalars\n\n-   A scalar is just a single number\n\n-   The name scalar is important: the number \"scales\" a vectorâ€”it can make a vector longer or shorter.\n\n-   Scalars are typically written without boldface:\n\n    $$\n    x_{11} = 520\n    $$\n\n-   Each element of a matrix is a scalar.\n\n-   Matrices can be multiplied by a scalar so that each element is multiplied by that scalar.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    3 * X\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n         [,1] [,2]\n    [1,]    3    6\n    [2,]    9   12\n    [3,]   15   18\n    ```\n    \n    \n    :::\n    :::\n\n\n## Matrix Transpose\n\n-   The transpose of a matrix is formed by switching the indices of the rows and columns.\n\n$$\n\\mathbf{X} = \\begin{bmatrix}\n520 & 580\\\\\n520 & 550\\\\\n\\vdots &  \\vdots\\\\\n540 & 660\\\\\n\\end{bmatrix}\n$$\n\n$$\n\\mathbf{X}^T = \\begin{bmatrix}\n520 & 520 & \\cdots & 540\\\\\n580 & 550 & \\cdots & 660\n\\end{bmatrix}\n$$\n\n-   An element $x_{ij}$ in the original matrix $\\mathbf{X}$ becomes $x_{ji}$ in the transposed matrix $\\mathbf{X}^T$.\n\n-   **Transposes are used to align matrices for operations where the sizes of matrices matter (such as matrix multiplication)**\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    t(X)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n         [,1] [,2] [,3]\n    [1,]    1    3    5\n    [2,]    2    4    6\n    ```\n    \n    \n    :::\n    :::\n\n\n## Types of Matrices\n\n-   **Square Matrix:** A square matrix has the same number of rows and columns.\n\n    -   Correlation / covariance matrices are square matrices\n\n-   **Diagonal Matrix:** A diagonal matrix is a square matrix with nonzero diagonal elements ($x_{ij}\\neq 0$ for $i=j$) and zeros on the off-diagonal elements ($x_{ij} = 0$ for $i\\neq j$):\n\n    $$\n    \\mathbf{A} = \\begin{bmatrix}\n    2.758 & 0 & 0 \\\\\n    0 & 1.643 & 0 \\\\\n    0 & 0     & 0.879\\\\\n    \\end{bmatrix}\n    $$\n\n    -   We will use diagonal matrices to transform correlation matrices into covariance matrices.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    vars = c(2.758, 1.643, 0.879)\n    diag(vars)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n          [,1]  [,2]  [,3]\n    [1,] 2.758 0.000 0.000\n    [2,] 0.000 1.643 0.000\n    [3,] 0.000 0.000 0.879\n    ```\n    \n    \n    :::\n    :::\n\n\n-   **Symmetric Matrix:** A symmetric matrix is a square matrix where all elements are reflected across the diagonal ($x_{ij} = x_{ji}$).\n\n    -   Correlation and covariance matrices are symmetric matrices\n    -   [**Question**: Is a diagonal matrix always symmetric?]{.underline} [True]{.mohu}\n\n## Linear Combinations\n\n-   The addition of a set of vectors (each multiplied by a scalar) is called a linear combination:\n\n$$\n\\mathbb{y} = a_1x_1 + a_2x_2 + \\cdots + a_kx_k = \\mathbf{A}^{-1} \\mathbf{X}\n$$\n\n-   Here, $\\mathbb{y}$ is the linear combination\n\n    -   For all *k* vectors, the set of all possible linear combinations is called their **span**\n\n    -   This is typically not emphasized in most analysesâ€”but when working with latent variables it becomes important.\n\n-   **In data**, linear combinations occur frequently:\n\n    -   Linear models (i.e., Regression and ANOVA)\n\n    -   Principal components analysis\n\n    -   **Question**: Do generalized linear models contain linear combinations? [True; link function + linear predictor]{.mohu}.\n\n## Inner (Dot/Cross-) Product of Vectors\n\n-   An important concept in vector geometry is the inner product of two vectors.\n\n    -   The inner product is also called the dot product\n\n    $$\n    \\mathbf{a} \\cdot \\mathbf{b} = a_{11}b_{11}+a_{21}b_{21}+\\cdots+ a_{N1}b_{N1} = \\sum_{i=1}^N{a_{i1}b_{i1}}\n    $$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx = matrix(c(1, 2), ncol = 1)\ny = matrix(c(2, 3), ncol = 1)\nx\ny\ncrossprod(x, y) # R function for dot product of x and y\nt(x) %*% y # This is formally equivalent to (but usually slightly faster than) the call `t(x) %*% y` (`crossprod`) or `x %*% t(y)` (`tcrossprod`).\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1]\n[1,]    1\n[2,]    2\n     [,1]\n[1,]    2\n[2,]    3\n     [,1]\n[1,]    8\n     [,1]\n[1,]    8\n```\n\n\n:::\n:::\n\n\n-------------\n\nUsing our example data `dataSAT`,\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncrossprod(dataSAT$SATV, dataSAT$SATM) # x and y could be variables in our data\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          [,1]\n[1,] 251928400\n```\n\n\n:::\n:::\n\n\n-   **In data:** the angle between vectors relates to the correlation between variables, and projection relates to regression/ANOVA/linear models.\n\n\n## Combine Two Matrices\n\nUse `cbind()` to combine by columns and `rbind()` to combine by rows. Dimensions must be conformable:\n\n- `cbind` requires the same number of rows.\n- `rbind` requires the same number of columns.\n\n```{webr-r}\n# Two 3x1 column vectors\nu <- matrix(c(1, 2, 3), ncol = 1)\nv <- matrix(c(4, 5, 6), ncol = 1)\n\n# Column-bind: 3x2 matrix\nC <- cbind(u, v)\nC\n\n# Two 1x3 row vectors\nu_row <- t(u)\nv_row <- t(v)\n\n# Row-bind: 2x3 matrix\nR <- rbind(u_row, v_row)\nR\n```\n\n--------------------\n\n```{webr-r}\n# Example with 3x2 matrices\nA <- matrix(1:6, nrow = 3, byrow = TRUE)   # 3x2\nB <- matrix(7:12, nrow = 3, byrow = TRUE)  # 3x2\n\n# cbind keeps rows (3) and stacks columns -> 3x4\ncbind(A, B)\n\n# rbind keeps columns (2) and stacks rows -> 6x2\nrbind(A, B)\n```\n\n\n## Mini Exercise: Dot Product\n\n::: panel-tabset\n### Question\n\nCompute the dot product of two column vectors and verify it equals the corresponding element of a matrix product.\n\n1) Define two vectors `a = [1, 3, 5]^T` and `b = [2, 4, 6]^T` as `3x1` matrices.\n\n2) Compute the dot product `a â‹… b` in two ways:\n\n- Using `crossprod(a, b)`\n- Using `t(a) %*% b`\n\n3) Now form matrices `A = [a  a]` (3x2) and `B = [b  b]` (3x2). Compute `t(A) %*% B`. Which entry of this `2x2` result equals `a â‹… b`?\n\n```{webr-r}\n#| echo: true\n#| eval: true\n# Starter code (edit and run):\na <- _________________\nb <- _________________\n\n# 1) Dot product two ways\ncrossprod(__, ___)\nt(__) %*% __\n\n# 2) Build A and B then compare\nA <- cbind(__, __)\nB <- cbind(__, __)\nt(__) %*% __\n```\n\n### Answer\n\n```{webr-r}\n#| echo: true\n#| eval: true\n#| output: true\n# Starter code (edit and run):\na <- matrix(c(1,3,5), ncol = 1)\nb <- matrix(c(2,4,6), ncol = 1)\n\n# 1) Dot product two ways\ncrossprod(a, b)\nt(a) %*% b\n\n# 2) Build A and B then compare\nA <- cbind(a, a)\nB <- cbind(b, b)\nt(A) %*% B\n```\n\nThe dot product is `a â‹… b = 1*2 + 3*4 + 5*6 = 44`.\n\nBoth `crossprod(a, b)` and `t(a) %*% b` return `44`.\n\nForming `A = [a  a]` and `B = [b  b]`, the product `t(A) %*% B` is a `2x2` matrix where every entry equals `a â‹… b = 44`, because each entry is the dot product between a column of `A` and a column of `B`.\n:::\n\n# Matrix Algebra\n\n## Moving from Vectors to Matrices\n\n-   A matrix can be thought of as a collection of vectors.\n\n    -   In R, use `df$[name]` or `matrix[, index]` to extract a single vector.\n\n-   Matrix algebra defines a set of operations and entities on matrices.\n\n    -   I will present a version meant to mirror your previous algebra experiences.\n\n-   Definitions:\n\n    -   Identity matrix\n\n    -   Zero vector\n\n    -   Ones vector\n\n-   Basic Operations:\n\n    -   Addition\n\n    -   Subtraction\n\n    -   Multiplication\n\n    -   \"Division\"\n\n## Matrix Addition and Subtraction\n\n-   Matrix addition and subtraction are much like vector addition and subtraction.\n\n-   **Rules:** Matrices must be the same size (rows and columns).\n\n    -   [Be careful! R may not produce an error message when adding a matrix and a vector.]{style=\"color: red\"}\n\n\n        ::: {.cell output-location='column'}\n        \n        ```{.r .cell-code}\n        A = matrix(c(1, 2, 3, 4), nrow = 2, byrow = T)\n        B = c(1, 2)\n        A\n        B\n        A+B\n        ```\n        \n        ::: {.cell-output .cell-output-stdout}\n        \n        ```\n             [,1] [,2]\n        [1,]    1    2\n        [2,]    3    4\n        [1] 1 2\n             [,1] [,2]\n        [1,]    2    3\n        [2,]    5    6\n        ```\n        \n        \n        :::\n        :::\n\n\n-   **Method:** the new matrix is constructed by element-by-element addition/subtraction of the previous matrices.\n\n-   **Order:** the order of the matrices (pre- and post-) does not matter.\n\n------------\n\n\n::: {.cell output-location='default'}\n\n```{.r .cell-code}\nA = matrix(c(1, 2, 3, 4), nrow = 2, byrow = T)\nB = matrix(c(5, 6, 7, 8), nrow = 2, byrow = T)\nC = matrix(c(3, 6), nrow = 2, byrow = T)\nA\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n```\n\n\n:::\n\n```{.r .cell-code}\nB\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1] [,2]\n[1,]    5    6\n[2,]    7    8\n```\n\n\n:::\n\n```{.r .cell-code}\nA + B\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1] [,2]\n[1,]    6    8\n[2,]   10   12\n```\n\n\n:::\n\n```{.r .cell-code}\nA - B\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1] [,2]\n[1,]   -4   -4\n[2,]   -4   -4\n```\n\n\n:::\n\n```{.r .cell-code}\nA + C\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in A + C: non-conformable arrays\n```\n\n\n:::\n:::\n\n\n## Matrix Multiplication\n\n-   **The new matrix** has the same [number of rows as the pre-multiplying]{style=\"color: tomato; font-weight: bold\"} matrix and the [number of columns as the post-multiplying]{style=\"color: royalblue; font-weight: bold\"} matrix.\n\n$$\n\\mathbf{A}_{(r \\times c)} \\mathbf{B}_{(c\\times k)} = \\mathbf{C}_{(r\\times k)}\n$$\n\n-   **Rules:** The pre-multiplying matrix must have a number of columns equal to the number of rows of the post-multiplying matrix.\n\n-   **Method:** the elements of the new matrix consist of the inner (dot) products of [the row vectors of the pre-multiplying matrix]{style=\"color: tomato; font-weight: bold\"} and [the column vectors of the post-multiplying matrix]{style=\"color: royalblue; font-weight: bold\"}.\n\n-   **Order:** The order of the matrices matters.\n\n-   **R:** Use the `%*%` operator or `crossprod` to perform matrix multiplication.\n\n\n::: {.cell output-location='default'}\n\n```{.r .cell-code}\nA = matrix(c(1, 2, 3, 4, 5, 6), nrow = 2, byrow = T)\nB = matrix(c(5, 6, 7, 8, 9, 10), nrow = 3, byrow = T)\nA\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n```\n\n\n:::\n\n```{.r .cell-code}\nB\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1] [,2]\n[1,]    5    6\n[2,]    7    8\n[3,]    9   10\n```\n\n\n:::\n\n```{.r .cell-code}\nA %*% B\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1] [,2]\n[1,]   46   52\n[2,]  109  124\n```\n\n\n:::\n\n```{.r .cell-code}\nB %*% A\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1] [,2] [,3]\n[1,]   29   40   51\n[2,]   39   54   69\n[3,]   49   68   87\n```\n\n\n:::\n:::\n\n\n-   **Example:** The inner product of A's first row vector and B's first column vector equals AB's first element.\n\n\n::: {.cell output-location='default'}\n\n```{.r .cell-code}\ncrossprod(A[1, ], B[, 1])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1]\n[1,]   46\n```\n\n\n:::\n\n```{.r .cell-code}\n(A%*%B)[1, 1]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 46\n```\n\n\n:::\n:::\n\n\n\n## Mean Centered\n\n$$\nX_{(n \\times k)}^c = X_{(n \\times k)} - I_{(n \\times 1)} * \\bar{X}_{(1 \\times k)} \n$$\nwhere n is the number of cases (sample size) and k is the number of variables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nX <- cbind(Sect1 = c(89, 71, 31, 74, 81, 54, 2, 21, 36, 17),\n           Sect2 = c(26, 32, 18, 51, 82, 15, 19, 98, 95, 24))\nXBAR <- colMeans(X)\nn <- nrow(X)\none <- matrix(1, nrow = n, ncol = 1)\nXc <- X - one %*% t(XBAR)\nXc\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      Sect1 Sect2\n [1,]  41.4   -20\n [2,]  23.4   -14\n [3,] -16.6   -28\n [4,]  26.4     5\n [5,]  33.4    36\n [6,]   6.4   -31\n [7,] -45.6   -27\n [8,] -26.6    52\n [9,] -11.6    49\n[10,] -30.6   -22\n```\n\n\n:::\n:::\n\n\n----\n\n### Self practice\n\n-   Try to mean centered the SATV and SATM of `datSAT`. \n-   Store your centered matrix as variable name `X_center`\n-   Test your centered matrix using `round(colMeans(X_center), 3)` to see if the means are 0s\n\n\n::: {.cell}\n\n```{.r .cell-code}\nX <- dataSAT[, c(\"SATV\", \"SATM\")]\nONE <- matrix(1, nrow = nrow(X), ncol = 1)\nX_bar <- colMeans(X)\nX_center <- X - ONE %*% X_bar\nround(colMeans(X_center), 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSATV SATM \n   0    0 \n```\n\n\n:::\n:::\n\n\n\n## Identity Matrix\n\n-   The identity matrix (denoted as $\\mathbf{I}$) is a matrix that, when pre- or post-multiplied by another matrix, results in the original matrix:\n\n    $$\n    \\mathbf{A}\\mathbf{I} = \\mathbf{A}\n    $$\n\n    $$\n    \\mathbf{I}\\mathbf{A}=\\mathbf{A}\n    $$\n\n-   The identity matrix is a square matrix that has:\n\n    -   Diagonal elements = 1\n\n    -   Off-diagonal elements = 0\n\n    $$\n    \\mathbf{I}_{(3 \\times 3)} = \\begin{bmatrix}\n    1&0&0\\\\\n    0&1&0\\\\\n    0&0&1\\\\\n    \\end{bmatrix}\n    $$\n\n-   **R:** Create an identity matrix using the `diag()` function.\n\n\n    ::: {.cell output-location='default' result='hold'}\n    \n    ```{.r .cell-code}\n    diag(nrow = 3)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n         [,1] [,2] [,3]\n    [1,]    1    0    0\n    [2,]    0    1    0\n    [3,]    0    0    1\n    ```\n    \n    \n    :::\n    \n    ```{.r .cell-code}\n    X = matrix(1:9, nrow = 3, byrow = TRUE)\n    X\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n         [,1] [,2] [,3]\n    [1,]    1    2    3\n    [2,]    4    5    6\n    [3,]    7    8    9\n    ```\n    \n    \n    :::\n    \n    ```{.r .cell-code}\n    diag(X)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    [1] 1 5 9\n    ```\n    \n    \n    :::\n    :::\n\n\n## Zero and One Vector\n\n-   The zero and one vectors are column vectors of zeros and ones, respectively:\n\n    $$\n    \\mathbf{0}_{(3\\times 1)} = \\begin{bmatrix}0\\\\0\\\\0\\end{bmatrix}\n    $$\n\n    $$\n    \\mathbf{1}_{(3\\times 1)} = \\begin{bmatrix}1\\\\1\\\\1\\end{bmatrix}\n    $$\n\n-   When pre- or post-multiplied with a matrix ($\\mathbf{A}$), the result with the zero vector is:\n\n    $$\n    \\mathbf{A0=0}\n    $$\n\n    $$\n    \\mathbf{0^TA=0}\n    $$\n\n-   **R:**\n\n\n::: {.cell output-location='default'}\n\n```{.r .cell-code}\nzero_vec <- matrix(0, nrow = 3, ncol = 1)\ncrossprod(B, zero_vec)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1]\n[1,]    0\n[2,]    0\n```\n\n\n:::\n\n```{.r .cell-code}\none_vec <- matrix(1, nrow = 3, ncol = 1)\ncrossprod(B, one_vec) # column-wise sums\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1]\n[1,]   21\n[2,]   24\n```\n\n\n:::\n:::\n\n\n## Matrix \"Division\": The Inverse Matrix\n\n-   Division from algebra:\n\n    -   First: $\\frac{a}{b} = b^{-1}a$\n\n    -   Second: $\\frac{a}{b}=1$\n\n-   \"Division\" in matrices serves a similar role.\n\n    -   For [**square symmetric**]{style=\"color: tomato; font-weight: bold\"} matrices, an inverse matrix is a matrix that, when pre- or post-multiplied with another matrix, produces the identity matrix:\n\n        $$\n        \\mathbf{A^{-1}A=I}\n        $$\n\n        $$\n        \\mathbf{AA^{-1}=I}\n        $$\n\n-   **R:** Use `solve()` to calculate the matrix inverse.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nA <- matrix(rlnorm(9), 3, 3, byrow = T)\nround(solve(A) %*% A, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1] [,2] [,3]\n[1,]    1    0    0\n[2,]    0    1    0\n[3,]    0    0    1\n```\n\n\n:::\n:::\n\n\n-   **Caution:** The calculation is complicated; even computers can struggle. Not all matrices can be inverted:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nA <- matrix(2:10, nrow = 3, ncol = 3, byrow = T)\nA\nsolve(A)%*%A\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in solve.default(A): Lapack routine dgesv: system is exactly singular: U[3,3] = 0\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1] [,2] [,3]\n[1,]    2    3    4\n[2,]    5    6    7\n[3,]    8    9   10\n```\n\n\n:::\n:::\n\n\n## Example: The Inverse of the Varianceâ€“Covariance Matrix\n\n-   In data analysis, the inverse shows up constantly in statistics.\n\n    -   Models that assume some form of (multivariate) normality need an inverse covariance matrix.\n\n-   Using our SAT example:\n\n    -   Our data matrix has size ($1000\\times 2$), which is not invertible.\n\n    -   However, $\\mathbf{X^TX}$ has size ($2\\times 2$)â€”square and symmetric.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    X = as.matrix(dataSAT[, c(\"SATV\", \"SATM\")])\n    crossprod(X, X)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n              SATV      SATM\n    SATV 251797800 251928400\n    SATM 251928400 254862700\n    ```\n    \n    \n    :::\n    :::\n\n\n    -   The inverse $\\mathbf{(X^TX)^{-1}}$ is:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    solve(crossprod(X, X))\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n                  SATV          SATM\n    SATV  3.610217e-07 -3.568652e-07\n    SATM -3.568652e-07  3.566802e-07\n    ```\n    \n    \n    :::\n    :::\n\n\n## Matrix Algebra Operations\n\n::: columns\n::: column\n-   $\\mathbf{(A+B)+C=A+(B+C)}$\n\n-   $\\mathbf{A+B=B+A}$\n\n-   $c(\\mathbf{A+B})=c\\mathbf{A}+c\\mathbf{B}$\n\n-   $(c+d)\\mathbf{A} = c\\mathbf{A} + d\\mathbf{A}$\n\n-   $\\mathbf{(A+B)^T=A^T+B^T}$\n\n-   $(cd)\\mathbf{A}=c(d\\mathbf{A})$\n\n-   $(c\\mathbf{A})^{T}=c\\mathbf{A}^T$\n\n-   $c\\mathbf{(AB)} = (c\\mathbf{A})\\mathbf{B}$\n\n-   $\\mathbf{A(BC) = (AB)C}$\n:::\n\n::: column\n-   $\\mathbf{A(B+C)=AB+AC}$\n-   $\\mathbf{(AB)}^T=\\mathbf{B}^T\\mathbf{A}^T$\n:::\n:::\n\n## Advanced Matrix Functions/Operations\n\n-   We end our matrix discussion with some advanced topics.\n\n-   To help us throughout, consider the correlation matrix of our SAT data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nR <- cor(dataSAT[, c(\"SATV\", \"SATM\")])\nR\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          SATV      SATM\nSATV 1.0000000 0.7752238\nSATM 0.7752238 1.0000000\n```\n\n\n:::\n:::\n\n\n$$\nR = \\begin{bmatrix}1.00 & 0.78 \\\\ 0.78 & 1.00\\end{bmatrix}\n$$\n\n## Matrix Trace\n\n-   For a square matrix $\\mathbf{A}$ with *p* rows/columns, the matrix trace is the sum of the diagonal elements:\n\n    $$\n    tr\\mathbf{A} = \\sum_{i=1}^{p} a_{ii}\n    $$\n\n-   In R, we can use `tr()` in `psych` package to calculate matrix trace\n\n-   For our data, the trace of the correlation matrix is 2\n\n    -   For all correlation matrices, **the trace is equal to the number of variables**\n\n\n        ::: {.cell}\n        \n        ```{.r .cell-code}\n        psych::tr(R)\n        ```\n        \n        ::: {.cell-output .cell-output-stdout}\n        \n        ```\n        [1] 2\n        ```\n        \n        \n        :::\n        :::\n\n\n-   The trace is considered as the total variance in multivariate statistics\n\n    -   Used as a target to recover when applying statistical models\n\n## Model Determinants\n\n-   A square matrix can be characterized by a scalar value called a determinant:\n\n    $$\n    \\text{det}\\mathbf{A} =|\\mathbf{A}|\n    $$\n\n-   Manual calculation of the determinant is tedious. In R, we use `det()` to calculate matrix determinant\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    det(R)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    [1] 0.399028\n    ```\n    \n    \n    :::\n    :::\n\n\n-   The determinant is useful in statistics:\n\n    -   Shows up in multivariate statistical distributions\n\n    -   Is a measure of \"generalized\" variance of multiple variables\n\n-   If the determinant is positive, the matrix is called positive definite â†’ the matrix has an inverse\n\n-   If the determinant is zero, the matrix is called singular matrix â†’ the matrix does not have an inverse, cannot used for multivariate analysis.\n\n-   If the determinant is not positive, the matrix is called non-positive definite â†’ the matrix has an inverse but very rare in multivariate analysis, maybe due to the mistakes in your data.\n\n## Mini Exercise 2: Inverse Model with Positive Determinant\n\n::: panel-tabset\n\n### Question\n\nCalculate the determinant of A and B\n\n```{webr-r}\nA <- matrix(rlnorm(9), 3, 3, byrow = T)\nB <- matrix(2:10, nrow = 3, ncol = 3, byrow = T)\n```\n\n### Answer\n\n```{webr-r}\nA <- matrix(rlnorm(9), 3, 3, byrow = T)\nB <- matrix(2:10, nrow = 3, ncol = 3, byrow = T)\ndet(A)\ndet(B)\n```\n:::\n\n## Wrap Up\n\n1.  Matrices show up nearly anytime multivariate statistics are used, often in the help/manual pages of the package you intend to use for analysis\n\n2.  You don't have to do matrix algebra, but please do try to understand the concepts underlying matrices\n\n3.  Your working with multivariate statistics will be better off because of even a small amount of understanding\n\n# Multivariate Normal Distribution\n\n## Covariance and Correlation in Matrices\n\n-   The covariance matrix $\\mathbf{S}$ is found by:\n\n    $$\n    \\mathbf{S}=\\frac{1}{N-1} \\mathbf{(X-1\\cdot\\bar x^T)^T(X-1\\cdot\\bar x^T)}\n    $$\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    X = as.matrix(dataSAT[,c(\"SATV\", \"SATM\")])\n    N = nrow(X)\n    XBAR = matrix(colMeans(X), ncol = 1)\n    ONES = matrix(1, nrow = nrow(X))\n    S = 1/(N-1) * t(X - ONES%*% t(XBAR)) %*% (X - ONES%*% t(XBAR))\n    S\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n             SATV     SATM\n    SATV 2479.817 3135.359\n    SATM 3135.359 6596.303\n    ```\n    \n    \n    :::\n    \n    ```{.r .cell-code}\n    cov(X)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n             SATV     SATM\n    SATV 2479.817 3135.359\n    SATM 3135.359 6596.303\n    ```\n    \n    \n    :::\n    :::\n\n\n## From Covariance to Correlation\n\n-   If we take the SDs (the square root of the diagonal of the covariance matrix) and put them into diagonal matrix $\\mathbf{D}$, the correlation matrix is found by:\n\n$$\n\\mathbf{R = D^{-1}SD^{-1}}\n$$ $$\n\\mathbf{S = DRD}\n$$\n\n\n::: {.cell output-location='default'}\n\n```{.r .cell-code}\nS ## variance-covariance matrix\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         SATV     SATM\nSATV 2479.817 3135.359\nSATM 3135.359 6596.303\n```\n\n\n:::\n\n```{.r .cell-code}\nD = sqrt(diag(diag(S))) ## Standard deviations for two variables\nD\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         [,1]     [,2]\n[1,] 49.79777  0.00000\n[2,]  0.00000 81.21763\n```\n\n\n:::\n\n```{.r .cell-code}\nR = solve(D) %*% S %*% solve(D)\nR\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          [,1]      [,2]\n[1,] 1.0000000 0.7752238\n[2,] 0.7752238 1.0000000\n```\n\n\n:::\n\n```{.r .cell-code}\ncor(X)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          SATV      SATM\nSATV 1.0000000 0.7752238\nSATM 0.7752238 1.0000000\n```\n\n\n:::\n:::\n\n\n## Generalized Variance\n\n-   The determinant of the covariance matrix is called **generalized variance**\n\n$$\n\\text{Generalized Sample Variance} = |\\mathbf{S}|\n$$\n\n-   It is a measure of spread across all variables\n\n    -   Reflecting how much overlapping area (covariance) across variables relative to the total variances occurs in the sample\n\n    -   Amount of overlap reduces the generalized sample variance\n\n\n::: {.cell output-location='default'}\n\n```{.r .cell-code}\ngsv = det(S)\ngsv\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 6527152\n```\n\n\n:::\n\n```{.r .cell-code}\n# If no correlation\nS_noCorr = S\nS_noCorr[upper.tri(S_noCorr)] = S_noCorr[lower.tri(S_noCorr)] = 0\nS_noCorr\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         SATV     SATM\nSATV 2479.817    0.000\nSATM    0.000 6596.303\n```\n\n\n:::\n\n```{.r .cell-code}\ngsv_noCorr <- det(S_noCorr)\ngsv_noCorr\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 16357628\n```\n\n\n:::\n\n```{.r .cell-code}\ngsv / gsv_noCorr\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.399028\n```\n\n\n:::\n\n```{.r .cell-code}\n# If correlation = 1\nS_PerfCorr = S\nS_PerfCorr[upper.tri(S_PerfCorr)] = S_PerfCorr[lower.tri(S_PerfCorr)] = prod(diag(S))\nS_PerfCorr\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             SATV         SATM\nSATV     2479.817 16357628.070\nSATM 16357628.070     6596.303\n```\n\n\n:::\n\n```{.r .cell-code}\ngsv_PefCorr <- det(S_PerfCorr)\ngsv_PefCorr\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -2.67572e+14\n```\n\n\n:::\n:::\n\n\n-   The generalized sample variance is:\n\n    -   Largest when variables are uncorrelated\n    -   Zero when variables from a linear dependency\n\n## Total Sample Variance\n\n-   The total sample variance is the sum of the variances of each variable in the sample.\n\n    -   The sum of the diagonal elements of the sample covariance matrix.\n    -   The trace of the sample covariance matrix.\n\n$$\n\\text{Total Sample Variance} = \\sum_{v=1}^{V} s^2_{x_i} = \\text{tr}\\mathbf{S}\n$$\n\nTotal sample variance for our SAT example:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(diag(S))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 9076.121\n```\n\n\n:::\n:::\n\n\n-   The total sample variance does not take into consideration the covariances among the variables.\n\n    -   It will not equal zero if linear dependency exists.\n\n## Multivariate Normal Distribution and Mahalanobis Distance\n\n-   The PDF of the multivariate normal distribution is very similar to the univariate normal distribution.\n\n$$\nf(\\mathbf{x}_p) = \\frac{1}{(2\\pi)^{\\frac{V}2}|\\mathbf{\\Sigma}|^{\\frac12}}\\exp[-\\frac{\\color{tomato}{(x_p^T - \\mu)^T \\mathbf{\\Sigma}^{-1}(x_p^T-\\mu)}}{2}]\n$$\n\nWhere $V$ represents the number of variables and the highlighted term is the [Mahalanobis distance]{style=\"color: tomato\"}.\n\n-   We use $MVN(\\mathbf{\\mu, \\Sigma})$ to represent a multivariate normal distribution with mean vector $\\mathbf{\\mu}$ and covariance matrix $\\mathbf{\\Sigma}$.\n\n-   Similar to the squared error in the univariate case, we can calculate the squared Mahalanobis distance for each observed individual in the context of a multivariate distribution.\n\n$$\nd^2(x_p) = (x_p^T - \\mu)^T \\Sigma^{-1}(x_p^T-\\mu)\n$$\n\n-   In R, we can use `mahalanobis` with a data vector (`x`), mean vector (`center`), and covariance matrix (`cov`) to calculate the squared Mahalanobis distance for one individual.\n\n\n::: {.cell output-location='default'}\n\n```{.r .cell-code}\nx_p <- X[1, ]\nx_p\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSATV SATM \n 520  580 \n```\n\n\n:::\n\n```{.r .cell-code}\nmahalanobis(x = x_p, center = XBAR, cov = S)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.346228\n```\n\n\n:::\n\n```{.r .cell-code}\nmahalanobis(x = X[2, ], center = XBAR, cov = S)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4211176\n```\n\n\n:::\n\n```{.r .cell-code}\nmahalanobis(x = X[3, ], center = XBAR, cov = S)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.6512687\n```\n\n\n:::\n\n```{.r .cell-code}\n# Alternatively,\nt(x_p - XBAR) %*% solve(S) %*% (x_p - XBAR)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         [,1]\n[1,] 1.346228\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmh_dist_all <- apply(X, 1, \\(x) mahalanobis(x, center = XBAR, cov = S))\nplot(density(mh_dist_all))\n```\n\n::: {.cell-output-display}\n![](Lecture07_files/figure-revealjs/unnamed-chunk-32-1.png){width=960}\n:::\n:::\n\n\n## Multivariate Normal Properties\n\n-   The multivariate normal distribution has useful properties that appear in statistical methods:\n\n-   If $\\mathbf{X}$ is distributed multivariate normally:\n\n    1.  Linear combinations of $\\mathbf{X}$ are normally distributed\n    2.  All subsets of $\\mathbf{X}$ are multivariate normally distributed\n    3.  A zero covariance between a pair of variables of $\\mathbf{X}$ implies that the variables are independent\n    4.  Conditional distributions of $\\mathbf{X}$ are multivariate normal\n\n## How to Use the Multivariate Normal Distribution in R\n\nSimilar to other distribution functions, use `dmvnorm` to get the density given the observations and the parameters (mean vector and covariance matrix). `rmvnorm` generates multiple samples from the distribution.\n\n\n::: {.cell output-location='default'}\n\n```{.r .cell-code}\nlibrary(mvtnorm)\n(mu <- colMeans(dataSAT[, 2:3]))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  SATV   SATM \n499.32 498.27 \n```\n\n\n:::\n\n```{.r .cell-code}\nS \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         SATV     SATM\nSATV 2479.817 3135.359\nSATM 3135.359 6596.303\n```\n\n\n:::\n\n```{.r .cell-code}\ndmvnorm(X[1, ], mean = mu, sigma = S)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.177814e-05\n```\n\n\n:::\n\n```{.r .cell-code}\ndmvnorm(X[2, ], mean = mu, sigma = S)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5.046773e-05\n```\n\n\n:::\n\n```{.r .cell-code}\n## Total Log Likelihood \nLL <- sum(log(apply(X, 1, \\(x) dmvnorm(x, mean = mu, sigma = S))))\nLL\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -10682.62\n```\n\n\n:::\n\n```{.r .cell-code}\n## Generate samples from MVN\nrmvnorm(20, mean = mu, sigma = S) |> show_table()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> SATV </th>\n   <th style=\"text-align:right;\"> SATM </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 537.0160 </td>\n   <td style=\"text-align:right;\"> 547.8028 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 387.0979 </td>\n   <td style=\"text-align:right;\"> 229.2198 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 571.3216 </td>\n   <td style=\"text-align:right;\"> 487.6030 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 535.4205 </td>\n   <td style=\"text-align:right;\"> 419.4245 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 497.6253 </td>\n   <td style=\"text-align:right;\"> 531.8480 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 419.4548 </td>\n   <td style=\"text-align:right;\"> 433.5945 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 467.1004 </td>\n   <td style=\"text-align:right;\"> 465.8834 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 587.4870 </td>\n   <td style=\"text-align:right;\"> 650.3022 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 517.0927 </td>\n   <td style=\"text-align:right;\"> 445.2122 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 467.8157 </td>\n   <td style=\"text-align:right;\"> 551.3610 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 499.3387 </td>\n   <td style=\"text-align:right;\"> 511.4012 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 517.7979 </td>\n   <td style=\"text-align:right;\"> 551.5509 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 549.7992 </td>\n   <td style=\"text-align:right;\"> 614.0548 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 521.5178 </td>\n   <td style=\"text-align:right;\"> 428.4098 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 495.9478 </td>\n   <td style=\"text-align:right;\"> 332.4840 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 496.0289 </td>\n   <td style=\"text-align:right;\"> 557.1868 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 439.6495 </td>\n   <td style=\"text-align:right;\"> 294.9847 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 577.3656 </td>\n   <td style=\"text-align:right;\"> 610.7236 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 510.8110 </td>\n   <td style=\"text-align:right;\"> 510.8675 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 512.4274 </td>\n   <td style=\"text-align:right;\"> 455.9697 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n## Mini Exercise 3: Self Practice\n\n::: panel-tabset\n### Question\n\nUsing a small practice matrix and the tools from this lecture, complete the following steps. Fill in the underlined placeholders where indicated.\n\n1) Build the data matrix `X` with columns `SATV` and `SATM` (as a numeric matrix). Compute:\n\n- The sample mean vector `XBAR` and covariance matrix `S`.\n- The correlation matrix `R` and its trace `tr(R)`.\n\n2) Verify basic matrix operations:\n\n- Center `X` to `Xc = X - ____ %*% t(____)` using a ones vector and the mean vector.\n- Check that `colMeans(Xc)` is (approximately) ____.\n- Confirm `t(Xc) %*% Xc / (____ - 1)` equals ____.\n\n3) Work with products and inverses:\n\n- Compute `XtX = crossprod(____)` and its inverse `XtX_inv = solve(____)`.\n- Verify `round(XtX_inv %*% ____, 6)` equals the identity.\n\n4) Mahalanobis distances and MVN:\n\n- Compute squared Mahalanobis distances for all rows of `X` using `mahalanobis` with center `____` and cov `____`.\n- Plot the density of the distances.\n\n```{webr-r}\n# Starter code (fill in the blanks and run):\n\n# 1) Data matrix and summaries\n# Create a small 2-variable practice matrix (n = 8)\nX <- cbind(Sect1 = c(520, 540, 560, 590, 610, 620, 640, 660),\n           Sect2 = c(510, 555, 570, 600, 605, 635, 650, 670))\nXBAR <- colMeans(____)\nS <- cov(____)\nR <- cor(____)\nXBAR; S; R\nsum(diag(R))  # trace(R)\n\n# 2) Centering with a ones vector\nn <- nrow(____)\none <- matrix(1, nrow = n, ncol = 1)\nXc <- ____ - one %*% t(____)\ncolMeans(____)\ncrossprod(____)/(n - 1)  # should equal ____\n\n# 3) Products and inverses\nXtX <- crossprod(____)\nXtX_inv <- solve(____)\nround(XtX_inv %*% ____, 6)\n\n# 4) Mahalanobis distances\nmh <- mahalanobis(____, center = ____, cov = ____)\nplot(density(mh))\n```\n\n### Answer\n\n```{webr-r}\n# Starter code (edit and run):\n\n# 1) Data matrix and summaries\n# Create a small 2-variable practice matrix (n = 8)\nX <- cbind(Sect1 = c(520, 540, 560, 590, 610, 620, 640, 660),\n           Sect2 = c(510, 555, 570, 600, 605, 635, 650, 670))\nXBAR <- colMeans(X)\nS <- cov(X)\nR <- cor(X)\nXBAR; S; R\nsum(diag(R))  # trace(R)\n\n# 2) Centering with a ones vector\nn <- nrow(X)\none <- matrix(1, nrow = n, ncol = 1)\nXc <- X - one %*% t(XBAR)\ncolMeans(Xc)\ncrossprod(Xc)/(n - 1)  # should equal S\n\n# 3) Products and inverses\nXtX <- crossprod(X)\nXtX_inv <- solve(XtX)\nround(XtX_inv %*% XtX, 6)\n\n# 4) Mahalanobis distances\nmh <- mahalanobis(X, center = XBAR, cov = S)\nplot(density(mh))\n```\n\n\n- `XBAR` is the 2x1 mean vector of `SATV` and `SATM`; `S` is their 2x2 sample covariance matrix; `R` is the correlation matrix and `tr(R)` equals the sum of its diagonal (2.0 for perfectly standardized variables; here it depends on scaling).\n- Centering with a ones vector yields `colMeans(Xc)` approximately zero; and `t(Xc) %*% Xc / (n - 1)` equals `S` by definition of sample covariance.\n- `XtX_inv %*% XtX` equals the identity (up to rounding) when `XtX` is invertible.\n- `mahalanobis(X, XBAR, S)` returns squared distances used in multivariate normal contexts; the density plot visualizes their distribution.\n:::\n\n\n## Wrapping Up\n\n1.  We are now ready to discuss multivariate models and the art/science of multivariate modeling.\n\n2.  Many of the concepts from univariate models carry over:\n\n    -   Maximum likelihood\n    -   Model building via nested models\n    -   Concepts involving multivariate distributions\n\n3.  Matrix algebra was necessary to concisely describe our distributions (which will soon be models).\n\n4.  Understanding the multivariate normal distribution is essential, as it is the most commonly used distribution for estimating multivariate models.\n\n5.  Next class, we will return to data analysisâ€”for multivariate observationsâ€”using Râ€™s lavaan package for path analysis.\n",
    "supporting": [
      "Lecture07_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}